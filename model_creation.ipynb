{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.16.5)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.42)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.44.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (69.1.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 23:56:10.951919: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-31 23:56:10.975043: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>N-Score</th>\n",
       "      <th>E-Score</th>\n",
       "      <th>O-Score</th>\n",
       "      <th>A-Score</th>\n",
       "      <th>C-Score</th>\n",
       "      <th>Impulsiveness</th>\n",
       "      <th>Sensation-seeking</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Benzo</th>\n",
       "      <th>Cannabis</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Semeron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  N-Score  E-Score  O-Score  A-Score  C-Score  Impulsiveness  \\\n",
       "0    1  0.31287 -0.57545 -0.58331 -0.91699 -0.00665       -0.21712   \n",
       "1    2 -0.67825  1.93886  1.43533  0.76096 -0.14277       -0.71126   \n",
       "2    3 -0.46725  0.80523 -0.84732 -1.62090 -1.01450       -1.37983   \n",
       "3    4 -0.14882 -0.80615 -0.01928  0.59042  0.58489       -1.37983   \n",
       "4    5  0.73545 -1.63340 -0.45174 -0.30172  1.30612       -0.21712   \n",
       "\n",
       "   Sensation-seeking  Amphet  Benzo  Cannabis  Heroin  Ketamine  Methadone  \\\n",
       "0           -1.18084       0      0         0       0         0          0   \n",
       "1           -0.21575       0      0         0       0         0          0   \n",
       "2            0.40148       0      0         0       0         0          0   \n",
       "3           -1.18084       0      0         0       0         0          0   \n",
       "4           -0.21575       0      0         0       0         0          0   \n",
       "\n",
       "   Semeron  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"drug_consumption_2.txt\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"idx\",\n",
    "        \"N-Score\",\n",
    "        \"E-Score\",\n",
    "        \"O-Score\",\n",
    "        \"A-Score\",\n",
    "        \"C-Score\",\n",
    "        \"Impulsiveness\",\n",
    "        \"Sensation-seeking\",\n",
    "        \"Amphet\",\n",
    "        \"Benzo\",\n",
    "        \"Cannabis\",\n",
    "        \"Heroin\",\n",
    "        \"Ketamine\",\n",
    "        \"Methadone\",\n",
    "        \"Semeron\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize score ranges to be [0, 1].\n",
    "for column in df.columns[1:8]:\n",
    "    column_min, column_max = df[column].min(), df[column].max()\n",
    "\n",
    "    column_normalized = (df[column] - column_min) / (column_max - column_min)\n",
    "\n",
    "    df[column] = column_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ranges:\n",
      "   idx: [1, 1888]\n",
      "   N-Score: [0.0, 1.0]\n",
      "   E-Score: [0.0, 1.0]\n",
      "   O-Score: [0.0, 1.0]\n",
      "   A-Score: [0.0, 1.0]\n",
      "   C-Score: [0.0, 1.0]\n",
      "   Impulsiveness: [0.0, 1.0]\n",
      "   Sensation-seeking: [0.0, 1.0]\n",
      "   Amphet: [0, 1]\n",
      "   Benzo: [0, 1]\n",
      "   Cannabis: [0, 1]\n",
      "   Heroin: [0, 1]\n",
      "   Ketamine: [0, 1]\n",
      "   Methadone: [0, 1]\n",
      "   Semeron: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Column ranges:\")\n",
    "for column in df.columns:\n",
    "    column_range = (df[column].min(), df[column].max())\n",
    "\n",
    "    print(f\"   { column}: [{column_range[0]}, { column_range[1] }]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "  Amphet dataset\n",
      "     Train dataset: 0: 1426, 1: 82\n",
      "     Test dataset: 0: 357, 1: 20\n",
      "  Benzo dataset\n",
      "     Train dataset: 0: 1432, 1: 76\n",
      "     Test dataset: 0: 358, 1: 19\n",
      "  Cannabis dataset\n",
      "     Train dataset: 0: 1138, 1: 370\n",
      "     Test dataset: 0: 284, 1: 93\n",
      "  Heroin dataset\n",
      "     Train dataset: 0: 1485, 1: 23\n",
      "     Test dataset: 0: 371, 1: 6\n",
      "  Ketamine dataset\n",
      "     Train dataset: 0: 1505, 1: 3\n",
      "     Test dataset: 0: 376, 1: 1\n",
      "  Methadone dataset\n",
      "     Train dataset: 0: 1450, 1: 58\n",
      "     Test dataset: 0: 362, 1: 15\n",
      "  Semeron dataset\n",
      "     Train dataset: 0: 1502, 1: 6\n",
      "     Test dataset: 0: 375, 1: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Class counts:\")\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"  { target } dataset\\n     Train dataset: 0: { len(target_y_train[target_y_train == 0]) }, 1: { len(target_y_train[target_y_train == 1]) }\\n     Test dataset: 0: { len(target_y_test[target_y_test == 0]) }, 1: { len(target_y_test[target_y_test == 1]) }\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Benzo': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Cannabis': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Heroin': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Ketamine': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Methadone': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Semeron': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0)}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.8620689655172413,\n",
      "        \"precision\": 0.029411764705882353,\n",
      "        \"recall\": 0.05,\n",
      "        \"f1_score\": 0.037037037037037035\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.883289124668435,\n",
      "        \"precision\": 0.037037037037037035,\n",
      "        \"recall\": 0.05263157894736842,\n",
      "        \"f1_score\": 0.043478260869565216\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.6074270557029178,\n",
      "        \"precision\": 0.34104046242774566,\n",
      "        \"recall\": 0.6344086021505376,\n",
      "        \"f1_score\": 0.44360902255639095\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.9496021220159151,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9946949602122016,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.8753315649867374,\n",
      "        \"precision\": 0.05555555555555555,\n",
      "        \"recall\": 0.13333333333333333,\n",
      "        \"f1_score\": 0.0784313725490196\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.986737400530504,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    # Create classifier.\n",
    "    target_clf = DecisionTreeClassifier(\n",
    "        criterion=\"gini\",\n",
    "        max_depth=15,\n",
    "        min_samples_leaf=3,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_clf.fit(target_x_train, target_y_train)\n",
    "    models[target] = target_clf\n",
    "\n",
    "    joblib.dump(\n",
    "        target_clf, f\"./models/decision_tree_{ target.lower() }.joblib\", compress=3\n",
    "    )\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = target_clf.predict(target_x_test)\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(\n",
    "        target_y_test, target_y_predictions, zero_division=np.nan\n",
    "    )\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Benzo': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Cannabis': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Heroin': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Ketamine': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Methadone': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Semeron': KNeighborsClassifier(n_neighbors=3)}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.9442970822281167,\n",
      "        \"precision\": 0.3333333333333333,\n",
      "        \"recall\": 0.05,\n",
      "        \"f1_score\": 0.08695652173913043\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.9283819628647215,\n",
      "        \"precision\": 0.1,\n",
      "        \"recall\": 0.05263157894736842,\n",
      "        \"f1_score\": 0.06896551724137931\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.7002652519893899,\n",
      "        \"precision\": 0.375,\n",
      "        \"recall\": 0.3225806451612903,\n",
      "        \"f1_score\": 0.3468208092485549\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.9840848806366048,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9973474801061007,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.9549071618037135,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.9946949602122016,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    # Create classifier.\n",
    "    target_neigh = KNeighborsClassifier(\n",
    "        n_neighbors=3,\n",
    "    )\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_neigh.fit(target_x_train, target_y_train)\n",
    "    models[target] = target_neigh\n",
    "\n",
    "    joblib.dump(target_neigh, f\"./models/knn_{ target.lower() }.joblib\", compress=3)\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = models[target].predict(target_x_test)\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(\n",
    "        target_y_test, target_y_predictions, zero_division=np.nan\n",
    "    )\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Benzo': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Cannabis': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Heroin': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Ketamine': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Methadone': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Semeron': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0)}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.9389920424403183,\n",
      "        \"precision\": 0.2,\n",
      "        \"recall\": 0.05,\n",
      "        \"f1_score\": 0.08\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.9257294429708223,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.726790450928382,\n",
      "        \"precision\": 0.4479166666666667,\n",
      "        \"recall\": 0.46236559139784944,\n",
      "        \"f1_score\": 0.455026455026455\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.9840848806366048,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9973474801061007,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.9575596816976127,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.9946949602122016,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    # Create classifier.\n",
    "    target_clf = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=25,\n",
    "        min_samples_leaf=3,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_clf.fit(target_x_train, target_y_train)\n",
    "    models[target] = target_clf\n",
    "\n",
    "    joblib.dump(\n",
    "        target_clf, f\"./models/random_forest_{ target.lower() }.joblib\", compress=3\n",
    "    )\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = target_clf.predict(target_x_test)\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(\n",
    "        target_y_test, target_y_predictions, zero_division=np.nan\n",
    "    )\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_df(data_frame: pd.DataFrame, target: str):\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        data_frame,\n",
    "        train_size=0.8,\n",
    "        shuffle=True,\n",
    "        stratify=data_frame[target],\n",
    "        random_state=0,\n",
    "    )\n",
    "    print(target)\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    x_train, y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    x_test, y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbas_korver\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235617-4j9248zx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace' target=\"_blank\">denim-wave-171</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.5553033169378232, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-wave-171</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235617-4j9248zx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = wandb.Artifact(\"drug_consumption\", type=\"dataset\")\n",
    "dataset.add_file(\"./drug_consumption_2.txt\")\n",
    "with wandb.init(project=\"XAI-group-assignment\", job_type=\"upload\"):\n",
    "    wandb.log_artifact(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ann_model_sweep():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_1,\n",
    "                activation=wandb.config.activation_1,\n",
    "                input_shape=wandb.config.input_shape_1,\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_2,\n",
    "                activation=wandb.config.activation_2,\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_3,\n",
    "                activation=wandb.config.activation_3,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    match wandb.config.optimizer:\n",
    "        case \"adam\":\n",
    "            optimizer = tf.keras.optimizers.Adam\n",
    "        case \"adamw\":\n",
    "            optimizer = tf.keras.optimizers.AdamW\n",
    "        case \"adamax\":\n",
    "            optimizer = tf.keras.optimizers.Adamax\n",
    "        case \"sgd\":\n",
    "            optimizer = tf.keras.optimizers.SGD\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer(wandb.config.lr),\n",
    "        loss=wandb.config.loss,\n",
    "        metrics=[\"accuracy\", \"precision\", \"recall\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb():\n",
    "    # Initialize wandb\n",
    "    with wandb.init():\n",
    "        # Load data.\n",
    "        target_x_train, target_y_train, target_x_test, target_y_test = get_data_from_df(\n",
    "            df, wandb.config.drug\n",
    "        )\n",
    "\n",
    "        # Calculate class weights.\n",
    "        if wandb.config.class_weighting:\n",
    "            target_class_weights = dict(\n",
    "                enumerate(\n",
    "                    class_weight.compute_class_weight(\n",
    "                        \"balanced\",\n",
    "                        classes=np.unique(target_y_train),\n",
    "                        y=target_y_train,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Create classifier.\n",
    "        target_model = create_ann_model_sweep()\n",
    "\n",
    "        # Train model with data specified for target.\n",
    "        if wandb.config.class_weighting:\n",
    "            target_model.fit(\n",
    "                target_x_train,\n",
    "                target_y_train,\n",
    "                epochs=wandb.config.epoch,\n",
    "                batch_size=wandb.config.batch_size,\n",
    "                class_weight=target_class_weights,\n",
    "                callbacks=[WandbMetricsLogger(\"batch\")],\n",
    "            )\n",
    "        else:\n",
    "            target_model.fit(\n",
    "                target_x_train,\n",
    "                target_y_train,\n",
    "                epochs=wandb.config.epoch,\n",
    "                batch_size=wandb.config.batch_size,\n",
    "                callbacks=[WandbMetricsLogger(\"batch\")],\n",
    "            )\n",
    "\n",
    "        models[target] = target_model\n",
    "\n",
    "        target_model.save(f\"./models/ann_{ target }.h5\")\n",
    "\n",
    "        # Evaluate trained classifier.\n",
    "        target_y_predictions = (target_model.predict(target_x_test) >= 0.5).astype(\n",
    "            \"int32\"\n",
    "        )\n",
    "\n",
    "        # Calculate metrics.\n",
    "        accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "        precision = precision_score(target_y_test, target_y_predictions)\n",
    "        recall = recall_score(target_y_test, target_y_predictions)\n",
    "        f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": f1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        model_artifact = wandb.Artifact(\n",
    "            name=f\"{target}_{f1}\",\n",
    "            type=\"model\",\n",
    "            description=f\"Model trained for {target}\",\n",
    "            metadata=dict(wandb.config),\n",
    "        )\n",
    "        model_artifact.add_file(f\"./models/ann_{ target }.h5\")\n",
    "        wandb.log_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 9kg7b063\n",
      "Sweep URL: https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: as2ydkcv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08002929024687723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235817-as2ydkcv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace' target=\"_blank\">classic-sweep-1</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7232 - loss: 0.3962 - precision: 0.0753 - recall: 0.3407\n",
      "Epoch 2/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.2180 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2469 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.2161 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.2210 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.2269 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2177 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.2123 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2108 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.2080 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2220 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2092 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2149 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2094 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2055 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2017 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.2060 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.2129 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▅██▇██▇█▇██▇████████▇██▇████████████▇▇█</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▃▂▄▃▂▃▂▃▃▂▃▃▂▂▂▁▃▃▃▃▂▂▃▂▃▂▂▂▁▂▂▂▃▂▂▃▃▂</td></tr><tr><td>batch/precision</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁█████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▄▄▂▃▁▁▃▄▂▂▁▃▃▃▂▂▂▃▂▂▃▂▂▄▃▂▂▂</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>209</td></tr><tr><td>batch/loss</td><td>0.20705</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/loss</td><td>0.20705</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-1</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235817-as2ydkcv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kh8fw3d8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.04173528501990623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235838-kh8fw3d8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace' target=\"_blank\">ancient-sweep-2</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.2736 - loss: 0.7149 - precision: 0.0426 - recall: 0.6581\n",
      "Epoch 2/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1855 - loss: 0.6711 - precision: 0.0537 - recall: 0.8948 \n",
      "Epoch 3/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3869 - loss: 0.6795 - precision: 0.0587 - recall: 0.6947 \n",
      "Epoch 4/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4143 - loss: 0.6633 - precision: 0.0606 - recall: 0.7326 \n",
      "Epoch 5/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 0.6774 - precision: 0.0852 - recall: 0.6441 \n",
      "Epoch 6/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.7741 - precision: 0.0661 - recall: 0.0085         \n",
      "Epoch 7/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7010 - loss: 0.6665 - precision: 0.1197 - recall: 0.3606         \n",
      "Epoch 8/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2411 - loss: 0.6596 - precision: 0.0557 - recall: 0.8772 \n",
      "Epoch 9/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6882 - loss: 0.6553 - precision: 0.0797 - recall: 0.4834 \n",
      "Epoch 10/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5356 - loss: 0.6572 - precision: 0.0735 - recall: 0.6582 \n",
      "Epoch 11/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5763 - loss: 0.6666 - precision: 0.0876 - recall: 0.6972 \n",
      "Epoch 12/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5711 - loss: 0.7022 - precision: 0.0913 - recall: 0.6510 \n",
      "Epoch 13/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6279 - loss: 0.6734 - precision: 0.0838 - recall: 0.5784 \n",
      "Epoch 14/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6442 - loss: 0.6293 - precision: 0.0894 - recall: 0.6303 \n",
      "Epoch 15/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6351 - loss: 0.6876 - precision: 0.0940 - recall: 0.5909 \n",
      "Epoch 16/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6321 - loss: 0.7149 - precision: 0.1049 - recall: 0.5752 \n",
      "Epoch 17/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6601 - loss: 0.6356 - precision: 0.1053 - recall: 0.6678 \n",
      "Epoch 18/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7280 - loss: 0.6669 - precision: 0.0956 - recall: 0.4817 \n",
      "Epoch 19/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 0.6905 - precision: 0.0940 - recall: 0.6851 \n",
      "Epoch 20/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7810 - loss: 0.6645 - precision: 0.0898 - recall: 0.3603         \n",
      "Epoch 21/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7117 - loss: 0.6623 - precision: 0.1079 - recall: 0.5661 \n",
      "Epoch 22/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6137 - loss: 0.6519 - precision: 0.0682 - recall: 0.5315         \n",
      "Epoch 23/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5755 - loss: 0.6523 - precision: 0.0801 - recall: 0.6397 \n",
      "Epoch 24/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6613 - loss: 0.6678 - precision: 0.1029 - recall: 0.5908 \n",
      "Epoch 25/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.6539 - precision: 0.1440 - recall: 0.0831         \n",
      "Epoch 26/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6448 - loss: 0.5812 - precision: 0.0809 - recall: 0.6510 \n",
      "Epoch 27/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4523 - loss: 0.7120 - precision: 0.0813 - recall: 0.7439 \n",
      "Epoch 28/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7269 - loss: 0.6717 - precision: 0.1120 - recall: 0.5130 \n",
      "Epoch 29/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6273 - loss: 0.6509 - precision: 0.0854 - recall: 0.5874 \n",
      "Epoch 30/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6536 - loss: 0.6742 - precision: 0.0990 - recall: 0.5712 \n",
      "Epoch 31/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6835 - loss: 0.6715 - precision: 0.1130 - recall: 0.5840 \n",
      "Epoch 32/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.6470 - precision: 0.1161 - recall: 0.5624 \n",
      "Epoch 33/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6600 - loss: 0.6810 - precision: 0.0875 - recall: 0.5093 \n",
      "Epoch 34/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6942 - loss: 0.6203 - precision: 0.0956 - recall: 0.5862 \n",
      "Epoch 35/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5579 - loss: 0.6145 - precision: 0.0878 - recall: 0.8047 \n",
      "Epoch 36/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6729 - loss: 0.6647 - precision: 0.0882 - recall: 0.5368 \n",
      "Epoch 37/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6682 - loss: 0.6703 - precision: 0.1114 - recall: 0.6322 \n",
      "Epoch 38/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.6101 - precision: 0.1287 - recall: 0.5128 \n",
      "Epoch 39/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6292 - loss: 0.6272 - precision: 0.0833 - recall: 0.6606 \n",
      "Epoch 40/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6775 - loss: 0.6718 - precision: 0.0954 - recall: 0.5323 \n",
      "Epoch 41/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7874 - loss: 0.6688 - precision: 0.1248 - recall: 0.4432 \n",
      "Epoch 42/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.6233 - precision: 0.0984 - recall: 0.5261 \n",
      "Epoch 43/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5147 - loss: 0.7023 - precision: 0.0940 - recall: 0.7515 \n",
      "Epoch 44/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.6691 - precision: 0.1005 - recall: 0.2494         \n",
      "Epoch 45/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6606 - loss: 0.6340 - precision: 0.1025 - recall: 0.6630 \n",
      "Epoch 46/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6670 - loss: 0.6426 - precision: 0.1135 - recall: 0.6913 \n",
      "Epoch 47/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7924 - loss: 0.6525 - precision: 0.1387 - recall: 0.4924 \n",
      "Epoch 48/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7136 - loss: 0.6011 - precision: 0.0853 - recall: 0.5237 \n",
      "Epoch 49/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7091 - loss: 0.6399 - precision: 0.1155 - recall: 0.6205 \n",
      "Epoch 50/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7310 - loss: 0.6429 - precision: 0.0841 - recall: 0.4239 \n",
      "Epoch 51/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6774 - loss: 0.6448 - precision: 0.1182 - recall: 0.6737 \n",
      "Epoch 52/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.5894 - precision: 0.1493 - recall: 0.5135 \n",
      "Epoch 53/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7517 - loss: 0.6321 - precision: 0.1166 - recall: 0.5164 \n",
      "Epoch 54/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5962 - loss: 0.5880 - precision: 0.0750 - recall: 0.7204 \n",
      "Epoch 55/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.6333 - precision: 0.0848 - recall: 0.6593 \n",
      "Epoch 56/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.6105 - precision: 0.0850 - recall: 0.3007 \n",
      "Epoch 57/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5748 - loss: 0.6316 - precision: 0.1050 - recall: 0.7667 \n",
      "Epoch 58/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.6131 - precision: 0.0942 - recall: 0.3381         \n",
      "Epoch 59/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7205 - loss: 0.5902 - precision: 0.1150 - recall: 0.6564 \n",
      "Epoch 60/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5915 - precision: 0.1295 - recall: 0.6471 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▁▃▅▆▃▄▅▄▅▄▄▄▅▄▅█▅▆▅▅▅▆▅▅▅▅▆▅▅▅▆▆▅▆▄▅▄▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▅▆▅▆▅▅▄▄█▅▆▅▄▅▃▄▆▄▄▇▄▆▄▆▄▃▅▂▄▃▄▆▄▁▂▄▃▂</td></tr><tr><td>batch/precision</td><td>▁▂▂▃▃▂▂▄▂▃▃▃▃▃▂▃█▃▅▃▃▃▄▄▄▄▃▃▃▄▄▄▅▄▅▂▄▄▅▅</td></tr><tr><td>batch/recall</td><td>▆█▇▅▃▇▅▅▆▆▆▆▇▅▆▅▁▆▅▆▆▄▅▅▆▆▆▄▆▆▆▅▆▆▅█▇▇▅▆</td></tr><tr><td>epoch/accuracy</td><td>▁▂▄▅▃▄▅▆▅▅▆▅▆▆▆▅█▅▆▅▅▆▆▅▆▇▅▆▅▆▆▇▆▆▆▇▅▆▆▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▆▅▆▅▆▅▅▅▃▄▄▅▄▅▄▆▄▃▃▄▄▃▄▄▄▃▄▅▅▃▃▃▃▃▄▁▃▂▁</td></tr><tr><td>epoch/precision</td><td>▁▁▂▃▂▂▂▄▃▄▃▃▄▃▃▃█▃▄▃▃▄▄▄▄▅▄▄▃▃▄▅▅▅▅▅▄▃▅▅</td></tr><tr><td>epoch/recall</td><td>██▆▅▆▇▆▅▆▆▅▆▅▅▅▅▁▆▅▆▆▅▅▇▆▄▆▅▆▄▆▅▆▅▅▄▇▅▅▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.687</td></tr><tr><td>batch/accuracy</td><td>0.70027</td></tr><tr><td>batch/batch_step</td><td>959</td></tr><tr><td>batch/loss</td><td>0.60555</td></tr><tr><td>batch/precision</td><td>0.11134</td></tr><tr><td>batch/recall</td><td>0.64634</td></tr><tr><td>epoch/accuracy</td><td>0.70027</td></tr><tr><td>epoch/epoch</td><td>59</td></tr><tr><td>epoch/loss</td><td>0.60555</td></tr><tr><td>epoch/precision</td><td>0.11134</td></tr><tr><td>epoch/recall</td><td>0.64634</td></tr><tr><td>f1_score</td><td>0.19178</td></tr><tr><td>precision</td><td>0.11111</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-2</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235838-kh8fw3d8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y0xljow7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08870812353317625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235856-y0xljow7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace' target=\"_blank\">blooming-sweep-3</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7221 - loss: 0.3901 - precision: 0.0368 - recall: 0.1995\n",
      "Epoch 2/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.2281 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.2335 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.2204 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.2007 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.2020 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.2257 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1787 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.2255 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2002 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.2205 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.2133 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.2267 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1889 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1971 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1822 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1917 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2070 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2126 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2106 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1868 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1891 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1916 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.1896 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1981 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.2104 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.2198 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2027 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1797 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.2015 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1834 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.2077 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1817 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.2021 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1932 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2093 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1981 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9410 - loss: 0.2081 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2082 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▄▄▄▃▁▄▃▄▄▃▃▄▄▃▃▃▄▄▄▃▃▂▂▃▃▃▃▃▃▄▄▃▃▃▄▄▃▃</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▂▂▂▃▂▂▂▁▂▂▁▂▁▁▂▂▂▁▂▁▂▁▁▃▁▁▁▃▂▁▁▁▁▅▁▂</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>719</td></tr><tr><td>batch/loss</td><td>0.20227</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>59</td></tr><tr><td>epoch/loss</td><td>0.20227</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-3</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235856-y0xljow7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1dbuxtcc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 58\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.04148164010801726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235912-1dbuxtcc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace' target=\"_blank\">avid-sweep-4</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8059 - loss: 0.3477 - precision: 0.0469 - recall: 0.1332\n",
      "Epoch 2/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.2161 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2246 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9524 - loss: 0.1815 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1893 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.2593 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.2037 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.2104 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2071 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2076 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.2147 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1729 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2174 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1995 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9373 - loss: 0.2255 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.2261 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9388 - loss: 0.2237 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.2241 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.2296 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.2209 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1889 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2044 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2134 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9436 - loss: 0.2116 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2052 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1802 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1653 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2194 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.2162 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1893 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1832 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2116 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1852 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2095 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1743 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2071 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1756 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.2274 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2196 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1998 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9337 - loss: 0.2392 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.2137 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5d50381f3447d98da93c29e008b885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▆▇▆▆▆▇▆▆▆▇▆▆▆▅▆▆▅▆▆▆▆▆▆▇▆▆▆█▆▆▆▅▆▆▆▇▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▄▄▄▅▃▅▄▃▂▅▄▃▅▅▄▅▄▄▄▅▅▄▁▅▃▄▁▄▄▄▆▃▄▄▂▄▄▄</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▁▁▂▃▂▂▂▁▂▁▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>1391</td></tr><tr><td>batch/loss</td><td>0.20112</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>57</td></tr><tr><td>epoch/loss</td><td>0.20112</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-sweep-4</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235912-1dbuxtcc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lcj2vf69 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.07101435730894305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235937-lcj2vf69</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace' target=\"_blank\">wandering-sweep-5</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.4067 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 2/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2205 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.2429 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2201 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9367 - loss: 0.2377 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9395 - loss: 0.2285 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9448 - loss: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.2335 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9468 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9552 - loss: 0.1807 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1838 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2103 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.2100 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2145 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2087 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 22/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2130 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2114 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2153 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 26/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2183 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 27/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1998 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1834 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 30/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9505 - loss: 0.1895 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 32/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9330 - loss: 0.2308 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 33/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.2256 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2114 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 35/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.2193 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 36/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1810 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9436 - loss: 0.2108 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1887 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9463 - loss: 0.2046 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 41/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1817 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2022 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1817 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.2022 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1968 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1848 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1782 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.2032 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1839 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.2219 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.9479 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 55/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1872 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9431 - loss: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 58/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2027 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1898 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.2272 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 64/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2093 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 65/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 66/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9388 - loss: 0.2147 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 67/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.9418 - loss: 0.2138 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 68/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9376 - loss: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 69/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1996 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 70/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.9457 - loss: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 71/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.2215 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 72/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9469 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 73/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 74/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2124 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 75/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9315 - loss: 0.2440 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 76/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.2231 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 77/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9430 - loss: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 78/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9348 - loss: 0.2307 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 79/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2135 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 80/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9474 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 81/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9503 - loss: 0.1884 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 82/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.2257 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 83/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9403 - loss: 0.2073 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 84/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.2246 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 85/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2102 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 86/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 87/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9460 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 88/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 89/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 90/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.2127 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0df411830f42ffa981606ae3558794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▆▄▆█▆▅▆▆▆▅▄▆▆▆▅▅▆▄▆▅▆▆▆▇▅▆▇▆▅▆▆▄▅▁▆▄▆▇▃</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▂▄▆▃▁▄▃▂▃▂▃▅▂▂▂▄▄▃▄▂▃▂▂▂▁▄▂▁▂▄▂▃▅▄█▂▅▂▂▄</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▃▃▁▁▁▁▁▂▁▁▁▃▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>4319</td></tr><tr><td>batch/loss</td><td>0.19672</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>89</td></tr><tr><td>epoch/loss</td><td>0.19672</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-sweep-5</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235937-lcj2vf69/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cz3k0cko with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.05899822579974695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000004-cz3k0cko</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace' target=\"_blank\">sweet-sweep-6</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.6519 - loss: 0.4405 - precision: 0.0804 - recall: 0.4272\n",
      "Epoch 2/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.2275 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.2105 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2166 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2080 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1903 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1950 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2045 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2090 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1943 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.2106 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2193 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.2266 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1972 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.2039 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1947 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.1819 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.2109 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1896 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.2040 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 33/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2090 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.2088 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1926 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1931 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2095 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2076 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1929 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.1968 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2033 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1888 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2020 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2037 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.2224 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1944 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1880 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1916 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.2103 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.2255 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.2216 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1906 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1863 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 64/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1954 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 65/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 66/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.2127 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 67/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1856 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 68/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1969 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 69/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1987 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 70/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1950 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 71/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1964 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 72/72\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1970 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2285ff79e4564ca98d36d2ccc53144c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇█████▇██▇▇▇███▇▇███▇█████▇▇██▇▇██▇████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▃▂▂▁▂▁▃▂▂▂▃▄▂▂▂▃▂▂▂▁▂▂▂▂▂▂▃▃▁▂▃▂▂▁▂▁▂▂▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>503</td></tr><tr><td>batch/loss</td><td>0.19984</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>71</td></tr><tr><td>epoch/loss</td><td>0.19984</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-sweep-6</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000004-cz3k0cko/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x9ovh5xz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08971019076624763\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000019-x9ovh5xz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x9ovh5xz/workspace' target=\"_blank\">whole-sweep-7</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x9ovh5xz/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/x9ovh5xz/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4721 - loss: 0.8790 - precision: 0.0575 - recall: 0.5296\n",
      "Epoch 2/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5852 - loss: 0.6846 - precision: 0.0594 - recall: 0.4612 \n",
      "Epoch 3/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7358 - loss: 0.6714 - precision: 0.1184 - recall: 0.3695 \n",
      "Epoch 4/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6288 - loss: 0.6280 - precision: 0.0800 - recall: 0.5871 \n",
      "Epoch 5/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2770 - loss: 0.7018 - precision: 0.0637 - recall: 0.8471 \n",
      "Epoch 6/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6166 - loss: 0.7210 - precision: 0.0779 - recall: 0.5007 \n",
      "Epoch 7/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.6862 - precision: 0.0324 - recall: 0.0861         \n",
      "Epoch 8/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6426 - loss: 0.6809 - precision: 0.0916 - recall: 0.5875 \n",
      "Epoch 9/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6002 - loss: 0.6753 - precision: 0.0772 - recall: 0.5657         \n",
      "Epoch 10/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7124 - loss: 0.6702 - precision: 0.0794 - recall: 0.4270 \n",
      "Epoch 11/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8209 - loss: 0.6248 - precision: 0.1021 - recall: 0.3307         \n",
      "Epoch 12/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8739 - loss: 0.6490 - precision: 0.1354 - recall: 0.2459         \n",
      "Epoch 13/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7428 - loss: 0.6663 - precision: 0.0941 - recall: 0.4187 \n",
      "Epoch 14/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.6867 - precision: 0.0989 - recall: 0.2403 \n",
      "Epoch 15/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4709 - loss: 0.7212 - precision: 0.0678 - recall: 0.6053 \n",
      "Epoch 16/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8325 - loss: 0.6748 - precision: 0.3253 - recall: 0.2594 \n",
      "Epoch 17/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8085 - loss: 0.6031 - precision: 0.0964 - recall: 0.3735         \n",
      "Epoch 18/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8354 - loss: 0.6720 - precision: 0.1220 - recall: 0.3075 \n",
      "Epoch 19/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7434 - loss: 0.6137 - precision: 0.0725 - recall: 0.4107 \n",
      "Epoch 20/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6747 - loss: 0.7113 - precision: 0.0588 - recall: 0.3908 \n",
      "Epoch 21/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1671 - loss: 0.6939 - precision: 0.0630 - recall: 0.9382 \n",
      "Epoch 22/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7849 - loss: 0.6480 - precision: 0.0887 - recall: 0.3340         \n",
      "Epoch 23/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7536 - loss: 0.6806 - precision: 0.0972 - recall: 0.4136 \n",
      "Epoch 24/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7582 - loss: 0.7043 - precision: 0.1083 - recall: 0.4188 \n",
      "Epoch 25/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7488 - loss: 0.6375 - precision: 0.0899 - recall: 0.4432 \n",
      "Epoch 26/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6591 - loss: 0.7059 - precision: 0.0804 - recall: 0.4403 \n",
      "Epoch 27/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7277 - loss: 0.7369 - precision: 0.1242 - recall: 0.5005 \n",
      "Epoch 28/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8340 - loss: 0.6509 - precision: 0.1005 - recall: 0.2648         \n",
      "Epoch 29/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.6725 - precision: 0.1428 - recall: 0.1167         \n",
      "Epoch 30/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3254 - loss: 0.6708 - precision: 0.0627 - recall: 0.7949 \n",
      "Epoch 31/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7298 - loss: 0.6253 - precision: 0.0962 - recall: 0.5220 \n",
      "Epoch 32/32\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7997 - loss: 0.6260 - precision: 0.1253 - recall: 0.4775 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8975959a6b45470990240d1c756b90f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▄▆▅▆▂▄▅█▆▅▆▆▇█▇▇▇▄▇▇▇▇▇▇▁▇▇▇▇▇▅▆▇▇█▂▆▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▄▃▁▄▃▃▃▄▃▃▃▃▂▄▃▃▃▃▁▁▃▃▄▄▃▃▃▃▂▄▃▃▃▄▃▂▃▂</td></tr><tr><td>batch/precision</td><td>▂▁▂▂▂▂▁▂▁▃▃▂▂▃▆▂▃▃▁▃▃▃▅▄▂▂▃▃▄▃▃▂▃▄▄█▁▃▃▄</td></tr><tr><td>batch/recall</td><td>▆▄▄▄▄█▅▄▁▅▅▅▃▄▂▃▄▂▅▃▃▃▃▃▂█▃▄▃▃▄▄▄▄▃▁▇▅▄▄</td></tr><tr><td>epoch/accuracy</td><td>▃▃▄▂▁▄▆▄▅▆▆▇▆█▅▄▆█▇▆▁▇▇▇▆▆▇▇▇▄▇█</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▃▂▃▃▄▂▃▃▂▂▃▃▄▃▃▃▂▅▂▁▂▃▁▂▁▂▄▂▁▂</td></tr><tr><td>epoch/precision</td><td>▁▁▂▂▁▂▁▃▃▃▄▅▄▅▁▂▄█▆▂▂▅▆▅▅▅▆▅▃▃▅█</td></tr><tr><td>epoch/recall</td><td>▄▄▅▇▆▄▂▆▅▃▄▃▃▁▃▄▃▂▃▁█▄▃▂▄▄▄▃▁▆▃▃</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.74005</td></tr><tr><td>batch/accuracy</td><td>0.83554</td></tr><tr><td>batch/batch_step</td><td>767</td></tr><tr><td>batch/loss</td><td>0.66241</td></tr><tr><td>batch/precision</td><td>0.13913</td></tr><tr><td>batch/recall</td><td>0.39024</td></tr><tr><td>epoch/accuracy</td><td>0.83554</td></tr><tr><td>epoch/epoch</td><td>31</td></tr><tr><td>epoch/loss</td><td>0.66241</td></tr><tr><td>epoch/precision</td><td>0.13913</td></tr><tr><td>epoch/recall</td><td>0.39024</td></tr><tr><td>f1_score</td><td>0.19672</td></tr><tr><td>precision</td><td>0.11765</td></tr><tr><td>recall</td><td>0.6</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-7</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x9ovh5xz/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/x9ovh5xz/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000019-x9ovh5xz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s0uwwqnh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02962183007166432\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000035-s0uwwqnh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/s0uwwqnh/workspace' target=\"_blank\">chocolate-sweep-8</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/s0uwwqnh/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/s0uwwqnh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6897 - loss: 0.6696 - precision: 0.0327 - recall: 0.2443     \n",
      "Epoch 2/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0611 - loss: 0.7058 - precision: 0.0573 - recall: 1.0000 \n",
      "Epoch 3/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2006 - loss: 0.6938 - precision: 0.0621 - recall: 0.9533 \n",
      "Epoch 4/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.7030 - precision: 0.7955 - recall: 0.0250         \n",
      "Epoch 5/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9322 - loss: 0.6960 - precision: 0.0864 - recall: 0.0370         \n",
      "Epoch 6/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4338 - loss: 0.7145 - precision: 0.0435 - recall: 0.5338         \n",
      "Epoch 7/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3760 - loss: 0.6855 - precision: 0.0754 - recall: 0.8571 \n",
      "Epoch 8/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7089 - loss: 0.6420 - precision: 0.0751 - recall: 0.4152 \n",
      "Epoch 9/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8113 - loss: 0.6313 - precision: 0.0873 - recall: 0.2876         \n",
      "Epoch 10/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3588 - loss: 0.7014 - precision: 0.0716 - recall: 0.8319 \n",
      "Epoch 11/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7161 - loss: 0.6488 - precision: 0.0769 - recall: 0.4024         \n",
      "Epoch 12/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5839 - loss: 0.6391 - precision: 0.0835 - recall: 0.6946 \n",
      "Epoch 13/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6853 - loss: 0.6291 - precision: 0.0938 - recall: 0.5805 \n",
      "Epoch 14/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5996 - loss: 0.6179 - precision: 0.0751 - recall: 0.6047 \n",
      "Epoch 15/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5139 - loss: 0.6612 - precision: 0.0782 - recall: 0.7007 \n",
      "Epoch 16/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5739 - loss: 0.6090 - precision: 0.0808 - recall: 0.7256 \n",
      "Epoch 17/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4169 - loss: 0.6418 - precision: 0.0698 - recall: 0.8078 \n",
      "Epoch 18/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6132 - loss: 0.6183 - precision: 0.0803 - recall: 0.6551 \n",
      "Epoch 19/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5648 - loss: 0.6646 - precision: 0.0847 - recall: 0.6818 \n",
      "Epoch 20/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6255 - loss: 0.6429 - precision: 0.0710 - recall: 0.5094 \n",
      "Epoch 21/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5857 - loss: 0.6653 - precision: 0.0967 - recall: 0.6827 \n",
      "Epoch 22/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6262 - loss: 0.6219 - precision: 0.0856 - recall: 0.6587 \n",
      "Epoch 23/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4737 - loss: 0.6874 - precision: 0.0894 - recall: 0.8037 \n",
      "Epoch 24/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5813 - loss: 0.6677 - precision: 0.0887 - recall: 0.6846 \n",
      "Epoch 25/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5508 - loss: 0.6840 - precision: 0.0997 - recall: 0.7229 \n",
      "Epoch 26/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5931 - loss: 0.6764 - precision: 0.0896 - recall: 0.6385 \n",
      "Epoch 27/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5535 - loss: 0.6278 - precision: 0.0850 - recall: 0.7480 \n",
      "Epoch 28/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4344 - loss: 0.6321 - precision: 0.0718 - recall: 0.8110 \n",
      "Epoch 29/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3692 - loss: 0.6244 - precision: 0.0697 - recall: 0.9082 \n",
      "Epoch 30/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5660 - loss: 0.6214 - precision: 0.0668 - recall: 0.5942         \n",
      "Epoch 31/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5751 - loss: 0.6191 - precision: 0.0828 - recall: 0.6982 \n",
      "Epoch 32/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5358 - loss: 0.5669 - precision: 0.0732 - recall: 0.7978 \n",
      "Epoch 33/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5131 - loss: 0.6271 - precision: 0.0832 - recall: 0.8078 \n",
      "Epoch 34/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6204 - loss: 0.5822 - precision: 0.0899 - recall: 0.7207 \n",
      "Epoch 35/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4420 - loss: 0.6620 - precision: 0.0884 - recall: 0.8636 \n",
      "Epoch 36/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6226 - loss: 0.5427 - precision: 0.0766 - recall: 0.7061 \n",
      "Epoch 37/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4489 - loss: 0.6317 - precision: 0.0831 - recall: 0.8740 \n",
      "Epoch 38/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5627 - loss: 0.6389 - precision: 0.1115 - recall: 0.8121 \n",
      "Epoch 39/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6118 - loss: 0.6102 - precision: 0.0984 - recall: 0.7440 \n",
      "Epoch 40/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5404 - loss: 0.6207 - precision: 0.1012 - recall: 0.8247 \n",
      "Epoch 41/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4654 - loss: 0.6287 - precision: 0.0870 - recall: 0.8460 \n",
      "Epoch 42/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6732 - loss: 0.5987 - precision: 0.1154 - recall: 0.7924 \n",
      "Epoch 43/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3853 - loss: 0.6691 - precision: 0.0756 - recall: 0.8679 \n",
      "Epoch 44/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6436 - loss: 0.5761 - precision: 0.0848 - recall: 0.6404 \n",
      "Epoch 45/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5964 - loss: 0.5759 - precision: 0.0848 - recall: 0.7509         \n",
      "Epoch 46/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5612 - loss: 0.5942 - precision: 0.0876 - recall: 0.8274 \n",
      "Epoch 47/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2936 - loss: 0.6513 - precision: 0.0666 - recall: 0.9146 \n",
      "Epoch 48/48\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7569 - loss: 0.6134 - precision: 0.1109 - recall: 0.5010 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab195c8cf9d491f87fd38a78267e625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▁▁██▃▆▇▃▄▆▆▅▅▆▅▅▅▆▅▄▅▃▃▅▅▅▅▄▆▅▅▅▄▆▆▅▅▂▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▆▇▇▇▆▆▆▅▆▂▅▅▅▆▄▅▅▆▇▇▆▅█▅▅▅▅▄▇▂▅▅▆▆▅▁▄▃▆▅</td></tr><tr><td>batch/precision</td><td>▁▁▁█▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂</td></tr><tr><td>batch/recall</td><td>▁██▁▂▇▄▃▇█▅▆▆▆▆▆▅▆▆▅▆▆▇▇▅▅▆▇▇▆▇█▇▇▇█▇██▅</td></tr><tr><td>epoch/accuracy</td><td>▄▁▃██▅▅▇▃▆▆▅▅▄▄▅▅▅▅▄▄▅▅▄▄▅▅▅▅▄▅▄▅▅▄▄▅▅▅▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▇▇▇▇▆▆▅▇▅▄▄▅▄▄▃▃▃▃▅▃▄▃▄▄▂▂▂▂▂▂▂▂▁▂▂▁▁▃▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁█▂▁▁▂▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▂▁▁▂▁▂▁▂▂▁▁▂▂▂▂</td></tr><tr><td>epoch/recall</td><td>▅█▆▁▂▅▅▄▇▅▅▅▅▆▆▆▅▆▆▇▆▆▆▆▇▆▆▆▆▇▆▇▆▆▇▇▆▆▆▅</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.62599</td></tr><tr><td>batch/accuracy</td><td>0.6817</td></tr><tr><td>batch/batch_step</td><td>1007</td></tr><tr><td>batch/loss</td><td>0.61449</td></tr><tr><td>batch/precision</td><td>0.09553</td></tr><tr><td>batch/recall</td><td>0.57317</td></tr><tr><td>epoch/accuracy</td><td>0.6817</td></tr><tr><td>epoch/epoch</td><td>47</td></tr><tr><td>epoch/loss</td><td>0.61449</td></tr><tr><td>epoch/precision</td><td>0.09553</td></tr><tr><td>epoch/recall</td><td>0.57317</td></tr><tr><td>f1_score</td><td>0.16568</td></tr><tr><td>precision</td><td>0.09396</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">chocolate-sweep-8</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/s0uwwqnh/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/s0uwwqnh/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000035-s0uwwqnh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9ezoregm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.09777103193934555\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000051-9ezoregm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9ezoregm/workspace' target=\"_blank\">misunderstood-sweep-9</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9ezoregm/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/9ezoregm/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4195 - loss: 1.0104 - precision: 0.0518 - recall: 0.5117        \n",
      "Epoch 2/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6981 - loss: 0.6540 - precision: 0.0285 - recall: 0.2559         \n",
      "Epoch 3/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6251 - loss: 0.6832 - precision: 0.0925 - recall: 0.4828 \n",
      "Epoch 4/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5494 - loss: 0.6503 - precision: 0.0803 - recall: 0.7056 \n",
      "Epoch 5/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6023 - loss: 0.6349 - precision: 0.0638 - recall: 0.5526         \n",
      "Epoch 6/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5450 - loss: 0.6546 - precision: 0.0826 - recall: 0.7366 \n",
      "Epoch 7/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2265 - loss: 0.7356 - precision: 0.0699 - recall: 0.8936 \n",
      "Epoch 8/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.7043 - precision: 0.0540 - recall: 0.4201         \n",
      "Epoch 9/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5527 - loss: 0.6697 - precision: 0.0860 - recall: 0.7059 \n",
      "Epoch 10/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4177 - loss: 0.7119 - precision: 0.0901 - recall: 0.8705 \n",
      "Epoch 11/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4428 - loss: 0.6796 - precision: 0.0802 - recall: 0.8264 \n",
      "Epoch 12/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3953 - loss: 0.6745 - precision: 0.0741 - recall: 0.8115 \n",
      "Epoch 13/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2674 - loss: 0.6683 - precision: 0.0605 - recall: 0.9096 \n",
      "Epoch 14/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5787 - loss: 0.6285 - precision: 0.0779 - recall: 0.6443 \n",
      "Epoch 15/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4472 - loss: 0.6196 - precision: 0.0639 - recall: 0.7238 \n",
      "Epoch 16/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3721 - loss: 0.5763 - precision: 0.0582 - recall: 0.8465         \n",
      "Epoch 17/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2248 - loss: 0.6995 - precision: 0.0700 - recall: 0.9722 \n",
      "Epoch 18/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5107 - loss: 0.6665 - precision: 0.1036 - recall: 0.8257 \n",
      "Epoch 19/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4842 - loss: 0.6673 - precision: 0.0678 - recall: 0.6842        \n",
      "Epoch 20/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5124 - loss: 0.6942 - precision: 0.0904 - recall: 0.7545 \n",
      "Epoch 21/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5110 - loss: 0.6714 - precision: 0.0748 - recall: 0.6833\n",
      "Epoch 22/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4266 - loss: 0.6992 - precision: 0.0577 - recall: 0.6098 \n",
      "Epoch 23/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.6655 - precision: 0.0133 - recall: 0.0436         \n",
      "Epoch 24/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4078 - loss: 0.6644 - precision: 0.0443 - recall: 0.5561 \n",
      "Epoch 25/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3099 - loss: 0.7042 - precision: 0.0543 - recall: 0.6991 \n",
      "Epoch 26/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4779 - loss: 0.6896 - precision: 0.0459 - recall: 0.5237         \n",
      "Epoch 27/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1638 - loss: 0.7357 - precision: 0.0613 - recall: 0.8812 \n",
      "Epoch 28/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6124 - loss: 0.7388 - precision: 0.0403 - recall: 0.3552         \n",
      "Epoch 29/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6872 - loss: 0.7525 - precision: 0.0368 - recall: 0.2439         \n",
      "Epoch 30/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.7182 - precision: 0.0184 - recall: 0.0735         \n",
      "Epoch 31/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4492 - loss: 0.7012 - precision: 0.0443 - recall: 0.4533 \n",
      "Epoch 32/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5239 - loss: 0.7490 - precision: 0.0466 - recall: 0.4331         \n",
      "Epoch 33/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.7046 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6738 - loss: 0.6946 - precision: 0.0348 - recall: 0.2474         \n",
      "Epoch 35/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6346 - loss: 0.6588 - precision: 0.0357 - recall: 0.2795 \n",
      "Epoch 36/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2773 - loss: 0.6844 - precision: 0.0533 - recall: 0.7609 \n",
      "Epoch 37/37\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5028 - loss: 0.6679 - precision: 0.0438 - recall: 0.4882         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04eaa4ee50d84e708b9cfbad2e7bfa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▄██▅▄▄▅▂▄▅▄▄▃▃▆▄▂▄▃▄▄▄▄▅█▄▄▄▁███▆█▃█▄▇▃▃</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▃▂▃▃▃▃▄▄▄▄▄▃▄▃▃▁▃▃▃▄▃▄▃▃▃▃▃▄▄▅▅▄▄▄▄▄▄▃▃</td></tr><tr><td>batch/precision</td><td>▄▁█▄▄▄▅▃▄▅▅▅▄▄▄▄▂▄▄▄▄▄▄▄▁▃▃▃▄▁▁▁▃▁▃▁▃▃▃▃</td></tr><tr><td>batch/recall</td><td>▄▁▃▅▆▆▆▇▅▆▇▇▇▇▅▆█▇█▇▇▆▆▄▁▅▅▅█▁▁▁▃▁▆▁▄▂▆▅</td></tr><tr><td>epoch/accuracy</td><td>▃▃▄▄▃▄▂▃▃▃▄▃▂▄▂▃▂▂▃▃▂▆▆▄▅▁▃▂▃▅▄▂█▄▄▄▄</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▂▁▃▂▃▃▂▂▂▁▂▁▂▁▁▁▂▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>epoch/precision</td><td>▅▆▇█▇█▆▆▇▇█▇▇▇▆▇▇▇▇▇▆▆▅▅▅▆▆▅▅▅▄▅▁▅▅▆▅</td></tr><tr><td>epoch/recall</td><td>▅▆▅▇▆▆▆▆▇▇▇▇█▆▇██▇▇▇▇▃▃▅▄▇▆▆▄▃▄▆▁▄▄▄▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.50928</td></tr><tr><td>batch/batch_step</td><td>998</td></tr><tr><td>batch/loss</td><td>0.69556</td></tr><tr><td>batch/precision</td><td>0.04808</td></tr><tr><td>batch/recall</td><td>0.42683</td></tr><tr><td>epoch/accuracy</td><td>0.50928</td></tr><tr><td>epoch/epoch</td><td>36</td></tr><tr><td>epoch/loss</td><td>0.69556</td></tr><tr><td>epoch/precision</td><td>0.04808</td></tr><tr><td>epoch/recall</td><td>0.42683</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-sweep-9</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9ezoregm/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/9ezoregm/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000051-9ezoregm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ra8fgluh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 78\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.07187289894958496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000106-ra8fgluh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ra8fgluh/workspace' target=\"_blank\">lyric-sweep-10</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ra8fgluh/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ra8fgluh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.0558 - loss: 0.7079 - precision: 0.0558 - recall: 1.0000\n",
      "Epoch 2/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0650 - loss: 0.7474 - precision: 0.0633 - recall: 1.0000 \n",
      "Epoch 3/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1156 - loss: 0.6859 - precision: 0.0524 - recall: 0.9204 \n",
      "Epoch 4/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3259 - loss: 0.6628 - precision: 0.0577 - recall: 0.8108 \n",
      "Epoch 5/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3678 - loss: 0.6890 - precision: 0.0660 - recall: 0.8076 \n",
      "Epoch 6/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4049 - loss: 0.7040 - precision: 0.0748 - recall: 0.8274 \n",
      "Epoch 7/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5152 - loss: 0.6962 - precision: 0.0830 - recall: 0.7638 \n",
      "Epoch 8/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5726 - loss: 0.6691 - precision: 0.0709 - recall: 0.5927 \n",
      "Epoch 9/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5920 - loss: 0.6450 - precision: 0.0751 - recall: 0.6526 \n",
      "Epoch 10/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.6533 - precision: 0.0850 - recall: 0.7106 \n",
      "Epoch 11/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4614 - loss: 0.7132 - precision: 0.0777 - recall: 0.7456 \n",
      "Epoch 12/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5528 - loss: 0.6754 - precision: 0.0813 - recall: 0.7150 \n",
      "Epoch 13/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5160 - loss: 0.7162 - precision: 0.0872 - recall: 0.7329 \n",
      "Epoch 14/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6246 - loss: 0.6594 - precision: 0.0868 - recall: 0.6794 \n",
      "Epoch 15/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5837 - loss: 0.6510 - precision: 0.0847 - recall: 0.7575 \n",
      "Epoch 16/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4882 - loss: 0.7026 - precision: 0.0863 - recall: 0.7957 \n",
      "Epoch 17/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5087 - loss: 0.7012 - precision: 0.0867 - recall: 0.7851 \n",
      "Epoch 18/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5910 - loss: 0.6574 - precision: 0.0773 - recall: 0.6299 \n",
      "Epoch 19/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6461 - loss: 0.6347 - precision: 0.0757 - recall: 0.5820 \n",
      "Epoch 20/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5506 - loss: 0.6643 - precision: 0.0815 - recall: 0.7370 \n",
      "Epoch 21/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5215 - loss: 0.7059 - precision: 0.0879 - recall: 0.7407 \n",
      "Epoch 22/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5839 - loss: 0.6887 - precision: 0.0981 - recall: 0.7474 \n",
      "Epoch 23/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5968 - loss: 0.6808 - precision: 0.0859 - recall: 0.6482 \n",
      "Epoch 24/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5784 - loss: 0.6863 - precision: 0.0771 - recall: 0.5916 \n",
      "Epoch 25/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 0.6637 - precision: 0.0869 - recall: 0.7037 \n",
      "Epoch 26/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5985 - loss: 0.6457 - precision: 0.0729 - recall: 0.5924 \n",
      "Epoch 27/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5944 - loss: 0.6299 - precision: 0.0746 - recall: 0.6640 \n",
      "Epoch 28/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 0.6842 - precision: 0.0885 - recall: 0.7705 \n",
      "Epoch 29/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6027 - loss: 0.6643 - precision: 0.0849 - recall: 0.6572 \n",
      "Epoch 30/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.6602 - precision: 0.0848 - recall: 0.6726 \n",
      "Epoch 31/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.6530 - precision: 0.0813 - recall: 0.6731 \n",
      "Epoch 32/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5604 - loss: 0.6711 - precision: 0.0867 - recall: 0.7154 \n",
      "Epoch 33/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6603 - loss: 0.6245 - precision: 0.0870 - recall: 0.6320 \n",
      "Epoch 34/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5528 - loss: 0.6795 - precision: 0.0871 - recall: 0.7191 \n",
      "Epoch 35/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6328 - loss: 0.6290 - precision: 0.0768 - recall: 0.5882 \n",
      "Epoch 36/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5732 - loss: 0.6839 - precision: 0.0918 - recall: 0.7119 \n",
      "Epoch 37/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6101 - loss: 0.6589 - precision: 0.0920 - recall: 0.6818 \n",
      "Epoch 38/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5963 - loss: 0.6764 - precision: 0.0934 - recall: 0.6830 \n",
      "Epoch 39/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 0.6504 - precision: 0.0912 - recall: 0.6775 \n",
      "Epoch 40/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6491 - loss: 0.6286 - precision: 0.0846 - recall: 0.5990 \n",
      "Epoch 41/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5939 - loss: 0.6278 - precision: 0.0627 - recall: 0.5298 \n",
      "Epoch 42/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5649 - loss: 0.6627 - precision: 0.0981 - recall: 0.7875 \n",
      "Epoch 43/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6098 - loss: 0.6761 - precision: 0.1095 - recall: 0.7463 \n",
      "Epoch 44/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6081 - loss: 0.6852 - precision: 0.0995 - recall: 0.6670 \n",
      "Epoch 45/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6415 - loss: 0.6627 - precision: 0.0806 - recall: 0.5353 \n",
      "Epoch 46/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6220 - loss: 0.6355 - precision: 0.0852 - recall: 0.6449 \n",
      "Epoch 47/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6084 - loss: 0.6649 - precision: 0.0848 - recall: 0.6122 \n",
      "Epoch 48/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6026 - loss: 0.6499 - precision: 0.0909 - recall: 0.6935 \n",
      "Epoch 49/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6202 - loss: 0.6539 - precision: 0.0843 - recall: 0.6185 \n",
      "Epoch 50/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6500 - loss: 0.6407 - precision: 0.0936 - recall: 0.6350 \n",
      "Epoch 51/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6839 - loss: 0.5872 - precision: 0.0748 - recall: 0.5541 \n",
      "Epoch 52/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5768 - loss: 0.6333 - precision: 0.0727 - recall: 0.6353 \n",
      "Epoch 53/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6385 - loss: 0.6205 - precision: 0.0917 - recall: 0.6857 \n",
      "Epoch 54/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6335 - loss: 0.6484 - precision: 0.0940 - recall: 0.6609 \n",
      "Epoch 55/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5858 - loss: 0.6937 - precision: 0.1015 - recall: 0.6909 \n",
      "Epoch 56/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6635 - loss: 0.6570 - precision: 0.0955 - recall: 0.5751 \n",
      "Epoch 57/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.6310 - precision: 0.0905 - recall: 0.6828 \n",
      "Epoch 58/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6096 - loss: 0.6328 - precision: 0.0851 - recall: 0.6630 \n",
      "Epoch 59/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6072 - loss: 0.6447 - precision: 0.0816 - recall: 0.6256 \n",
      "Epoch 60/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.7020 - precision: 0.0891 - recall: 0.6410 \n",
      "Epoch 61/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6916 - loss: 0.6630 - precision: 0.1044 - recall: 0.5866 \n",
      "Epoch 62/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6255 - loss: 0.6245 - precision: 0.0885 - recall: 0.6441 \n",
      "Epoch 63/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6213 - loss: 0.6567 - precision: 0.0953 - recall: 0.6831 \n",
      "Epoch 64/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 0.6551 - precision: 0.0947 - recall: 0.6444 \n",
      "Epoch 65/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6673 - loss: 0.6222 - precision: 0.0878 - recall: 0.5975 \n",
      "Epoch 66/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6116 - loss: 0.6498 - precision: 0.0939 - recall: 0.6794 \n",
      "Epoch 67/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6340 - loss: 0.6606 - precision: 0.0955 - recall: 0.6263 \n",
      "Epoch 68/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6624 - loss: 0.6339 - precision: 0.0885 - recall: 0.5779 \n",
      "Epoch 69/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.6519 - precision: 0.0815 - recall: 0.5946 \n",
      "Epoch 70/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.6655 - precision: 0.0853 - recall: 0.6254 \n",
      "Epoch 71/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6656 - loss: 0.6477 - precision: 0.1013 - recall: 0.6231 \n",
      "Epoch 72/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6123 - loss: 0.6672 - precision: 0.0890 - recall: 0.6310 \n",
      "Epoch 73/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6498 - loss: 0.6378 - precision: 0.1043 - recall: 0.6841 \n",
      "Epoch 74/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6389 - loss: 0.6514 - precision: 0.0971 - recall: 0.6322 \n",
      "Epoch 75/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.6646 - precision: 0.0885 - recall: 0.6332 \n",
      "Epoch 76/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6150 - loss: 0.6538 - precision: 0.0877 - recall: 0.6335 \n",
      "Epoch 77/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6114 - loss: 0.6414 - precision: 0.0866 - recall: 0.6500 \n",
      "Epoch 78/78\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5994 - loss: 0.6316 - precision: 0.0885 - recall: 0.6877 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b212a59bdb72421a9565017a8fe0dfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▁▄▅▇▇▆▇▆▇▆▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇██▇▇▇▇▇█▇▇█▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▂▂</td></tr><tr><td>batch/precision</td><td>▁▁▃▄▆▇▆▇▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇██▇▆▇▇█▇██▇▇</td></tr><tr><td>batch/recall</td><td>██▅▆▂▂▄▃▅▃▄▃▂▂▄▃▄▄▄▂▁▄▃▂▃▂▃▂▁▃▃▂▂▃▂▃▃▂▂▂</td></tr><tr><td>epoch/accuracy</td><td>▁▁▄▅▇▇▆▇▆▇▆▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇██▇▇▇▇▇█▇▇█▇▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▂▂</td></tr><tr><td>epoch/precision</td><td>▁▁▃▄▆▇▆▇▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇██▇▆▇▇█▇██▇▇</td></tr><tr><td>epoch/recall</td><td>██▅▆▂▂▄▃▅▃▄▃▂▂▄▃▄▄▄▂▁▄▃▂▃▂▃▂▁▃▃▂▂▃▂▃▃▂▂▂</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.59682</td></tr><tr><td>batch/accuracy</td><td>0.61605</td></tr><tr><td>batch/batch_step</td><td>623</td></tr><tr><td>batch/loss</td><td>0.64435</td></tr><tr><td>batch/precision</td><td>0.08652</td></tr><tr><td>batch/recall</td><td>0.63415</td></tr><tr><td>epoch/accuracy</td><td>0.61605</td></tr><tr><td>epoch/epoch</td><td>77</td></tr><tr><td>epoch/loss</td><td>0.64435</td></tr><tr><td>epoch/precision</td><td>0.08652</td></tr><tr><td>epoch/recall</td><td>0.63415</td></tr><tr><td>f1_score</td><td>0.1828</td></tr><tr><td>precision</td><td>0.10241</td></tr><tr><td>recall</td><td>0.85</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-10</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ra8fgluh/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ra8fgluh/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000106-ra8fgluh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1nqq805t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 69\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.05471858682154946\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000122-1nqq805t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1nqq805t/workspace' target=\"_blank\">restful-sweep-11</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1nqq805t/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1nqq805t/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5322 - loss: 0.6830 - precision: 0.0584 - recall: 0.5121         \n",
      "Epoch 2/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6107 - loss: 0.6552 - precision: 0.0796 - recall: 0.6357\n",
      "Epoch 3/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4552 - loss: 0.6648 - precision: 0.0682 - recall: 0.7437\n",
      "Epoch 4/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6020 - loss: 0.6295 - precision: 0.0703 - recall: 0.5959        \n",
      "Epoch 5/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5589 - loss: 0.6562 - precision: 0.0672 - recall: 0.5548        \n",
      "Epoch 6/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5399 - loss: 0.6932 - precision: 0.0886 - recall: 0.7093\n",
      "Epoch 7/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7233 - loss: 0.6327 - precision: 0.0976 - recall: 0.5173\n",
      "Epoch 8/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4863 - loss: 0.7244 - precision: 0.0976 - recall: 0.7562\n",
      "Epoch 9/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7072 - loss: 0.5894 - precision: 0.0742 - recall: 0.4672        \n",
      "Epoch 10/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5165 - loss: 0.6692 - precision: 0.0704 - recall: 0.6423\n",
      "Epoch 11/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6115 - loss: 0.6505 - precision: 0.0943 - recall: 0.7048\n",
      "Epoch 12/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6228 - loss: 0.6421 - precision: 0.0992 - recall: 0.6947\n",
      "Epoch 13/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5728 - loss: 0.6852 - precision: 0.0863 - recall: 0.6150        \n",
      "Epoch 14/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5742 - loss: 0.6783 - precision: 0.0893 - recall: 0.6715\n",
      "Epoch 15/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5903 - loss: 0.6720 - precision: 0.0796 - recall: 0.5992\n",
      "Epoch 16/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6098 - loss: 0.6147 - precision: 0.0656 - recall: 0.5583\n",
      "Epoch 17/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6185 - loss: 0.6480 - precision: 0.0920 - recall: 0.6652\n",
      "Epoch 18/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6675 - loss: 0.6012 - precision: 0.0998 - recall: 0.6983\n",
      "Epoch 19/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5975 - loss: 0.6555 - precision: 0.0773 - recall: 0.5769\n",
      "Epoch 20/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 0.6531 - precision: 0.0836 - recall: 0.6215        \n",
      "Epoch 21/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6450 - loss: 0.6445 - precision: 0.1027 - recall: 0.6782\n",
      "Epoch 22/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5460 - loss: 0.6804 - precision: 0.0906 - recall: 0.7060\n",
      "Epoch 23/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6962 - loss: 0.5787 - precision: 0.0957 - recall: 0.6440        \n",
      "Epoch 24/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5713 - loss: 0.6298 - precision: 0.0868 - recall: 0.7143\n",
      "Epoch 25/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5376 - loss: 0.6743 - precision: 0.0917 - recall: 0.7271\n",
      "Epoch 26/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5947 - loss: 0.6830 - precision: 0.0808 - recall: 0.5719        \n",
      "Epoch 27/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6054 - loss: 0.6786 - precision: 0.0925 - recall: 0.6322        \n",
      "Epoch 28/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6801 - loss: 0.5977 - precision: 0.1120 - recall: 0.6907        \n",
      "Epoch 29/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5733 - loss: 0.6358 - precision: 0.0876 - recall: 0.6813        \n",
      "Epoch 30/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6056 - loss: 0.6490 - precision: 0.0868 - recall: 0.6278        \n",
      "Epoch 31/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6133 - loss: 0.6298 - precision: 0.0769 - recall: 0.5765        \n",
      "Epoch 32/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6182 - loss: 0.6280 - precision: 0.0914 - recall: 0.6608\n",
      "Epoch 33/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5594 - loss: 0.6615 - precision: 0.0937 - recall: 0.7381\n",
      "Epoch 34/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6948 - loss: 0.5654 - precision: 0.0825 - recall: 0.5883\n",
      "Epoch 35/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5829 - loss: 0.6158 - precision: 0.0767 - recall: 0.6572        \n",
      "Epoch 36/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6712 - loss: 0.5949 - precision: 0.0830 - recall: 0.5932\n",
      "Epoch 37/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5853 - loss: 0.6588 - precision: 0.1084 - recall: 0.7349\n",
      "Epoch 38/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5763 - loss: 0.6093 - precision: 0.0863 - recall: 0.7587\n",
      "Epoch 39/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6396 - loss: 0.5985 - precision: 0.0869 - recall: 0.6613\n",
      "Epoch 40/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6364 - loss: 0.6455 - precision: 0.1023 - recall: 0.6977        \n",
      "Epoch 41/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6068 - loss: 0.6440 - precision: 0.0944 - recall: 0.7077        \n",
      "Epoch 42/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5802 - loss: 0.6195 - precision: 0.0677 - recall: 0.5809        \n",
      "Epoch 43/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5956 - loss: 0.6502 - precision: 0.0819 - recall: 0.6115        \n",
      "Epoch 44/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6231 - loss: 0.6162 - precision: 0.0859 - recall: 0.6302        \n",
      "Epoch 45/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5739 - loss: 0.6475 - precision: 0.0717 - recall: 0.5963        \n",
      "Epoch 46/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5804 - loss: 0.6114 - precision: 0.0825 - recall: 0.6682        \n",
      "Epoch 47/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6611 - loss: 0.5903 - precision: 0.0945 - recall: 0.6468\n",
      "Epoch 48/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6152 - loss: 0.5498 - precision: 0.0852 - recall: 0.8011        \n",
      "Epoch 49/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5461 - loss: 0.5978 - precision: 0.0719 - recall: 0.7156\n",
      "Epoch 50/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6044 - loss: 0.6595 - precision: 0.1167 - recall: 0.7508\n",
      "Epoch 51/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6962 - loss: 0.5295 - precision: 0.0795 - recall: 0.6079        \n",
      "Epoch 52/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5881 - loss: 0.5956 - precision: 0.0994 - recall: 0.7816        \n",
      "Epoch 53/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6329 - loss: 0.6247 - precision: 0.1121 - recall: 0.7358\n",
      "Epoch 54/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6375 - loss: 0.5725 - precision: 0.0866 - recall: 0.6735\n",
      "Epoch 55/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6317 - loss: 0.5774 - precision: 0.0913 - recall: 0.7218\n",
      "Epoch 56/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5997 - loss: 0.5974 - precision: 0.0873 - recall: 0.7181        \n",
      "Epoch 57/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6181 - loss: 0.5661 - precision: 0.0928 - recall: 0.7789\n",
      "Epoch 58/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5607 - loss: 0.6483 - precision: 0.1116 - recall: 0.8259\n",
      "Epoch 59/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6901 - loss: 0.6052 - precision: 0.1011 - recall: 0.6365\n",
      "Epoch 60/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6054 - loss: 0.5915 - precision: 0.0916 - recall: 0.7649\n",
      "Epoch 61/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5792 - loss: 0.5992 - precision: 0.0958 - recall: 0.7802\n",
      "Epoch 62/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5944 - loss: 0.6004 - precision: 0.0909 - recall: 0.7496\n",
      "Epoch 63/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6524 - loss: 0.6060 - precision: 0.1060 - recall: 0.6912\n",
      "Epoch 64/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5718 - loss: 0.6751 - precision: 0.1034 - recall: 0.7234\n",
      "Epoch 65/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7144 - loss: 0.5405 - precision: 0.1104 - recall: 0.7228\n",
      "Epoch 66/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6378 - loss: 0.5620 - precision: 0.0869 - recall: 0.7029        \n",
      "Epoch 67/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6090 - loss: 0.6039 - precision: 0.0933 - recall: 0.7209        \n",
      "Epoch 68/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5542 - loss: 0.6140 - precision: 0.0916 - recall: 0.7813\n",
      "Epoch 69/69\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5947 - loss: 0.6075 - precision: 0.0958 - recall: 0.7473        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01caaa5e16e34c898201cde84b80f018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▄▁▆█▃▄█▆▆▇█▆▆▆▅▇▅▇▇█▆▆▇▆▆▆▆▇▆█▆▆▇▆▇▇▆▇▇█</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▄▃▆█▄▅▄▅▄▃▅▅▄▅▄▅▅▄▃▅▄▄▅▄▅▄▄▄▄▄▄▄▄▄▄▄▄▂▁</td></tr><tr><td>batch/precision</td><td>▇▃▁▇█▃█▅▄▅▆▄▅▄▆▅▅▅▅▃▅▅▅▅▄▄▄▅▄▅▅▅▅▅▅▅▅▅▆▃</td></tr><tr><td>batch/recall</td><td>██▁▃▇▄▆▅▃▄▅▄▅▅▆▄▅▅▅▂▅▅▅▅▄▄▅▅▅▄▅▅▅▅▅▅▅▅██</td></tr><tr><td>epoch/accuracy</td><td>▁▇▄▃██▄▅▅▃▆▅▅█▃▆▄▃▇█▄▅▆▅▃▃▂▄▂▇▅▅▅▃▆▅▆██▅</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>epoch/precision</td><td>▁▅▄▅▆▅▆▄▅▄▆▅▅▇▅▆▅▄▆▆▆▅▇▆▅▅▆▆▆▇▆▆▆▆▆▇▇██▇</td></tr><tr><td>epoch/recall</td><td>▁▃▅▅▄▄▆▄▅▄▆▅▆▅▆▅▆▅▅▅▇▅▇▇▇▅▇▇▇▆▆▇▇█▆█▇▇▇▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.67905</td></tr><tr><td>batch/accuracy</td><td>0.61074</td></tr><tr><td>batch/batch_step</td><td>4346</td></tr><tr><td>batch/loss</td><td>0.60622</td></tr><tr><td>batch/precision</td><td>0.096</td></tr><tr><td>batch/recall</td><td>0.73171</td></tr><tr><td>epoch/accuracy</td><td>0.61074</td></tr><tr><td>epoch/epoch</td><td>68</td></tr><tr><td>epoch/loss</td><td>0.60622</td></tr><tr><td>epoch/precision</td><td>0.096</td></tr><tr><td>epoch/recall</td><td>0.73171</td></tr><tr><td>f1_score</td><td>0.18792</td></tr><tr><td>precision</td><td>0.10853</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-11</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1nqq805t/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1nqq805t/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000122-1nqq805t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zvab4fyl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.09279203621849225\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000155-zvab4fyl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/zvab4fyl/workspace' target=\"_blank\">rare-sweep-12</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/zvab4fyl/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/zvab4fyl/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6883 - loss: 0.4542 - precision: 0.0714 - recall: 0.3281\n",
      "Epoch 2/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.2126 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.2152 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1928 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2199 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9374 - loss: 0.2321 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.2088 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2208 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1966 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2147 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.2007 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.2194 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1921 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.2309 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1903 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2193 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1999 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2200 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.1976 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1965 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2032 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2149 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1949 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1861 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1893 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.2071 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2057 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.1981 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2122 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1942 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9378 - loss: 0.2193 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1923 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.2106 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.2058 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/45\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.2039 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59597b60376449bb8c704752234e2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▇▇█▇▇▇███▇▇█▇██▇▇▇█▇██▇███▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▂▂▂▂▃▃▂▂▂▂▂▂▁▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▂▄▂▂▂▂▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>404</td></tr><tr><td>batch/loss</td><td>0.2001</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>44</td></tr><tr><td>epoch/loss</td><td>0.2001</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-sweep-12</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/zvab4fyl/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/zvab4fyl/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000155-zvab4fyl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gjhhryng with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.024274842414202344\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000212-gjhhryng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/gjhhryng/workspace' target=\"_blank\">fallen-sweep-13</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/gjhhryng/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/gjhhryng/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4679 - loss: 0.7128 - precision: 0.0353 - recall: 0.4093\n",
      "Epoch 2/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5014 - loss: 0.6985 - precision: 0.0746 - recall: 0.6502 \n",
      "Epoch 3/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5466 - loss: 0.6613 - precision: 0.0782 - recall: 0.6440 \n",
      "Epoch 4/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.6314 - precision: 0.0887 - recall: 0.5653 \n",
      "Epoch 5/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5336 - loss: 0.6525 - precision: 0.0782 - recall: 0.7055 \n",
      "Epoch 6/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6520 - loss: 0.6366 - precision: 0.0931 - recall: 0.6383 \n",
      "Epoch 7/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4890 - loss: 0.6406 - precision: 0.0666 - recall: 0.6892 \n",
      "Epoch 8/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6844 - loss: 0.6089 - precision: 0.1031 - recall: 0.6452 \n",
      "Epoch 9/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4350 - loss: 0.6889 - precision: 0.0808 - recall: 0.8003 \n",
      "Epoch 10/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7122 - loss: 0.6779 - precision: 0.1122 - recall: 0.5209 \n",
      "Epoch 11/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5711 - loss: 0.6444 - precision: 0.0894 - recall: 0.6921 \n",
      "Epoch 12/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6610 - loss: 0.6708 - precision: 0.0977 - recall: 0.5701 \n",
      "Epoch 13/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6398 - loss: 0.6021 - precision: 0.0789 - recall: 0.6146 \n",
      "Epoch 14/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4715 - loss: 0.6853 - precision: 0.0802 - recall: 0.7447 \n",
      "Epoch 15/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6636 - loss: 0.6145 - precision: 0.0849 - recall: 0.5421 \n",
      "Epoch 16/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4171 - loss: 0.6252 - precision: 0.0692 - recall: 0.8452 \n",
      "Epoch 17/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5769 - loss: 0.5959 - precision: 0.0857 - recall: 0.7396 \n",
      "Epoch 18/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5488 - loss: 0.6188 - precision: 0.0843 - recall: 0.7454 \n",
      "Epoch 19/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 0.6266 - precision: 0.1160 - recall: 0.8155 \n",
      "Epoch 20/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3776 - loss: 0.6932 - precision: 0.0803 - recall: 0.8726 \n",
      "Epoch 21/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.5976 - precision: 0.0907 - recall: 0.5337 \n",
      "Epoch 22/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4786 - loss: 0.6420 - precision: 0.0791 - recall: 0.7821 \n",
      "Epoch 23/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8360 - loss: 0.6428 - precision: 0.0779 - recall: 0.1896         \n",
      "Epoch 24/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5580 - loss: 0.6119 - precision: 0.0809 - recall: 0.7595 \n",
      "Epoch 25/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5187 - loss: 0.6427 - precision: 0.0909 - recall: 0.8228 \n",
      "Epoch 26/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5297 - loss: 0.6125 - precision: 0.0856 - recall: 0.8166 \n",
      "Epoch 27/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4792 - loss: 0.6274 - precision: 0.0870 - recall: 0.8649 \n",
      "Epoch 28/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5595 - loss: 0.6028 - precision: 0.0921 - recall: 0.7961 \n",
      "Epoch 29/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5913 - loss: 0.6067 - precision: 0.0885 - recall: 0.7177 \n",
      "Epoch 30/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4835 - loss: 0.6383 - precision: 0.0901 - recall: 0.8530 \n",
      "Epoch 31/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5424 - loss: 0.6477 - precision: 0.0914 - recall: 0.7455 \n",
      "Epoch 32/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6698 - loss: 0.5923 - precision: 0.0946 - recall: 0.6285 \n",
      "Epoch 33/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3471 - loss: 0.6148 - precision: 0.0692 - recall: 0.9477 \n",
      "Epoch 34/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5067 - loss: 0.6233 - precision: 0.0805 - recall: 0.7742 \n",
      "Epoch 35/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4458 - loss: 0.5872 - precision: 0.0766 - recall: 0.8596 \n",
      "Epoch 36/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3562 - loss: 0.6239 - precision: 0.0622 - recall: 0.8396 \n",
      "Epoch 37/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7031 - loss: 0.5860 - precision: 0.0939 - recall: 0.5910 \n",
      "Epoch 38/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6728 - loss: 0.6106 - precision: 0.0870 - recall: 0.5246 \n",
      "Epoch 39/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6045 - loss: 0.5754 - precision: 0.0926 - recall: 0.7610 \n",
      "Epoch 40/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6151 - loss: 0.6004 - precision: 0.0877 - recall: 0.6632 \n",
      "Epoch 41/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 0.6173 - precision: 0.1007 - recall: 0.6801 \n",
      "Epoch 42/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6047 - loss: 0.5898 - precision: 0.0950 - recall: 0.7421 \n",
      "Epoch 43/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5652 - loss: 0.6070 - precision: 0.0827 - recall: 0.6637 \n",
      "Epoch 44/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.6210 - precision: 0.0888 - recall: 0.7044 \n",
      "Epoch 45/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6733 - loss: 0.6099 - precision: 0.1107 - recall: 0.6975 \n",
      "Epoch 46/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5541 - loss: 0.6263 - precision: 0.0876 - recall: 0.7045 \n",
      "Epoch 47/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5383 - loss: 0.6237 - precision: 0.0945 - recall: 0.7811 \n",
      "Epoch 48/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6550 - loss: 0.5523 - precision: 0.0907 - recall: 0.6726 \n",
      "Epoch 49/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3139 - loss: 0.6212 - precision: 0.0686 - recall: 0.9230 \n",
      "Epoch 50/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5166 - loss: 0.6173 - precision: 0.0918 - recall: 0.8403 \n",
      "Epoch 51/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5981 - loss: 0.5618 - precision: 0.0856 - recall: 0.7319 \n",
      "Epoch 52/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5805 - loss: 0.6391 - precision: 0.0988 - recall: 0.7294 \n",
      "Epoch 53/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6394 - loss: 0.6423 - precision: 0.1007 - recall: 0.6389 \n",
      "Epoch 54/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5678 - loss: 0.6031 - precision: 0.0873 - recall: 0.7371 \n",
      "Epoch 55/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6407 - loss: 0.5828 - precision: 0.0958 - recall: 0.6847 \n",
      "Epoch 56/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5095 - loss: 0.5838 - precision: 0.0919 - recall: 0.8973 \n",
      "Epoch 57/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6271 - loss: 0.5755 - precision: 0.0960 - recall: 0.7459 \n",
      "Epoch 58/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4265 - loss: 0.6145 - precision: 0.0774 - recall: 0.8609 \n",
      "Epoch 59/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6082 - loss: 0.6009 - precision: 0.0928 - recall: 0.7605 \n",
      "Epoch 60/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5247 - loss: 0.6277 - precision: 0.0894 - recall: 0.8149 \n",
      "Epoch 61/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5925 - precision: 0.1018 - recall: 0.5287 \n",
      "Epoch 62/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4553 - loss: 0.6075 - precision: 0.0733 - recall: 0.8419 \n",
      "Epoch 63/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6400 - loss: 0.5788 - precision: 0.0968 - recall: 0.6970 \n",
      "Epoch 64/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4161 - loss: 0.6398 - precision: 0.0748 - recall: 0.8611 \n",
      "Epoch 65/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4915 - loss: 0.6006 - precision: 0.0773 - recall: 0.8072 \n",
      "Epoch 66/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6272 - loss: 0.6188 - precision: 0.1067 - recall: 0.7186 \n",
      "Epoch 67/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5480 - loss: 0.5543 - precision: 0.0792 - recall: 0.7938 \n",
      "Epoch 68/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5033 - loss: 0.5683 - precision: 0.0723 - recall: 0.8306 \n",
      "Epoch 69/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4859 - loss: 0.6248 - precision: 0.0826 - recall: 0.8190 \n",
      "Epoch 70/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6012 - loss: 0.5699 - precision: 0.0912 - recall: 0.7947 \n",
      "Epoch 71/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4996 - loss: 0.5906 - precision: 0.0897 - recall: 0.8861 \n",
      "Epoch 72/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5560 - loss: 0.6013 - precision: 0.0889 - recall: 0.7892 \n",
      "Epoch 73/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.5431 - precision: 0.0875 - recall: 0.7083 \n",
      "Epoch 74/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4873 - loss: 0.6238 - precision: 0.0873 - recall: 0.8511 \n",
      "Epoch 75/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6224 - loss: 0.6214 - precision: 0.1103 - recall: 0.7514 \n",
      "Epoch 76/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5865 - loss: 0.5981 - precision: 0.1130 - recall: 0.8784 \n",
      "Epoch 77/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6225 - loss: 0.5623 - precision: 0.0824 - recall: 0.6450 \n",
      "Epoch 78/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3984 - loss: 0.5980 - precision: 0.0732 - recall: 0.8938 \n",
      "Epoch 79/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 0.6563 - precision: 0.1049 - recall: 0.6897 \n",
      "Epoch 80/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.5970 - precision: 0.1030 - recall: 0.7514 \n",
      "Epoch 81/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5626 - loss: 0.5678 - precision: 0.0821 - recall: 0.7948 \n",
      "Epoch 82/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5946 - loss: 0.5593 - precision: 0.0991 - recall: 0.8497 \n",
      "Epoch 83/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6007 - loss: 0.5655 - precision: 0.1039 - recall: 0.8511 \n",
      "Epoch 84/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5981 - loss: 0.5581 - precision: 0.0804 - recall: 0.7526 \n",
      "Epoch 85/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5724 - loss: 0.6069 - precision: 0.1040 - recall: 0.7987 \n",
      "Epoch 86/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6012 - loss: 0.5755 - precision: 0.0993 - recall: 0.8160 \n",
      "Epoch 87/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.5973 - precision: 0.0977 - recall: 0.7553 \n",
      "Epoch 88/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5731 - loss: 0.5893 - precision: 0.1022 - recall: 0.8631 \n",
      "Epoch 89/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5756 - loss: 0.5752 - precision: 0.0880 - recall: 0.7843 \n",
      "Epoch 90/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 0.6063 - precision: 0.1119 - recall: 0.7483 \n",
      "Epoch 91/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6299 - loss: 0.5836 - precision: 0.0887 - recall: 0.6487 \n",
      "Epoch 92/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5818 - loss: 0.5665 - precision: 0.0954 - recall: 0.8032 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a0cf7b0a9c487e85afcd9fb7057316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▄▆█▇▆█▅▅▂▅▅▆▅▁▂▇▆▅▇▅▁▅▆▄▆▃▄▆▄▄▆▆▂▆▆▅▅▅▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▅▃▆▄▆▄▅▅▅▄▆▃▅▅▄▄▃▅▁▅▆▄▄▅▄▄▄▂▁▃▅▄▇▂▄▄▃▂</td></tr><tr><td>batch/precision</td><td>▁▂▄█▄▃▄▃▄▃▃▃▄▄▂▂▄▄▃▅▂▂▄▄▃▄▂▂▅▂▃▄▅▂▇▄▅▅▄▄</td></tr><tr><td>batch/recall</td><td>▂▅▄▇▃▄▁▅▅▇▅▅▃▇▇▇▂▄▄▄▃▇▅▅▆▅▆▅▅▆█▄▄▇▆▅▆▆▆▆</td></tr><tr><td>epoch/accuracy</td><td>▃▄▆▇▇▇▆▅▆▆▆▅▅▄▁▄▇▆▇▇▅▆▅▅█▆█▂▇▅▄▇▇▄▇▇▆▆▅▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▅▄▄▄▄▃▃▃▄▄▃▃▃▃▄▂▂▂▂▁▂▂▂▂▃▂▃▂▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▄▆▆▆▆▅▅▆▅▆▆▅▅▄▄▆▆▆▇▆▇▆▆█▇▇▄▇▆▅▆▇▅▇▇▇▇▇▇</td></tr><tr><td>epoch/recall</td><td>▁▅▄▂▂▃▃▅▅▃▅▅▅▇█▄▃▄▄▄▆▅▆▆▄▆▂█▄▆▆▄▄▇▄▅▆▅▆▅</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58621</td></tr><tr><td>batch/accuracy</td><td>0.59947</td></tr><tr><td>batch/batch_step</td><td>827</td></tr><tr><td>batch/loss</td><td>0.58556</td></tr><tr><td>batch/precision</td><td>0.09472</td></tr><tr><td>batch/recall</td><td>0.7439</td></tr><tr><td>epoch/accuracy</td><td>0.59947</td></tr><tr><td>epoch/epoch</td><td>91</td></tr><tr><td>epoch/loss</td><td>0.58556</td></tr><tr><td>epoch/precision</td><td>0.09472</td></tr><tr><td>epoch/recall</td><td>0.7439</td></tr><tr><td>f1_score</td><td>0.15217</td></tr><tr><td>precision</td><td>0.08537</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fallen-sweep-13</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/gjhhryng/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/gjhhryng/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000212-gjhhryng/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xhw1cemp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 34\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0593800201799622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000227-xhw1cemp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/xhw1cemp/workspace' target=\"_blank\">young-sweep-14</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/xhw1cemp/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/xhw1cemp/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5202 - loss: 0.7700 - precision: 0.0732 - recall: 0.6074\n",
      "Epoch 2/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0588 - loss: 0.7089 - precision: 0.0567 - recall: 0.9956 \n",
      "Epoch 3/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.6771 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4832 - loss: 0.7153 - precision: 0.0453 - recall: 0.4743         \n",
      "Epoch 5/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3320 - loss: 0.7435 - precision: 0.0596 - recall: 0.6403 \n",
      "Epoch 6/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6075 - loss: 0.7479 - precision: 0.0378 - recall: 0.3310         \n",
      "Epoch 7/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.6731 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2221 - loss: 0.7184 - precision: 0.0540 - recall: 0.7883         \n",
      "Epoch 9/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8118 - loss: 0.6830 - precision: 0.0360 - recall: 0.1472         \n",
      "Epoch 10/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4943 - loss: 0.6616 - precision: 0.0343 - recall: 0.4063         \n",
      "Epoch 11/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8264 - loss: 0.6275 - precision: 0.0144 - recall: 0.0659         \n",
      "Epoch 12/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0527 - loss: 0.6878 - precision: 0.0527 - recall: 1.0000 \n",
      "Epoch 13/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4722 - loss: 0.6954 - precision: 0.0528 - recall: 0.5147 \n",
      "Epoch 14/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5583 - loss: 0.6932 - precision: 0.0410 - recall: 0.4027         \n",
      "Epoch 15/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5949 - loss: 0.6970 - precision: 0.0387 - recall: 0.2984         \n",
      "Epoch 16/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1423 - loss: 0.7088 - precision: 0.0569 - recall: 0.9036 \n",
      "Epoch 17/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6500 - loss: 0.6999 - precision: 0.0297 - recall: 0.2681         \n",
      "Epoch 18/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.6931 - precision: 0.0454 - recall: 0.1591 \n",
      "Epoch 19/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6411 - loss: 0.6942 - precision: 0.0303 - recall: 0.2290         \n",
      "Epoch 20/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1751 - loss: 0.6785 - precision: 0.0456 - recall: 0.7668 \n",
      "Epoch 21/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8735 - loss: 0.6724 - precision: 0.0189 - recall: 0.0471         \n",
      "Epoch 22/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2446 - loss: 0.6784 - precision: 0.0493 - recall: 0.7575 \n",
      "Epoch 23/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4142 - loss: 0.7191 - precision: 0.0486 - recall: 0.5670         \n",
      "Epoch 24/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5804 - loss: 0.6706 - precision: 0.0459 - recall: 0.3999 \n",
      "Epoch 25/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0555 - loss: 0.7005 - precision: 0.0555 - recall: 1.0000 \n",
      "Epoch 26/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1620 - loss: 0.7313 - precision: 0.0596 - recall: 0.8712 \n",
      "Epoch 27/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8935 - loss: 0.6701 - precision: 0.0180 - recall: 0.0615         \n",
      "Epoch 28/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4207 - loss: 0.6632 - precision: 0.0449 - recall: 0.5569 \n",
      "Epoch 29/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6694 - loss: 0.6330 - precision: 0.0339 - recall: 0.2650         \n",
      "Epoch 30/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0576 - loss: 0.7142 - precision: 0.0576 - recall: 1.0000 \n",
      "Epoch 31/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4626 - loss: 0.7216 - precision: 0.0485 - recall: 0.4636 \n",
      "Epoch 32/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7770 - loss: 0.7185 - precision: 0.0243 - recall: 0.1366         \n",
      "Epoch 33/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.7219 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/34\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.6898 - precision: 0.0121 - recall: 0.0175         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ea29697f114269b55a201653d49e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▆▄▁█▄▃▇█▃▃▆▃▇▁▁█▄▅▂▅▆█▅▃▇▃▃▅▁▁▃█▅▄▁▅█▆█▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▆▅▄▆▅▆▃▅▅▄▄▁▄▇▁▅▅▅▅▆▆▅▅▅▃▆▃▄█▅▅▄▂▇▇▄▅▅▄</td></tr><tr><td>batch/precision</td><td>█▆▆▁▆▅▄▁▅▅▅▅▁▅▆▁▅▅▅▅▅▁▅▄▂▅▆▅▅▇▅▁▄▄▆▅▁▄▁▄</td></tr><tr><td>batch/recall</td><td>▄▆█▁▅▆▁▁▅▆▃▅▁██▁▅▃▇▄▂▁▃▅▁▆▆▃██▆▁▄▄█▃▁▃▁▁</td></tr><tr><td>epoch/accuracy</td><td>▃▁█▂▃▃█▃▇▅▆▁▆▄▄▄▃▇▅▄▆▅▂▇▁▄▆▆▆▁▃▆█▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▁▁▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▂▂▂▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▇▁▇▇▇▁▇▇▆▇▇▇▇▆█▇▅▆▆▆▆▇▆▇▇▇▆▇▇▇▆▁▅</td></tr><tr><td>epoch/recall</td><td>▆█▁▆▅▅▁▆▂▃▃█▂▅▄▅▅▂▃▄▂▄▇▂█▅▃▂▃█▅▃▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.87666</td></tr><tr><td>batch/batch_step</td><td>917</td></tr><tr><td>batch/loss</td><td>0.69377</td></tr><tr><td>batch/precision</td><td>0.03571</td></tr><tr><td>batch/recall</td><td>0.04878</td></tr><tr><td>epoch/accuracy</td><td>0.87666</td></tr><tr><td>epoch/epoch</td><td>33</td></tr><tr><td>epoch/loss</td><td>0.69377</td></tr><tr><td>epoch/precision</td><td>0.03571</td></tr><tr><td>epoch/recall</td><td>0.04878</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-sweep-14</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/xhw1cemp/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/xhw1cemp/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000227-xhw1cemp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tag1w1yr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 28\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02402220189753354\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000242-tag1w1yr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tag1w1yr/workspace' target=\"_blank\">sage-sweep-15</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tag1w1yr/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/tag1w1yr/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5405 - loss: 0.7045 - precision: 0.0514 - recall: 0.4576\n",
      "Epoch 2/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0864 - loss: 0.6679 - precision: 0.0536 - recall: 1.0000 \n",
      "Epoch 3/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8566 - loss: 0.6678 - precision: 0.0591 - recall: 0.1206 \n",
      "Epoch 4/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4725 - loss: 0.6355 - precision: 0.0688 - recall: 0.7916 \n",
      "Epoch 5/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5400 - loss: 0.6467 - precision: 0.0767 - recall: 0.6791 \n",
      "Epoch 6/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5956 - loss: 0.6530 - precision: 0.1013 - recall: 0.7349 \n",
      "Epoch 7/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5535 - loss: 0.6444 - precision: 0.0808 - recall: 0.7202 \n",
      "Epoch 8/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6418 - loss: 0.6261 - precision: 0.0863 - recall: 0.5922 \n",
      "Epoch 9/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4756 - loss: 0.6589 - precision: 0.0729 - recall: 0.7363 \n",
      "Epoch 10/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6505 - loss: 0.6716 - precision: 0.0780 - recall: 0.4875 \n",
      "Epoch 11/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7589 - loss: 0.6430 - precision: 0.1056 - recall: 0.4677 \n",
      "Epoch 12/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4918 - loss: 0.6372 - precision: 0.0766 - recall: 0.7502 \n",
      "Epoch 13/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.6085 - precision: 0.0942 - recall: 0.4861 \n",
      "Epoch 14/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4101 - loss: 0.6776 - precision: 0.0758 - recall: 0.7961 \n",
      "Epoch 15/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7684 - loss: 0.6663 - precision: 0.1225 - recall: 0.4651 \n",
      "Epoch 16/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5017 - loss: 0.6486 - precision: 0.0826 - recall: 0.7481 \n",
      "Epoch 17/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7511 - loss: 0.6035 - precision: 0.0714 - recall: 0.3459 \n",
      "Epoch 18/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2103 - loss: 0.6984 - precision: 0.0675 - recall: 0.9741 \n",
      "Epoch 19/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3949 - loss: 0.6804 - precision: 0.0788 - recall: 0.8674 \n",
      "Epoch 20/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6967 - loss: 0.6445 - precision: 0.0984 - recall: 0.5669 \n",
      "Epoch 21/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4345 - loss: 0.6658 - precision: 0.0847 - recall: 0.8466 \n",
      "Epoch 22/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6490 - loss: 0.6878 - precision: 0.0894 - recall: 0.5618 \n",
      "Epoch 23/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5009 - loss: 0.6363 - precision: 0.0783 - recall: 0.7641 \n",
      "Epoch 24/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5533 - loss: 0.6425 - precision: 0.0875 - recall: 0.7273 \n",
      "Epoch 25/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4836 - loss: 0.6357 - precision: 0.0728 - recall: 0.7567 \n",
      "Epoch 26/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5647 - loss: 0.6433 - precision: 0.0994 - recall: 0.8129 \n",
      "Epoch 27/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6444 - loss: 0.6318 - precision: 0.1029 - recall: 0.6829 \n",
      "Epoch 28/28\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6050 - loss: 0.6307 - precision: 0.0864 - recall: 0.6428 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd41f5987724e05bebb3e301a2540c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▅▅▁▇█▄▅▅▅▅▆▅▅▆▅▆▅▇▆▃▇▅▄▇▃▂▄▇▆▄▆▄▅▅▅▅▅▆▅▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▇█▅▇▆▆▇▆▆▄▇▇▇▆▆▆▁▆▆▇▅▆▃█▇▇█▆▆▆▅▅▆█▇▆▆▅▅</td></tr><tr><td>batch/precision</td><td>▁▂▂▁▄▄▃▇▅▄▅▄▄▅▄▆▃▃▅▃▆▅▄▃▅▂▄▆▅▄▅▃▄▄▄█▅▆▄▄</td></tr><tr><td>batch/recall</td><td>▄▄█▂▁▇▆▆▆▆▅▅▆▄▅▄▆▄▅▇▃▆▆▃▇█▇▄▅▇▅▆▆▆▅▇▆▅▅▆</td></tr><tr><td>epoch/accuracy</td><td>▅▁█▄▅▆▅▅▅▅▆▅▆▄▆▄▇▂▄▆▄▆▅▅▄▅▅▅</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▅▇▅▃▄▅▅▃▃▄▂▃▃▄▃▆▅▄▃▂▃▄▄▃▂▃▁</td></tr><tr><td>epoch/precision</td><td>▂▁▃▄▅▇▅▄▅▄█▅▇▄█▄▆▂▄▆▄▆▅▅▄▇▆▅</td></tr><tr><td>epoch/recall</td><td>▄█▁▆▅▆▆▅▆▅▄▅▅▆▅▆▃█▆▅▇▅▆▆▇▆▅▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.59151</td></tr><tr><td>batch/accuracy</td><td>0.58289</td></tr><tr><td>batch/batch_step</td><td>251</td></tr><tr><td>batch/loss</td><td>0.59852</td></tr><tr><td>batch/precision</td><td>0.08498</td></tr><tr><td>batch/recall</td><td>0.68293</td></tr><tr><td>epoch/accuracy</td><td>0.58289</td></tr><tr><td>epoch/epoch</td><td>27</td></tr><tr><td>epoch/loss</td><td>0.59852</td></tr><tr><td>epoch/precision</td><td>0.08498</td></tr><tr><td>epoch/recall</td><td>0.68293</td></tr><tr><td>f1_score</td><td>0.17204</td></tr><tr><td>precision</td><td>0.09639</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sage-sweep-15</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tag1w1yr/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/tag1w1yr/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000242-tag1w1yr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kirgprkr with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 160\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02258866371793687\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000305-kirgprkr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kirgprkr/workspace' target=\"_blank\">amber-sweep-16</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kirgprkr/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kirgprkr/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9447 - loss: 0.3248 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.2167 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1892 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.2044 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1988 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1972 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1860 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.2106 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.1969 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1914 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1900 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1915 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.2268 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.2005 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.2095 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2007 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/26\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caea7ba5212646a198c2b9d5e81a3130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▂▄▂▃▃▁▃▄▃▃▄▄▃▄▅▃▄▅▃▄▆▃▃█▃▄▄▃▂▆▃▃▄▃▃▅▃▅▁▃</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▅▄▄▅▄▄▄▄▃▃▄▃▃▄▃▃▃▃▃▄▄▁▄▃▃▄▄▂▄▄▃▃▄▃▃▃▄▄</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▂▃▂▂▃▂▂▁▂▂▁▂▂▁▂▂▂▁▂▂▁▂▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>259</td></tr><tr><td>batch/loss</td><td>0.20048</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>25</td></tr><tr><td>epoch/loss</td><td>0.20048</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">amber-sweep-16</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kirgprkr/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kirgprkr/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000305-kirgprkr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 715sssgq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 23\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 4.5769844588491824e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000326-715sssgq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/715sssgq/workspace' target=\"_blank\">breezy-sweep-17</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/715sssgq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/715sssgq/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0563 - loss: 0.8424 - precision: 0.0563 - recall: 1.0000\n",
      "Epoch 2/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0468 - loss: 0.8431 - precision: 0.0468 - recall: 1.0000 \n",
      "Epoch 3/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0538 - loss: 0.8382 - precision: 0.0538 - recall: 1.0000 \n",
      "Epoch 4/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0556 - loss: 0.8372 - precision: 0.0556 - recall: 1.0000 \n",
      "Epoch 5/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0413 - loss: 0.8386 - precision: 0.0413 - recall: 1.0000 \n",
      "Epoch 6/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0601 - loss: 0.8323 - precision: 0.0601 - recall: 1.0000 \n",
      "Epoch 7/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0605 - loss: 0.8303 - precision: 0.0605 - recall: 1.0000 \n",
      "Epoch 8/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0495 - loss: 0.8307 - precision: 0.0495 - recall: 1.0000 \n",
      "Epoch 9/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0516 - loss: 0.8290 - precision: 0.0516 - recall: 1.0000 \n",
      "Epoch 10/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0604 - loss: 0.8234 - precision: 0.0604 - recall: 1.0000 \n",
      "Epoch 11/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0560 - loss: 0.8253 - precision: 0.0560 - recall: 1.0000 \n",
      "Epoch 12/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0508 - loss: 0.8236 - precision: 0.0508 - recall: 0.9600             \n",
      "Epoch 13/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0485 - loss: 0.8231 - precision: 0.0485 - recall: 1.0000 \n",
      "Epoch 14/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0601 - loss: 0.8163 - precision: 0.0601 - recall: 1.0000 \n",
      "Epoch 15/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0418 - loss: 0.8207 - precision: 0.0418 - recall: 0.9600             \n",
      "Epoch 16/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0553 - loss: 0.8161 - precision: 0.0553 - recall: 1.0000 \n",
      "Epoch 17/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0489 - loss: 0.8152 - precision: 0.0489 - recall: 1.0000 \n",
      "Epoch 18/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0588 - loss: 0.8118 - precision: 0.0588 - recall: 1.0000 \n",
      "Epoch 19/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0577 - loss: 0.8107 - precision: 0.0577 - recall: 1.0000 \n",
      "Epoch 20/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0562 - loss: 0.8085 - precision: 0.0562 - recall: 1.0000 \n",
      "Epoch 21/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0566 - loss: 0.8071 - precision: 0.0566 - recall: 1.0000 \n",
      "Epoch 22/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0474 - loss: 0.8064 - precision: 0.0474 - recall: 1.0000\n",
      "Epoch 23/23\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0578 - loss: 0.8035 - precision: 0.0578 - recall: 1.0000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d055def6164c5c81030c4fad0bea9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▅▆▃▅▄▅▆▁▅█▅▆▅▆▆▅█▅▆▆▇▄▅▆▅▅▆▅▆▅▅█▆▇▅▆▅▅▇▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>███▇▇▇▆▇▇▆▆▆▆▅▅▅▄▅▄▄▄▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁</td></tr><tr><td>batch/precision</td><td>▅▆▃▅▄▅▆▁▅█▅▆▅▆▆▅█▅▆▆▇▄▅▆▅▅▆▅▆▅▅█▆▇▅▆▅▅▇▅</td></tr><tr><td>batch/recall</td><td>███▁█▁████▁█▁██▁█▁████▁█▁▁█▁█▁█▁██▁█▁██▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>epoch/loss</td><td>██▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.05305</td></tr><tr><td>batch/accuracy</td><td>0.05438</td></tr><tr><td>batch/batch_step</td><td>551</td></tr><tr><td>batch/loss</td><td>0.80381</td></tr><tr><td>batch/precision</td><td>0.05438</td></tr><tr><td>batch/recall</td><td>1.0</td></tr><tr><td>epoch/accuracy</td><td>0.05438</td></tr><tr><td>epoch/epoch</td><td>22</td></tr><tr><td>epoch/loss</td><td>0.80381</td></tr><tr><td>epoch/precision</td><td>0.05438</td></tr><tr><td>epoch/recall</td><td>1.0</td></tr><tr><td>f1_score</td><td>0.10076</td></tr><tr><td>precision</td><td>0.05305</td></tr><tr><td>recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-sweep-17</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/715sssgq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/715sssgq/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000326-715sssgq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: txjm6247 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 44\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.030360553576684914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000342-txjm6247</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/txjm6247/workspace' target=\"_blank\">still-sweep-18</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/txjm6247/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/txjm6247/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9343 - loss: 0.3210 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 2/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2223 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9345 - loss: 0.2321 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.2158 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.2280 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.2231 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.2169 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2123 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2048 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1845 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2102 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2141 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.2294 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9321 - loss: 0.2423 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1996 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1916 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.2058 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2185 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.2058 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1838 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9360 - loss: 0.2218 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1794 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9371 - loss: 0.2288 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2052 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1865 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1730 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2068 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.2006 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.2283 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2152 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.2262 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/44\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a322140555094c3d9b1da762baccd091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▃▂▄▄▄▄▄▄▄▄▆▃▄▄▄▄▄▄▃▃▃▄▄▄▄▁▃▄▅█▄▄▄▄▂▃▄▂▄</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▄▄▄▃▃▃▃▃▃▂▄▃▃▄▃▃▄▃▄▄▃▃▃▃▅▄▃▂▁▄▄▃▃▄▄▃▄▃</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▂▂▃▂▂▂▂▂▂▁▂▂▂▃▂▂▂▂▁▂▁▂▁▁▂▁▂▂▁▃▂▂▁▁▁▂▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>1407</td></tr><tr><td>batch/loss</td><td>0.2013</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>43</td></tr><tr><td>epoch/loss</td><td>0.2013</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">still-sweep-18</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/txjm6247/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/txjm6247/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000342-txjm6247/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kbz4orr4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.07974109527173756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000357-kbz4orr4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kbz4orr4/workspace' target=\"_blank\">rare-sweep-19</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kbz4orr4/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kbz4orr4/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.7490 - loss: 0.7061 - precision: 0.0540 - recall: 0.1916\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7432 - loss: 0.7221 - precision: 0.0545 - recall: 0.1939 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.6752 - precision: 0.0502 - recall: 0.0686         \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.6899 - precision: 0.0552 - recall: 0.2801 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3614 - loss: 0.7059 - precision: 0.0566 - recall: 0.6465 \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6165 - loss: 0.6892 - precision: 0.0626 - recall: 0.4266 \n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6229 - loss: 0.6782 - precision: 0.0643 - recall: 0.4678 \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3254 - loss: 0.7051 - precision: 0.0664 - recall: 0.8317  \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3988 - loss: 0.6647 - precision: 0.0524 - recall: 0.6475 \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2506 - loss: 0.6972 - precision: 0.0604 - recall: 0.8473 \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5353 - loss: 0.6782 - precision: 0.0600 - recall: 0.5371 \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4339 - loss: 0.6694 - precision: 0.0564 - recall: 0.6479 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4022 - loss: 0.6621 - precision: 0.0604 - recall: 0.7405 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4463 - loss: 0.6927 - precision: 0.0638 - recall: 0.6554 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5747 - loss: 0.6858 - precision: 0.0648 - recall: 0.5129 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3701 - loss: 0.6915 - precision: 0.0634 - recall: 0.7476 \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5399 - loss: 0.6840 - precision: 0.0739 - recall: 0.6243 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.6964 - precision: 0.0904 - recall: 0.4151 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6409 - precision: 0.0864 - recall: 0.5800 \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6687 - loss: 0.6689 - precision: 0.0732 - recall: 0.4644 \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5063 - loss: 0.6697 - precision: 0.0732 - recall: 0.7202 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4685 - loss: 0.6801 - precision: 0.0728 - recall: 0.7244 \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6545 - precision: 0.0872 - recall: 0.5399 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6094 - loss: 0.6867 - precision: 0.0822 - recall: 0.5924 \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5153 - loss: 0.7033 - precision: 0.0811 - recall: 0.7005 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5182 - loss: 0.6658 - precision: 0.0698 - recall: 0.6598 \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6035 - loss: 0.6611 - precision: 0.0704 - recall: 0.5477 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5768 - loss: 0.6439 - precision: 0.0753 - recall: 0.6582 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5726 - loss: 0.6629 - precision: 0.0803 - recall: 0.6681 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5637 - loss: 0.6712 - precision: 0.0790 - recall: 0.6253 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6813 - loss: 0.7180 - precision: 0.0866 - recall: 0.4606 \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 0.6565 - precision: 0.0793 - recall: 0.4773 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.6465 - precision: 0.0902 - recall: 0.5364 \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7148 - loss: 0.6586 - precision: 0.0993 - recall: 0.5570 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4781 - loss: 0.6953 - precision: 0.0801 - recall: 0.7329 \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6522 - loss: 0.6632 - precision: 0.0837 - recall: 0.5446 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6509 - loss: 0.6793 - precision: 0.0944 - recall: 0.5963 \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5777 - loss: 0.6621 - precision: 0.0766 - recall: 0.6054 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6969 - loss: 0.6270 - precision: 0.0903 - recall: 0.5666 \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5625 - loss: 0.6691 - precision: 0.0816 - recall: 0.6659 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6495 - loss: 0.6590 - precision: 0.0948 - recall: 0.6329 \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.6435 - precision: 0.0871 - recall: 0.7471 \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 0.6572 - precision: 0.0877 - recall: 0.6311 \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6981 - loss: 0.6633 - precision: 0.0860 - recall: 0.4895 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6543 - loss: 0.6284 - precision: 0.0798 - recall: 0.5719 \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5799 - loss: 0.6579 - precision: 0.0881 - recall: 0.6943 \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6796 - loss: 0.6542 - precision: 0.1025 - recall: 0.6155 \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.6514 - precision: 0.1034 - recall: 0.5682 \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6871 - loss: 0.6530 - precision: 0.0903 - recall: 0.5251 \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - loss: 0.6498 - precision: 0.1044 - recall: 0.5799 \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5751 - loss: 0.6818 - precision: 0.0935 - recall: 0.6852 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.6479 - precision: 0.0940 - recall: 0.4703 \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5928 - loss: 0.6334 - precision: 0.0831 - recall: 0.7120 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5369 - loss: 0.6699 - precision: 0.0851 - recall: 0.7207 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 0.6448 - precision: 0.0783 - recall: 0.5785 \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 0.6209 - precision: 0.0895 - recall: 0.6295 \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5793 - loss: 0.6303 - precision: 0.0792 - recall: 0.6726 \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5688 - loss: 0.6344 - precision: 0.0874 - recall: 0.7524 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5912 - loss: 0.6333 - precision: 0.0811 - recall: 0.6630 \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6638 - loss: 0.6488 - precision: 0.0838 - recall: 0.5311 \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7102 - loss: 0.6386 - precision: 0.1004 - recall: 0.5567 \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.6581 - precision: 0.0921 - recall: 0.6536 \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6074 - loss: 0.6699 - precision: 0.0890 - recall: 0.6370 \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6462 - loss: 0.6313 - precision: 0.0882 - recall: 0.6226 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.6672 - precision: 0.0941 - recall: 0.6993 \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5913 - loss: 0.6537 - precision: 0.0789 - recall: 0.6050 \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.6560 - precision: 0.1021 - recall: 0.5533 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 0.6476 - precision: 0.0913 - recall: 0.6590 \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6487 - loss: 0.6446 - precision: 0.0893 - recall: 0.5993 \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5446 - loss: 0.6409 - precision: 0.0828 - recall: 0.7226 \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6439 - loss: 0.6168 - precision: 0.0896 - recall: 0.6555 \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6237 - loss: 0.6410 - precision: 0.0880 - recall: 0.6398 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6247 - loss: 0.6192 - precision: 0.0785 - recall: 0.6058 \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6022 - loss: 0.6349 - precision: 0.0766 - recall: 0.6353 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4390 - loss: 0.6482 - precision: 0.0675 - recall: 0.7818 \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5088 - loss: 0.6901 - precision: 0.0876 - recall: 0.7300 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 0.6710 - precision: 0.0930 - recall: 0.6465 \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6731 - loss: 0.6211 - precision: 0.0985 - recall: 0.6246 \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5690 - loss: 0.6835 - precision: 0.0888 - recall: 0.6595 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6566 - loss: 0.6378 - precision: 0.0961 - recall: 0.6358 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5360 - loss: 0.6308 - precision: 0.0790 - recall: 0.7231 \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6778 - loss: 0.6488 - precision: 0.0868 - recall: 0.5568 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6053 - loss: 0.6569 - precision: 0.1008 - recall: 0.6983 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7042 - loss: 0.6441 - precision: 0.0909 - recall: 0.5145 \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5802 - loss: 0.6719 - precision: 0.0758 - recall: 0.6008 \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5897 - loss: 0.6324 - precision: 0.0808 - recall: 0.6537 \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6730 - loss: 0.6164 - precision: 0.0894 - recall: 0.5782 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6595 - loss: 0.6622 - precision: 0.0962 - recall: 0.5801 \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6804 - loss: 0.6238 - precision: 0.1021 - recall: 0.6316 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6790 - loss: 0.6378 - precision: 0.0937 - recall: 0.5526 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.6023 - precision: 0.1096 - recall: 0.6042 \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6046 - loss: 0.6528 - precision: 0.0934 - recall: 0.6723 \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6538 - loss: 0.6368 - precision: 0.0859 - recall: 0.5605 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.6485 - precision: 0.1006 - recall: 0.5934 \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 0.6509 - precision: 0.0926 - recall: 0.7050 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7126 - loss: 0.6501 - precision: 0.0914 - recall: 0.4710 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.5954 - precision: 0.0921 - recall: 0.5799 \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5511 - loss: 0.6602 - precision: 0.0826 - recall: 0.6922 \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5807 - loss: 0.6510 - precision: 0.0846 - recall: 0.6707 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6607 - loss: 0.6374 - precision: 0.1010 - recall: 0.6715 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29101b9fdd8041f2972afb9fa03ef01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▆▄▁▃▂▂▆▄▅▄▄▅▆▅▆▃▅▄▆▆▄▅▅▆▅▆▅▅▃▄▄▆▆▅▆▅▆▆▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▆▆▄▆▅▃▄▅▆▅▅▂▅▄▄▄▅▃▃▅▄▃▃▄▄▃▄▄▄▄▁▄▃▄▅▄▃▃</td></tr><tr><td>batch/precision</td><td>▄▁▂▂▁▂▂▆▃▅▃▃▅▃▄▆▆▄▅▆▅▄▅▃▇▄█▄▆▂▅▄▃▆▄▆▅▆▅▆</td></tr><tr><td>batch/recall</td><td>▁▃▄▆▅▅▆▅▆▄▄▅▅▄▅▅█▄▆▅▄▆▅▅▅▅▅▅▅▆▆▅▅▅▅▄▅▅▄▆</td></tr><tr><td>epoch/accuracy</td><td>▆█▄▁▄▂▂▆▄▆▃▄▆▆▅▆▅▆▄▅▄▄▅▄▆▅▆▅▅▅▅▄▅▆▅▅▅▅▆▅</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>▅▇▆██▆▆▆▇▅▅▅▅█▄▅▆▄▂▃▁▄▄▂▃▃▂▄▄█▂▂▂▃▁▁▂▄▃▆</td></tr><tr><td>epoch/precision</td><td>▁▆▃▃▄▄▃▆▅▆▄▅▆█▆▇▆█▆▇▆▆▆▆▇▆▇▇▆▇▆▆▇▇▇▇▆▇█▇</td></tr><tr><td>epoch/recall</td><td>▂▁▄█▅█▇▄▇▅▇▆▅▆▆▆▆▅▇▆▇▇▆▇▅▆▅▆▆▆▆▇▆▆▆▆▇▆▆▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.44297</td></tr><tr><td>batch/accuracy</td><td>0.65385</td></tr><tr><td>batch/batch_step</td><td>699</td></tr><tr><td>batch/loss</td><td>0.67951</td></tr><tr><td>batch/precision</td><td>0.09707</td></tr><tr><td>batch/recall</td><td>0.64634</td></tr><tr><td>epoch/accuracy</td><td>0.65385</td></tr><tr><td>epoch/epoch</td><td>99</td></tr><tr><td>epoch/loss</td><td>0.67951</td></tr><tr><td>epoch/precision</td><td>0.09707</td></tr><tr><td>epoch/recall</td><td>0.64634</td></tr><tr><td>f1_score</td><td>0.14634</td></tr><tr><td>precision</td><td>0.07965</td></tr><tr><td>recall</td><td>0.9</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rare-sweep-19</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kbz4orr4/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kbz4orr4/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000357-kbz4orr4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0qtwcf8a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 37\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06715442772389037\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000413-0qtwcf8a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0qtwcf8a/workspace' target=\"_blank\">northern-sweep-20</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0qtwcf8a/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/0qtwcf8a/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8634 - loss: 0.3712 - precision: 0.1111 - recall: 0.1244\n",
      "Epoch 2/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.2743 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.2205 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2133 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.2217 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.2057 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.2110 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1885 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.2087 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2139 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.1867 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.2116 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.2218 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.2218 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.2158 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2006 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.2192 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.2253 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1877 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2080 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1943 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.2262 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2231 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2033 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.1936 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.2073 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1977 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/37\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115a7d7e2ac34db7a9add1a518eab73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▅▇▇▇▇▇▇▆█▅▇▇▅▆▇▇▇▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▁▃▂▂▂▂▂▂▂▂▃▂▁▂▃▂▂▂▅▂▂▂▂▂▃▃▁▄▂▂▄▃▂▂▂▃▂▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▅▃▂▄▃▃▃▃▄▃▂▂▄▃▁▃▁▃▃▃▃▂▂▃▃▂▂▂▂▁▃▂▁▂▂▃</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>332</td></tr><tr><td>batch/loss</td><td>0.21405</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>36</td></tr><tr><td>epoch/loss</td><td>0.21405</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-20</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0qtwcf8a/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/0qtwcf8a/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000413-0qtwcf8a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: avd4to0j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 46\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02448149854871713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000429-avd4to0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/avd4to0j/workspace' target=\"_blank\">giddy-sweep-21</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/avd4to0j/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/avd4to0j/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.9453 - loss: 0.3804 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.2221 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9507 - loss: 0.1974 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.2018 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.2005 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2099 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1970 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1843 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1889 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.2339 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.2046 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.2166 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1919 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1900 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1941 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1831 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1986 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1912 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1904 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.1834 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.2045 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.2266 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2079 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1897 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1971 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1919 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2017 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1911 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1995 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9486 - loss: 0.1918 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1814 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/46\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.2142 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c833446536448bc92f976c6c4248e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▇▇▆▇█▆▆▆▇▇▇▁▆▆▆▆▆▇▇▇▆█▆▆▇█▆▆▆▆▇▇█▇▆▆▇▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▃▃▃▁▃▃▃▃▃▃█▃▃▃▃▃▃▂▂▃▂▃▃▃▁▃▄▃▃▃▃▂▂▄▃▂▃▃▃</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▂▁▂▁▂▂▁▂▂▁▁▁▁▁▁▁▁▂▁▁▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>321</td></tr><tr><td>batch/loss</td><td>0.19175</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>45</td></tr><tr><td>epoch/loss</td><td>0.19175</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">giddy-sweep-21</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/avd4to0j/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/avd4to0j/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000429-avd4to0j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tnpr1sjn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 240\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.013927871103402028\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000450-tnpr1sjn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tnpr1sjn/workspace' target=\"_blank\">vivid-sweep-22</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tnpr1sjn/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/tnpr1sjn/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7004 - loss: 0.6793 - precision: 0.0629 - recall: 0.3884       \n",
      "Epoch 2/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2390 - loss: 0.7114 - precision: 0.0674 - recall: 0.9369 \n",
      "Epoch 3/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8913 - loss: 0.7694 - precision: 0.1284 - recall: 0.0999         \n",
      "Epoch 4/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3159 - loss: 0.6992 - precision: 0.0711 - recall: 0.8511 \n",
      "Epoch 5/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4411 - loss: 0.6624 - precision: 0.0679 - recall: 0.7296 \n",
      "Epoch 6/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6899 - loss: 0.6033 - precision: 0.0908 - recall: 0.5972 \n",
      "Epoch 7/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3600 - loss: 0.6509 - precision: 0.0650 - recall: 0.8172 \n",
      "Epoch 8/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6416 - loss: 0.6522 - precision: 0.0883 - recall: 0.6039 \n",
      "Epoch 9/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 0.6715 - precision: 0.0856 - recall: 0.7175 \n",
      "Epoch 10/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5014 - loss: 0.6489 - precision: 0.0842 - recall: 0.7658 \n",
      "Epoch 11/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7971 - loss: 0.6583 - precision: 0.1170 - recall: 0.4239 \n",
      "Epoch 12/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3745 - loss: 0.6757 - precision: 0.0692 - recall: 0.8010 \n",
      "Epoch 13/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3793 - loss: 0.6530 - precision: 0.0728 - recall: 0.8956 \n",
      "Epoch 14/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6794 - loss: 0.6434 - precision: 0.1022 - recall: 0.6276 \n",
      "Epoch 15/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 0.6433 - precision: 0.1024 - recall: 0.6577 \n",
      "Epoch 16/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 0.6681 - precision: 0.0975 - recall: 0.5896 \n",
      "Epoch 17/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6207 - loss: 0.6784 - precision: 0.1048 - recall: 0.6716 \n",
      "Epoch 18/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7006 - loss: 0.6329 - precision: 0.0980 - recall: 0.5454 \n",
      "Epoch 19/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.6236 - precision: 0.0703 - recall: 0.6266 \n",
      "Epoch 20/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.6215 - precision: 0.0925 - recall: 0.7015 \n",
      "Epoch 21/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6746 - loss: 0.6160 - precision: 0.1010 - recall: 0.6282 \n",
      "Epoch 22/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5856 - loss: 0.6906 - precision: 0.1038 - recall: 0.7016 \n",
      "Epoch 23/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6683 - loss: 0.6257 - precision: 0.0964 - recall: 0.5842 \n",
      "Epoch 24/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6139 - loss: 0.6125 - precision: 0.0828 - recall: 0.6502 \n",
      "Epoch 25/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6170 - loss: 0.6143 - precision: 0.1007 - recall: 0.7298 \n",
      "Epoch 26/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7043 - loss: 0.5819 - precision: 0.1062 - recall: 0.6503 \n",
      "Epoch 27/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5623 - loss: 0.6080 - precision: 0.0819 - recall: 0.7139 \n",
      "Epoch 28/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7094 - loss: 0.5997 - precision: 0.0876 - recall: 0.5321 \n",
      "Epoch 29/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6678 - loss: 0.6204 - precision: 0.1018 - recall: 0.6355 \n",
      "Epoch 30/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6947 - loss: 0.5953 - precision: 0.1170 - recall: 0.6659 \n",
      "Epoch 31/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4658 - loss: 0.6394 - precision: 0.0826 - recall: 0.8212 \n",
      "Epoch 32/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6063 - loss: 0.6541 - precision: 0.0977 - recall: 0.7163 \n",
      "Epoch 33/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.6019 - precision: 0.1035 - recall: 0.6984 \n",
      "Epoch 34/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6734 - loss: 0.6391 - precision: 0.1077 - recall: 0.6020 \n",
      "Epoch 35/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7369 - loss: 0.6200 - precision: 0.1395 - recall: 0.6407 \n",
      "Epoch 36/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5129 - loss: 0.6604 - precision: 0.0913 - recall: 0.7653 \n",
      "Epoch 37/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 0.6286 - precision: 0.1286 - recall: 0.5284 \n",
      "Epoch 38/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.5817 - precision: 0.1002 - recall: 0.6213 \n",
      "Epoch 39/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6591 - loss: 0.6054 - precision: 0.0983 - recall: 0.6532 \n",
      "Epoch 40/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5929 - loss: 0.5878 - precision: 0.0840 - recall: 0.6898 \n",
      "Epoch 41/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5857 - loss: 0.6261 - precision: 0.0980 - recall: 0.7500 \n",
      "Epoch 42/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6397 - loss: 0.6454 - precision: 0.1057 - recall: 0.6470 \n",
      "Epoch 43/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6905 - loss: 0.6117 - precision: 0.1053 - recall: 0.5999 \n",
      "Epoch 44/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6020 - loss: 0.6052 - precision: 0.0935 - recall: 0.7188 \n",
      "Epoch 45/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6966 - loss: 0.6006 - precision: 0.1011 - recall: 0.5797 \n",
      "Epoch 46/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5462 - loss: 0.6067 - precision: 0.0864 - recall: 0.7869 \n",
      "Epoch 47/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6707 - loss: 0.6373 - precision: 0.1220 - recall: 0.6781 \n",
      "Epoch 48/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 0.5862 - precision: 0.0935 - recall: 0.6469 \n",
      "Epoch 49/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6030 - loss: 0.5880 - precision: 0.0939 - recall: 0.7489 \n",
      "Epoch 50/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6684 - loss: 0.5734 - precision: 0.0997 - recall: 0.6595 \n",
      "Epoch 51/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6273 - loss: 0.5892 - precision: 0.0947 - recall: 0.7266 \n",
      "Epoch 52/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6472 - loss: 0.5731 - precision: 0.0881 - recall: 0.7197 \n",
      "Epoch 53/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4469 - loss: 0.6324 - precision: 0.0834 - recall: 0.8612 \n",
      "Epoch 54/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7129 - loss: 0.6204 - precision: 0.1162 - recall: 0.6114 \n",
      "Epoch 55/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6549 - loss: 0.6145 - precision: 0.1218 - recall: 0.7363 \n",
      "Epoch 56/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7394 - loss: 0.6523 - precision: 0.1103 - recall: 0.4950 \n",
      "Epoch 57/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5235 - loss: 0.5923 - precision: 0.0808 - recall: 0.8029 \n",
      "Epoch 58/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6729 - loss: 0.5984 - precision: 0.1120 - recall: 0.6633 \n",
      "Epoch 59/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5983 - loss: 0.5923 - precision: 0.0952 - recall: 0.7783 \n",
      "Epoch 60/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.5805 - precision: 0.1047 - recall: 0.6500 \n",
      "Epoch 61/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6216 - loss: 0.5748 - precision: 0.1001 - recall: 0.7940 \n",
      "Epoch 62/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5415 - loss: 0.5930 - precision: 0.0921 - recall: 0.8217 \n",
      "Epoch 63/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6805 - loss: 0.5874 - precision: 0.0989 - recall: 0.6409 \n",
      "Epoch 64/64\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6648 - loss: 0.5979 - precision: 0.1092 - recall: 0.6838 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92add260b6943d2b4335597afa37a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▆▁▂▆▂▄█▃▆▆▅▆▅▅▆▆▅▇▇▅▆▇▄▇▅▆▇▅▄▆▆▆▃▇█▇▅▅▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▆██▄▆▆▁▇▆▆▆▅▅▆▅▄▄▅▅▆▄▅▄▄▂▆▅▄▄▂▂▄▆▆▇▄▄▂▂▃</td></tr><tr><td>batch/precision</td><td>▂▁▂▂▁▂▅▁▄▃▃▂▃▃▃▃▂▄▅▂▄█▂▄▃▅▄▃▂▃▃▃▂▅▄▆▃▃▁▃</td></tr><tr><td>batch/recall</td><td>▂█▇▃▆▅▄▆▅▄▄▃▅▅▄▅▅▂▄▄▄▅▆▄▅▄▃▆▆▅▄▅▇▄▁▄▆▇▄▅</td></tr><tr><td>epoch/accuracy</td><td>▇▂▁▅▂▄▅▂▄▆▆█▆▅▇▆▇█▇▄▇▇▄▇▇▆█▆▅▇▆▆▇▇▇▅▆█▅▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▆▆▇▅▅▃▆▆▄▄▇▅▄▄▃▃▄▄▅▄▃▃▃▄▅▃▃▃▃▃▂▃▂▁▄▂▄▃▁</td></tr><tr><td>epoch/precision</td><td>▃▂▁▃▂▂▃▁▃▄▅▆▄▄▅▅▆▇▆▃▆▅▃▆▆▅▇▅▄▇▆▆▆▇▇▅▆█▄▆</td></tr><tr><td>epoch/recall</td><td>▁██▅▇▆▆█▇▄▅▃▅▆▄▅▃▂▄▇▄▄▇▄▄▆▃▆▇▅▅▆▅▅▆▆▇▄▇▅</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.62865</td></tr><tr><td>batch/accuracy</td><td>0.63528</td></tr><tr><td>batch/batch_step</td><td>447</td></tr><tr><td>batch/loss</td><td>0.56887</td></tr><tr><td>batch/precision</td><td>0.09932</td></tr><tr><td>batch/recall</td><td>0.70732</td></tr><tr><td>epoch/accuracy</td><td>0.63528</td></tr><tr><td>epoch/epoch</td><td>63</td></tr><tr><td>epoch/loss</td><td>0.56887</td></tr><tr><td>epoch/precision</td><td>0.09932</td></tr><tr><td>epoch/recall</td><td>0.70732</td></tr><tr><td>f1_score</td><td>0.16667</td></tr><tr><td>precision</td><td>0.09459</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vivid-sweep-22</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tnpr1sjn/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/tnpr1sjn/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000450-tnpr1sjn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vaxaeols with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 160\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 39\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.033287665716819265\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000511-vaxaeols</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vaxaeols/workspace' target=\"_blank\">easy-sweep-23</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vaxaeols/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vaxaeols/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9416 - loss: 0.5475 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.3881 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.3026 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.2562 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.2385 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.2351 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.2164 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.2248 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.2094 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.2150 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2267 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.2152 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.2080 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.2093 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.2426 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.2172 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9398 - loss: 0.2310 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9511 - loss: 0.2002 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2186 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1909 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.2166 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.2195 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.2274 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.2294 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2178 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.2194 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2150 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2147 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2164 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1938 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9354 - loss: 0.2413 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/39\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2236 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2972b5875c4d4081517c1303e5e81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▅▃▇▃▂▃▃▃▄▃▅▃█▃▃▃▂▃▄▃▄▃▃▃▄▃▃▁▄▆▅▂▄▃▄▄▂▂▂</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▄▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>389</td></tr><tr><td>batch/loss</td><td>0.20878</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>38</td></tr><tr><td>epoch/loss</td><td>0.20878</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">easy-sweep-23</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vaxaeols/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vaxaeols/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000511-vaxaeols/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rq9lt8ch with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06014475436863081\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000527-rq9lt8ch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/rq9lt8ch/workspace' target=\"_blank\">woven-sweep-24</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/rq9lt8ch/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/rq9lt8ch/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 120ms/step - accuracy: 0.9422 - loss: 0.3749 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/6\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.2194 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/6\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2097 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/6\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9383 - loss: 0.2311 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/6\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.2037 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/6\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.2207 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f597883a064f7a843b7c4daa4ad07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▅▄▅▆▆▅▅▄▅▆▅▆▅█▄▅▄▅▅▃▂▃▃▄▄▅▆▆██▇▆▅▁▂▂▃▅▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>batch/loss</td><td>█▄▅▄▃▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▂▁</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▂▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>41</td></tr><tr><td>batch/loss</td><td>0.20032</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>5</td></tr><tr><td>epoch/loss</td><td>0.20032</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-sweep-24</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/rq9lt8ch/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/rq9lt8ch/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000527-rq9lt8ch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a6llbxjx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00411978083731485\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000542-a6llbxjx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/a6llbxjx/workspace' target=\"_blank\">solar-sweep-25</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/a6llbxjx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/a6llbxjx/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3014 - loss: 0.7115 - precision: 0.0552 - recall: 0.7273\n",
      "Epoch 2/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.6330 - precision: 0.0375 - recall: 0.0092         \n",
      "Epoch 3/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.5777 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.5350 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.4948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9409 - loss: 0.4661 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9396 - loss: 0.4402 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.4122 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.3839 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.3686 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.3570 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.3402 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.3339 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.3208 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.3067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.2924 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/17\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.2763 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85331b60f7a4acda6e2040f1ab2f510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▃▄█████████████████████████████████████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>██▇▇▆▆▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>batch/precision</td><td>▇▇▇▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▆▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▄▄▄▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>237</td></tr><tr><td>batch/loss</td><td>0.28336</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>16</td></tr><tr><td>epoch/loss</td><td>0.28336</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-25</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/a6llbxjx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/a6llbxjx/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000542-a6llbxjx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xchkio4d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.050095209449401934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000559-xchkio4d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/xchkio4d/workspace' target=\"_blank\">graceful-sweep-26</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/xchkio4d/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/xchkio4d/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6367 - loss: 0.4793 - precision: 0.0565 - recall: 0.3499\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.3192 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.2294 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.2223 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.2418 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.2186 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1996 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1965 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1877 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1863 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2204 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2428 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1965 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1916 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1872 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2130 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9449 - loss: 0.2046 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1920 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.2006 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.2008 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1924 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.1835 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.1924 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9532 - loss: 0.1882 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1861 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2225 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2017 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1838 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.2265 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1910 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.2289 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1879 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1868 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1986 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1920 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868d17fbf0ee43ae98eb3123b1a1c650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▇▇▇▇▇▇███▇█▇▇▇▇▇▇▇▇▇▇██▇█▇█▇█▇▇▇▇▇▇▇▇█</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▃▃▄▂▂▂▂▂▁▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▁▃▂▂▁▃▂▃▂▂▂▂▂▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▄▂▂▂▂▂▁▁▁▄▂▁▂▂▂▁▂▂▁▂▂▂▁▁▂▁▂▁▁▂▂▂▂▂▁▂▁▂</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>349</td></tr><tr><td>batch/loss</td><td>0.20102</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/loss</td><td>0.20102</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-sweep-26</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/xchkio4d/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/xchkio4d/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000559-xchkio4d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cxp6h8za with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 49\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.03586498238943817\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000614-cxp6h8za</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cxp6h8za/workspace' target=\"_blank\">rich-sweep-27</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cxp6h8za/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/cxp6h8za/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7987 - loss: 0.3689 - precision: 0.1125 - recall: 0.2771\n",
      "Epoch 2/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1950 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9351 - loss: 0.2440 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9351 - loss: 0.2331 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2142 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9306 - loss: 0.2482 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2144 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1969 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.2234 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2048 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.2008 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.2336 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.2274 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1890 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.2044 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2093 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2117 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.2169 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2111 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1994 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2151 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2086 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1911 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1928 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2064 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1911 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2134 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1838 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9340 - loss: 0.2308 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1914 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1923 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2094 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2158 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1781 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9377 - loss: 0.2157 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1934 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1949 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/49\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a844f0a744ac4579b7d4987d5ee5ef54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁█▇▇▆▆▇▇██▆▇█▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇██▇▇▇▇▇▅▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▂▃▂▄▅▃▃▂▂▃▃▂▃▂▃▃▂▃▂▂▁▃▂▂▂▃▂▃▁▂▂▂▃▃▂▅▂▂▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▂▃▂▁▁▁▁▂▁▁▁▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>930</td></tr><tr><td>batch/loss</td><td>0.20369</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>48</td></tr><tr><td>epoch/loss</td><td>0.20369</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-sweep-27</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cxp6h8za/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/cxp6h8za/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000614-cxp6h8za/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kak4166y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 160\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.03594517440558307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000629-kak4166y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kak4166y/workspace' target=\"_blank\">lilac-sweep-28</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kak4166y/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kak4166y/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4135 - loss: 0.7606 - precision: 0.0655 - recall: 0.6388\n",
      "Epoch 2/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.7175 - precision: 0.0378 - recall: 0.1355         \n",
      "Epoch 3/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3414 - loss: 0.6751 - precision: 0.0679 - recall: 0.8480 \n",
      "Epoch 4/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5569 - loss: 0.6728 - precision: 0.0999 - recall: 0.7503 \n",
      "Epoch 5/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.6462 - precision: 0.1286 - recall: 0.2664 \n",
      "Epoch 6/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4838 - loss: 0.6459 - precision: 0.0748 - recall: 0.7754 \n",
      "Epoch 7/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5945 - loss: 0.6191 - precision: 0.0824 - recall: 0.6921 \n",
      "Epoch 8/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4692 - loss: 0.6441 - precision: 0.0691 - recall: 0.7471 \n",
      "Epoch 9/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4672 - loss: 0.6454 - precision: 0.0683 - recall: 0.7311 \n",
      "Epoch 10/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6561 - loss: 0.6502 - precision: 0.0954 - recall: 0.5916 \n",
      "Epoch 11/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4603 - loss: 0.6719 - precision: 0.0836 - recall: 0.8062 \n",
      "Epoch 12/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.6160 - precision: 0.0881 - recall: 0.5057 \n",
      "Epoch 13/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2190 - loss: 0.7122 - precision: 0.0710 - recall: 0.9654 \n",
      "Epoch 14/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7093 - loss: 0.6898 - precision: 0.1019 - recall: 0.4946 \n",
      "Epoch 15/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5226 - loss: 0.6724 - precision: 0.0753 - recall: 0.6648 \n",
      "Epoch 16/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6587 - loss: 0.6289 - precision: 0.0903 - recall: 0.5963 \n",
      "Epoch 17/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6353 - loss: 0.6322 - precision: 0.0890 - recall: 0.6293 \n",
      "Epoch 18/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1244 - loss: 0.6541 - precision: 0.0538 - recall: 1.0000 \n",
      "Epoch 19/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4135 - loss: 0.6476 - precision: 0.0686 - recall: 0.8286 \n",
      "Epoch 20/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6929 - loss: 0.6596 - precision: 0.0995 - recall: 0.5555 \n",
      "Epoch 21/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.6254 - precision: 0.1123 - recall: 0.4349 \n",
      "Epoch 22/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4398 - loss: 0.6923 - precision: 0.0765 - recall: 0.7707 \n",
      "Epoch 23/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.6596 - precision: 0.1053 - recall: 0.3401 \n",
      "Epoch 24/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6100 - loss: 0.6428 - precision: 0.0791 - recall: 0.6266 \n",
      "Epoch 25/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6807 - loss: 0.7018 - precision: 0.0925 - recall: 0.5042 \n",
      "Epoch 26/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6317 - loss: 0.6586 - precision: 0.0826 - recall: 0.5610 \n",
      "Epoch 27/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6632 - loss: 0.6631 - precision: 0.1038 - recall: 0.6203 \n",
      "Epoch 28/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.6328 - precision: 0.1003 - recall: 0.5373 \n",
      "Epoch 29/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6378 - loss: 0.6171 - precision: 0.0832 - recall: 0.6182 \n",
      "Epoch 30/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5640 - loss: 0.6694 - precision: 0.0790 - recall: 0.6488 \n",
      "Epoch 31/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.6532 - precision: 0.1103 - recall: 0.5470 \n",
      "Epoch 32/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5578 - loss: 0.6107 - precision: 0.0674 - recall: 0.6086         \n",
      "Epoch 33/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.6349 - precision: 0.0941 - recall: 0.6725 \n",
      "Epoch 34/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7151 - loss: 0.6833 - precision: 0.0822 - recall: 0.3904 \n",
      "Epoch 35/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5591 - loss: 0.6204 - precision: 0.0840 - recall: 0.7295 \n",
      "Epoch 36/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.6036 - precision: 0.1039 - recall: 0.5576 \n",
      "Epoch 37/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6352 - loss: 0.6257 - precision: 0.1119 - recall: 0.7365 \n",
      "Epoch 38/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5334 - loss: 0.6770 - precision: 0.0831 - recall: 0.6665 \n",
      "Epoch 39/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5978 - loss: 0.6495 - precision: 0.0900 - recall: 0.6372 \n",
      "Epoch 40/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.6375 - precision: 0.1178 - recall: 0.5417 \n",
      "Epoch 41/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6043 - loss: 0.6310 - precision: 0.0836 - recall: 0.6322 \n",
      "Epoch 42/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6701 - loss: 0.6139 - precision: 0.0988 - recall: 0.6264 \n",
      "Epoch 43/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5049 - loss: 0.6139 - precision: 0.0750 - recall: 0.7580 \n",
      "Epoch 44/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.6725 - precision: 0.1041 - recall: 0.6686 \n",
      "Epoch 45/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.6028 - precision: 0.0868 - recall: 0.5785 \n",
      "Epoch 46/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5629 - loss: 0.5887 - precision: 0.0758 - recall: 0.7105 \n",
      "Epoch 47/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3864 - loss: 0.6056 - precision: 0.0601 - recall: 0.8808 \n",
      "Epoch 48/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5602 - loss: 0.6208 - precision: 0.0733 - recall: 0.6410 \n",
      "Epoch 49/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5890 - loss: 0.5987 - precision: 0.0883 - recall: 0.7117 \n",
      "Epoch 50/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3846 - loss: 0.6546 - precision: 0.0727 - recall: 0.8252 \n",
      "Epoch 51/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7684 - loss: 0.6639 - precision: 0.1500 - recall: 0.5661 \n",
      "Epoch 52/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7615 - loss: 0.5579 - precision: 0.1103 - recall: 0.5865 \n",
      "Epoch 53/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5066 - loss: 0.6058 - precision: 0.0835 - recall: 0.8323 \n",
      "Epoch 54/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6731 - loss: 0.6005 - precision: 0.1005 - recall: 0.6360 \n",
      "Epoch 55/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5734 - loss: 0.6164 - precision: 0.0890 - recall: 0.7234 \n",
      "Epoch 56/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7069 - loss: 0.5959 - precision: 0.0911 - recall: 0.5543 \n",
      "Epoch 57/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6086 - loss: 0.5817 - precision: 0.0925 - recall: 0.7834 \n",
      "Epoch 58/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5213 - loss: 0.6227 - precision: 0.0831 - recall: 0.7811 \n",
      "Epoch 59/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7411 - loss: 0.6227 - precision: 0.1141 - recall: 0.5445 \n",
      "Epoch 60/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5487 - loss: 0.6288 - precision: 0.0787 - recall: 0.6884 \n",
      "Epoch 61/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7154 - loss: 0.5987 - precision: 0.0948 - recall: 0.5360 \n",
      "Epoch 62/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4725 - loss: 0.6237 - precision: 0.0836 - recall: 0.8549 \n",
      "Epoch 63/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6954 - loss: 0.6025 - precision: 0.1264 - recall: 0.7216 \n",
      "Epoch 64/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5117 - loss: 0.6316 - precision: 0.0893 - recall: 0.7855 \n",
      "Epoch 65/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6537 - loss: 0.6378 - precision: 0.1207 - recall: 0.7629 \n",
      "Epoch 66/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5608 - loss: 0.6292 - precision: 0.0853 - recall: 0.7097 \n",
      "Epoch 67/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7815 - loss: 0.5845 - precision: 0.1438 - recall: 0.6146 \n",
      "Epoch 68/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3356 - loss: 0.6465 - precision: 0.0738 - recall: 0.9474 \n",
      "Epoch 69/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5962 - loss: 0.6373 - precision: 0.0923 - recall: 0.6910 \n",
      "Epoch 70/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.6460 - precision: 0.1074 - recall: 0.5812 \n",
      "Epoch 71/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6714 - loss: 0.5857 - precision: 0.1000 - recall: 0.6929 \n",
      "Epoch 72/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5343 - loss: 0.6231 - precision: 0.0816 - recall: 0.7384 \n",
      "Epoch 73/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5624 - loss: 0.6491 - precision: 0.0948 - recall: 0.7370 \n",
      "Epoch 74/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6239 - loss: 0.6113 - precision: 0.1091 - recall: 0.7267 \n",
      "Epoch 75/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5739 - loss: 0.5838 - precision: 0.0851 - recall: 0.7603 \n",
      "Epoch 76/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5553 - loss: 0.6189 - precision: 0.0796 - recall: 0.7076 \n",
      "Epoch 77/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7032 - loss: 0.6271 - precision: 0.1248 - recall: 0.6985 \n",
      "Epoch 78/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6069 - loss: 0.6267 - precision: 0.1018 - recall: 0.7047 \n",
      "Epoch 79/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5280 - loss: 0.5983 - precision: 0.0876 - recall: 0.8228 \n",
      "Epoch 80/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7018 - loss: 0.5842 - precision: 0.1013 - recall: 0.6095 \n",
      "Epoch 81/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4709 - loss: 0.5934 - precision: 0.0758 - recall: 0.8374 \n",
      "Epoch 82/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7624 - loss: 0.5832 - precision: 0.1217 - recall: 0.5749 \n",
      "Epoch 83/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6153 - loss: 0.5693 - precision: 0.0825 - recall: 0.6904 \n",
      "Epoch 84/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4239 - loss: 0.6145 - precision: 0.0782 - recall: 0.8727 \n",
      "Epoch 85/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.5918 - precision: 0.1479 - recall: 0.5911 \n",
      "Epoch 86/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5887 - loss: 0.5898 - precision: 0.0802 - recall: 0.6706 \n",
      "Epoch 87/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5505 - loss: 0.5854 - precision: 0.0755 - recall: 0.7315 \n",
      "Epoch 88/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5342 - loss: 0.6269 - precision: 0.0821 - recall: 0.7262 \n",
      "Epoch 89/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5145 - loss: 0.6156 - precision: 0.0852 - recall: 0.8031 \n",
      "Epoch 90/90\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 0.6028 - precision: 0.0839 - recall: 0.6308 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396f3d7a78ae4ba8ba7f3d4fca34d8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▁█▂▆▅▄▅▃▇▅▆▆▇▅▄▅▆▆▅▅▄▇▄▇▄▅▃▅▇▆▄▅▅▅▆▅▇▄▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▇▅▆▅▅▆▄▆▅▄▆▄▆▅▃▄▅▄▄▃▄▇▃▁▄▄▄▃▂▅▅▄▄▄▄▂▃▆▅</td></tr><tr><td>batch/precision</td><td>▁▂▄▃▄▃▂▃▂▅▃▄▄▆▃▂▄▅▃▃▃▃█▃▂▃▃▃▃▇▄▂▄▂▃▄▂▇▃▃</td></tr><tr><td>batch/recall</td><td>▄▇▁█▄▅▅▅▆▃▆▅▄▄▆▆▅▄▅▅▆▆▄▇▃▇▆▇▆▅▅▅▆▅▆▅▆▄▅▄</td></tr><tr><td>epoch/accuracy</td><td>▁▂█▄▄▄▅▄▂▇▇▅▅▃▃▃▅▃▄▄▄▂▆▃▃▂▃▃▃▆▅▄▄▃▄▅▅▇▃▅</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▇█▅▅▅▆▄▆▆▆▅▄▄▅▄▄▃▄▄▃▄▅▃▁▃▃▃▁▇▃▂▂▃▃▃▃▄▃▂</td></tr><tr><td>epoch/precision</td><td>▁▂▇▃▃▃▄▃▃▅▆▄▄▃▃▃▅▃▄▃▄▃▅▃▄▃▃▃▄▆▅▄▄▃▄▅▄█▃▅</td></tr><tr><td>epoch/recall</td><td>▅▆▁▆▆▅▅▆▇▃▃▅▅▇▇▆▆▇▆▆▆▇▅▇▇█▇▇▇▅▆▆▆▇▆▅▆▄▇▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.75597</td></tr><tr><td>batch/accuracy</td><td>0.70093</td></tr><tr><td>batch/batch_step</td><td>899</td></tr><tr><td>batch/loss</td><td>0.5995</td></tr><tr><td>batch/precision</td><td>0.10994</td></tr><tr><td>batch/recall</td><td>0.63415</td></tr><tr><td>epoch/accuracy</td><td>0.70093</td></tr><tr><td>epoch/epoch</td><td>89</td></tr><tr><td>epoch/loss</td><td>0.5995</td></tr><tr><td>epoch/precision</td><td>0.10994</td></tr><tr><td>epoch/recall</td><td>0.63415</td></tr><tr><td>f1_score</td><td>0.2069</td></tr><tr><td>precision</td><td>0.125</td></tr><tr><td>recall</td><td>0.6</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-sweep-28</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kak4166y/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kak4166y/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000629-kak4166y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2mpmib6p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 200\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.07851201382517613\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000646-2mpmib6p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2mpmib6p/workspace' target=\"_blank\">restful-sweep-29</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2mpmib6p/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2mpmib6p/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.4780 - loss: 0.9083 - precision: 0.0656 - recall: 0.5934\n",
      "Epoch 2/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1971 - loss: 0.7013 - precision: 0.0602 - recall: 0.9031 \n",
      "Epoch 3/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7135 - loss: 0.6933 - precision: 0.1099 - recall: 0.4971 \n",
      "Epoch 4/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4589 - loss: 0.6557 - precision: 0.0661 - recall: 0.7359 \n",
      "Epoch 5/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4235 - loss: 0.6859 - precision: 0.0808 - recall: 0.8663 \n",
      "Epoch 6/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5819 - loss: 0.6958 - precision: 0.0923 - recall: 0.6677 \n",
      "Epoch 7/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.6756 - precision: 0.1080 - recall: 0.4921 \n",
      "Epoch 8/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5184 - loss: 0.6817 - precision: 0.0824 - recall: 0.7047 \n",
      "Epoch 9/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7538 - loss: 0.6306 - precision: 0.0851 - recall: 0.4059 \n",
      "Epoch 10/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5115 - loss: 0.6515 - precision: 0.0773 - recall: 0.7135 \n",
      "Epoch 11/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.6582 - precision: 0.1123 - recall: 0.5793 \n",
      "Epoch 12/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5650 - loss: 0.6896 - precision: 0.0883 - recall: 0.6728 \n",
      "Epoch 13/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7627 - loss: 0.6670 - precision: 0.1023 - recall: 0.4475 \n",
      "Epoch 14/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5524 - loss: 0.6491 - precision: 0.0838 - recall: 0.7253 \n",
      "Epoch 15/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.6476 - precision: 0.1045 - recall: 0.5777 \n",
      "Epoch 16/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5319 - loss: 0.6503 - precision: 0.0756 - recall: 0.6924 \n",
      "Epoch 17/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7561 - loss: 0.6224 - precision: 0.0840 - recall: 0.3883 \n",
      "Epoch 18/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3798 - loss: 0.7082 - precision: 0.0779 - recall: 0.8331 \n",
      "Epoch 19/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7079 - loss: 0.6669 - precision: 0.1119 - recall: 0.5641 \n",
      "Epoch 20/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8183 - loss: 0.6754 - precision: 0.1401 - recall: 0.4032 \n",
      "Epoch 21/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5139 - loss: 0.6263 - precision: 0.0763 - recall: 0.7826 \n",
      "Epoch 22/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5285 - loss: 0.6476 - precision: 0.0739 - recall: 0.6799 \n",
      "Epoch 23/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.6624 - precision: 0.1021 - recall: 0.5502 \n",
      "Epoch 24/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6200 - loss: 0.6247 - precision: 0.0871 - recall: 0.6858 \n",
      "Epoch 25/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.6176 - precision: 0.0792 - recall: 0.6862 \n",
      "Epoch 26/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.6463 - precision: 0.0815 - recall: 0.6058 \n",
      "Epoch 27/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6338 - loss: 0.6595 - precision: 0.0851 - recall: 0.6007 \n",
      "Epoch 28/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5540 - loss: 0.6810 - precision: 0.0862 - recall: 0.6880 \n",
      "Epoch 29/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6119 - loss: 0.6700 - precision: 0.1054 - recall: 0.6870 \n",
      "Epoch 30/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7088 - loss: 0.6127 - precision: 0.0895 - recall: 0.5215 \n",
      "Epoch 31/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5663 - loss: 0.6355 - precision: 0.0802 - recall: 0.6886 \n",
      "Epoch 32/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.6306 - precision: 0.0847 - recall: 0.6608 \n",
      "Epoch 33/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5399 - loss: 0.6876 - precision: 0.0912 - recall: 0.7091 \n",
      "Epoch 34/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5815 - loss: 0.6822 - precision: 0.0973 - recall: 0.6806 \n",
      "Epoch 35/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6357 - loss: 0.6726 - precision: 0.0961 - recall: 0.5894 \n",
      "Epoch 36/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6182 - loss: 0.6252 - precision: 0.0969 - recall: 0.7009 \n",
      "Epoch 37/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.6243 - precision: 0.0924 - recall: 0.7278 \n",
      "Epoch 38/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5550 - loss: 0.6507 - precision: 0.0972 - recall: 0.7625 \n",
      "Epoch 39/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6362 - loss: 0.6399 - precision: 0.0945 - recall: 0.6388 \n",
      "Epoch 40/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5701 - loss: 0.6193 - precision: 0.0889 - recall: 0.7359 \n",
      "Epoch 41/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6134 - loss: 0.6007 - precision: 0.0871 - recall: 0.6808 \n",
      "Epoch 42/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5482 - loss: 0.6559 - precision: 0.0967 - recall: 0.7663 \n",
      "Epoch 43/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6635 - loss: 0.6278 - precision: 0.0977 - recall: 0.6333 \n",
      "Epoch 44/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5399 - loss: 0.6134 - precision: 0.0820 - recall: 0.7451 \n",
      "Epoch 45/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6160 - loss: 0.5886 - precision: 0.0813 - recall: 0.6424 \n",
      "Epoch 46/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4806 - loss: 0.6468 - precision: 0.0823 - recall: 0.7836 \n",
      "Epoch 47/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6181 - loss: 0.6296 - precision: 0.0920 - recall: 0.6434 \n",
      "Epoch 48/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5293 - loss: 0.6385 - precision: 0.0841 - recall: 0.7419 \n",
      "Epoch 49/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5403 - loss: 0.6440 - precision: 0.0889 - recall: 0.7200 \n",
      "Epoch 50/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7011 - loss: 0.5881 - precision: 0.1073 - recall: 0.6706 \n",
      "Epoch 51/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4326 - loss: 0.6141 - precision: 0.0733 - recall: 0.8901 \n",
      "Epoch 52/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5798 - loss: 0.6090 - precision: 0.0847 - recall: 0.7177 \n",
      "Epoch 53/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6789 - loss: 0.5634 - precision: 0.0867 - recall: 0.6355 \n",
      "Epoch 54/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5195 - loss: 0.6258 - precision: 0.0861 - recall: 0.8133 \n",
      "Epoch 55/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6469 - loss: 0.6574 - precision: 0.1093 - recall: 0.6419 \n",
      "Epoch 56/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5229 - loss: 0.6066 - precision: 0.0858 - recall: 0.8117 \n",
      "Epoch 57/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6161 - loss: 0.6050 - precision: 0.0936 - recall: 0.6723 \n",
      "Epoch 58/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4478 - loss: 0.6077 - precision: 0.0800 - recall: 0.8915 \n",
      "Epoch 59/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5574 - loss: 0.6427 - precision: 0.1001 - recall: 0.7802 \n",
      "Epoch 60/60\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6665 - loss: 0.5942 - precision: 0.0968 - recall: 0.6342 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7820cdde3ae94d4892ead52d27a03dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▁▂▁▇▄▃▅█▄▄█▆█▃▆▄▅▄▅▄▄▅▅▅▅▄▄▅▅▂▄▄▁▅▃▄▅▃▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▂▂▂▂▂▂▂▃▂▂▃▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/precision</td><td>▁▁▁▂▇▃▃▄█▄▃▅▇█▃▅▃▄▃▅▃▄▄▆▄▄▄▅▅▃▃▅▄▁▅▂▄▆▄▇</td></tr><tr><td>batch/recall</td><td>▃▇▆█▂▆▇▄▁▆▅▁▅▃▆▄▆▅▆▅▆▆▅▅▅▄▆▆▅▅█▇▆█▅█▆▅█▄</td></tr><tr><td>epoch/accuracy</td><td>▄▁▄▁▇▄▄▆▇▄▃███▄▆▅▅▃▅▄▅▅▅▅▄▅▅▆▃▂▆▄▆▅▆▄▄▃▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▃▃▃▂▂▂▃▂▂▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▁▁▁▂▁▁▁▁▂▁</td></tr><tr><td>epoch/precision</td><td>▁▁▃▂▅▃▃▄▆▄▃▅▇█▄▅▄▄▃▅▃▄▄▄▄▄▄▄▅▃▃▄▄▅▅▅▄▄▄▇</td></tr><tr><td>epoch/recall</td><td>▃▆▅█▄▆▅▄▄▆▇▁▂▃▆▄▅▅▆▅▆▅▅▅▅▆▆▆▅▇▇▄▆▄▆▄▆▇▇▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.687</td></tr><tr><td>batch/accuracy</td><td>0.71485</td></tr><tr><td>batch/batch_step</td><td>479</td></tr><tr><td>batch/loss</td><td>0.61812</td></tr><tr><td>batch/precision</td><td>0.10987</td></tr><tr><td>batch/recall</td><td>0.59756</td></tr><tr><td>epoch/accuracy</td><td>0.71485</td></tr><tr><td>epoch/epoch</td><td>59</td></tr><tr><td>epoch/loss</td><td>0.61812</td></tr><tr><td>epoch/precision</td><td>0.10987</td></tr><tr><td>epoch/recall</td><td>0.59756</td></tr><tr><td>f1_score</td><td>0.21333</td></tr><tr><td>precision</td><td>0.12308</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-29</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2mpmib6p/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2mpmib6p/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000646-2mpmib6p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t8q3u4i7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 89\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0765357628499069\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000702-t8q3u4i7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/t8q3u4i7/workspace' target=\"_blank\">glowing-sweep-30</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/t8q3u4i7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/t8q3u4i7/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5696 - loss: 0.6913 - precision: 0.0556 - recall: 0.4638        \n",
      "Epoch 2/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3975 - loss: 0.7027 - precision: 0.0809 - recall: 0.8576 \n",
      "Epoch 3/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6132 - loss: 0.7271 - precision: 0.0976 - recall: 0.5365 \n",
      "Epoch 4/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7724 - loss: 0.6733 - precision: 0.1104 - recall: 0.4498 \n",
      "Epoch 5/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 0.6569 - precision: 0.0753 - recall: 0.7053 \n",
      "Epoch 6/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6371 - loss: 0.6968 - precision: 0.0806 - recall: 0.5416 \n",
      "Epoch 7/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.6554 - precision: 0.0930 - recall: 0.4793 \n",
      "Epoch 8/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6450 - loss: 0.6410 - precision: 0.0850 - recall: 0.5734 \n",
      "Epoch 9/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3897 - loss: 0.6560 - precision: 0.0779 - recall: 0.8771 \n",
      "Epoch 10/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8004 - loss: 0.6376 - precision: 0.0922 - recall: 0.3235 \n",
      "Epoch 11/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5017 - loss: 0.6709 - precision: 0.0872 - recall: 0.7881 \n",
      "Epoch 12/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6675 - loss: 0.6149 - precision: 0.0884 - recall: 0.6281 \n",
      "Epoch 13/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4121 - loss: 0.6498 - precision: 0.0651 - recall: 0.7634 \n",
      "Epoch 14/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5642 - loss: 0.6366 - precision: 0.0777 - recall: 0.6722 \n",
      "Epoch 15/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5753 - loss: 0.6609 - precision: 0.0858 - recall: 0.6606 \n",
      "Epoch 16/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6699 - loss: 0.6674 - precision: 0.0863 - recall: 0.5352 \n",
      "Epoch 17/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6414 - loss: 0.6124 - precision: 0.0944 - recall: 0.6926 \n",
      "Epoch 18/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5282 - loss: 0.6464 - precision: 0.0854 - recall: 0.7396 \n",
      "Epoch 19/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6350 - loss: 0.6377 - precision: 0.1003 - recall: 0.6483 \n",
      "Epoch 20/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6422 - loss: 0.6012 - precision: 0.0913 - recall: 0.6639 \n",
      "Epoch 21/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6595 - loss: 0.6126 - precision: 0.0995 - recall: 0.6658 \n",
      "Epoch 22/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4435 - loss: 0.6531 - precision: 0.0825 - recall: 0.8121 \n",
      "Epoch 23/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7882 - loss: 0.6168 - precision: 0.1142 - recall: 0.4536 \n",
      "Epoch 24/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5009 - loss: 0.6425 - precision: 0.0790 - recall: 0.7353 \n",
      "Epoch 25/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7611 - loss: 0.6154 - precision: 0.0997 - recall: 0.4544 \n",
      "Epoch 26/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6173 - loss: 0.6038 - precision: 0.0962 - recall: 0.7128 \n",
      "Epoch 27/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5083 - loss: 0.6429 - precision: 0.0704 - recall: 0.6667 \n",
      "Epoch 28/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5892 - loss: 0.6092 - precision: 0.0876 - recall: 0.7252 \n",
      "Epoch 29/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5797 - loss: 0.6384 - precision: 0.0960 - recall: 0.7487 \n",
      "Epoch 30/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5773 - loss: 0.6792 - precision: 0.0949 - recall: 0.6560 \n",
      "Epoch 31/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6384 - loss: 0.5936 - precision: 0.0697 - recall: 0.5264 \n",
      "Epoch 32/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3724 - loss: 0.6577 - precision: 0.0665 - recall: 0.8027 \n",
      "Epoch 33/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6091 - loss: 0.6702 - precision: 0.1078 - recall: 0.6781 \n",
      "Epoch 34/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.6186 - precision: 0.1006 - recall: 0.5617 \n",
      "Epoch 35/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5269 - loss: 0.6189 - precision: 0.0868 - recall: 0.8163 \n",
      "Epoch 36/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 0.6714 - precision: 0.0943 - recall: 0.6599 \n",
      "Epoch 37/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6303 - loss: 0.6125 - precision: 0.0873 - recall: 0.6617 \n",
      "Epoch 38/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4877 - loss: 0.6421 - precision: 0.0832 - recall: 0.7904 \n",
      "Epoch 39/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 0.6372 - precision: 0.1029 - recall: 0.5832 \n",
      "Epoch 40/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6595 - loss: 0.5991 - precision: 0.1066 - recall: 0.7319 \n",
      "Epoch 41/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.5890 - precision: 0.0873 - recall: 0.6380 \n",
      "Epoch 42/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 0.5995 - precision: 0.0971 - recall: 0.7415 \n",
      "Epoch 43/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6818 - loss: 0.6002 - precision: 0.1039 - recall: 0.6287 \n",
      "Epoch 44/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6375 - loss: 0.5957 - precision: 0.0909 - recall: 0.6491 \n",
      "Epoch 45/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5991 - loss: 0.6120 - precision: 0.0891 - recall: 0.6783 \n",
      "Epoch 46/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6851 - loss: 0.6376 - precision: 0.1041 - recall: 0.5823 \n",
      "Epoch 47/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6305 - loss: 0.6219 - precision: 0.1131 - recall: 0.7406 \n",
      "Epoch 48/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7209 - loss: 0.5679 - precision: 0.1224 - recall: 0.6945 \n",
      "Epoch 49/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6834 - loss: 0.5642 - precision: 0.0999 - recall: 0.7103 \n",
      "Epoch 50/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6236 - loss: 0.5896 - precision: 0.0947 - recall: 0.7561 \n",
      "Epoch 51/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7768 - loss: 0.6034 - precision: 0.1234 - recall: 0.5103 \n",
      "Epoch 52/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6605 - loss: 0.6199 - precision: 0.0923 - recall: 0.6286 \n",
      "Epoch 53/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7617 - loss: 0.6007 - precision: 0.1450 - recall: 0.6439 \n",
      "Epoch 54/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.6199 - precision: 0.1446 - recall: 0.6574 \n",
      "Epoch 55/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.6063 - precision: 0.1466 - recall: 0.5542 \n",
      "Epoch 56/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7104 - loss: 0.6431 - precision: 0.1229 - recall: 0.5933 \n",
      "Epoch 57/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.5787 - precision: 0.1281 - recall: 0.5801 \n",
      "Epoch 58/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7133 - loss: 0.6005 - precision: 0.1274 - recall: 0.6954 \n",
      "Epoch 59/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7141 - loss: 0.5964 - precision: 0.1187 - recall: 0.6172 \n",
      "Epoch 60/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7408 - loss: 0.6184 - precision: 0.1165 - recall: 0.5702 \n",
      "Epoch 61/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7028 - loss: 0.5931 - precision: 0.1170 - recall: 0.6469 \n",
      "Epoch 62/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7774 - loss: 0.6099 - precision: 0.1190 - recall: 0.4822 \n",
      "Epoch 63/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7004 - loss: 0.6515 - precision: 0.1202 - recall: 0.6156 \n",
      "Epoch 64/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7907 - loss: 0.5816 - precision: 0.1295 - recall: 0.5157 \n",
      "Epoch 65/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7337 - loss: 0.5794 - precision: 0.1279 - recall: 0.6135 \n",
      "Epoch 66/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7213 - loss: 0.6271 - precision: 0.1357 - recall: 0.6297 \n",
      "Epoch 67/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7807 - loss: 0.5673 - precision: 0.1651 - recall: 0.6596 \n",
      "Epoch 68/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7402 - loss: 0.6272 - precision: 0.1158 - recall: 0.5687 \n",
      "Epoch 69/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7807 - loss: 0.5421 - precision: 0.1433 - recall: 0.6566 \n",
      "Epoch 70/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6683 - loss: 0.6047 - precision: 0.1091 - recall: 0.6512 \n",
      "Epoch 71/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8157 - loss: 0.5676 - precision: 0.1254 - recall: 0.4620         \n",
      "Epoch 72/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.5817 - precision: 0.1034 - recall: 0.6143 \n",
      "Epoch 73/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7509 - loss: 0.5499 - precision: 0.1404 - recall: 0.7124 \n",
      "Epoch 74/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7825 - loss: 0.5430 - precision: 0.1229 - recall: 0.5825 \n",
      "Epoch 75/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7443 - loss: 0.5975 - precision: 0.1432 - recall: 0.6838 \n",
      "Epoch 76/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.6447 - precision: 0.1449 - recall: 0.6171 \n",
      "Epoch 77/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7935 - loss: 0.5682 - precision: 0.1462 - recall: 0.5814 \n",
      "Epoch 78/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7316 - loss: 0.5495 - precision: 0.1308 - recall: 0.6922 \n",
      "Epoch 79/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7932 - loss: 0.5538 - precision: 0.1435 - recall: 0.6294 \n",
      "Epoch 80/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7614 - loss: 0.5990 - precision: 0.1341 - recall: 0.5983 \n",
      "Epoch 81/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7826 - loss: 0.5606 - precision: 0.1264 - recall: 0.5662 \n",
      "Epoch 82/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7049 - loss: 0.5919 - precision: 0.1085 - recall: 0.6130 \n",
      "Epoch 83/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7649 - loss: 0.5279 - precision: 0.1344 - recall: 0.6808 \n",
      "Epoch 84/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5643 - precision: 0.1176 - recall: 0.6061 \n",
      "Epoch 85/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.6150 - precision: 0.1115 - recall: 0.5530 \n",
      "Epoch 86/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.6182 - precision: 0.1190 - recall: 0.5463 \n",
      "Epoch 87/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8077 - loss: 0.5329 - precision: 0.1595 - recall: 0.6234 \n",
      "Epoch 88/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7153 - loss: 0.5646 - precision: 0.1284 - recall: 0.7175 \n",
      "Epoch 89/89\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.5973 - precision: 0.1511 - recall: 0.6375 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b5813fa084466283d592dabc90bd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▅▄▅█▃▅▅▅▆▃▆▄▅▃▄▆▇▆▅▆▆▇▅█▇▆▇▆▇▇█▇▇▇▇▆▇█▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▅▅▄▃▄▄▄▄▃▄▄▄▃▅▄▄▄▃▃▃▄▃▃▃▄▃▇▄▃▄▄▃▃█▂▃▃▃▁▂</td></tr><tr><td>batch/precision</td><td>▂▂▂▁▂▁▁▂▂▂▂▂▁▂▁▂▂▁▂▁▃▃▃▂▆▄▃▄▃▅▄▁▄█▄▅▂▄▆▅</td></tr><tr><td>batch/recall</td><td>█▄▆▅▁▆▅▅▅▅▆▅▇▆▆▆▅▂▅▄▅▅▄▅▄▅▄▄▅▅▅▁▆▄▅▅▅▅▆▆</td></tr><tr><td>epoch/accuracy</td><td>▄▂▃▅█▆▄▅▄▅▇▆▃▃▁▅▅▄▅▅▄▆▄▅▇▆▅▅▇▆▆▆▆▆▇▇▆▇▆▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▇▆▆▇▆▅▅▄▅▆▅▄▄▅▅▄▅▃▃▃▂▄▂▂▂▂▂▃▂▂▂▂▁▁▁▂▁▂▁</td></tr><tr><td>epoch/precision</td><td>▁▂▃▃▄▄▃▃▃▄▅▄▃▂▂▃▄▃▄▄▃▅▃▅▇▅▄▄▆▅▆▅▅▆▇█▆▆▅▇</td></tr><tr><td>epoch/recall</td><td>▄▆▇▄▁▅▆▅▆▅▃▄▇▇█▆▆▇▆▆▆▆▇▇▅▆▆▆▅▆▆▆▇▇▅▆▆▅▅▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.7321</td></tr><tr><td>batch/accuracy</td><td>0.75597</td></tr><tr><td>batch/batch_step</td><td>1156</td></tr><tr><td>batch/loss</td><td>0.578</td></tr><tr><td>batch/precision</td><td>0.1352</td></tr><tr><td>batch/recall</td><td>0.64634</td></tr><tr><td>epoch/accuracy</td><td>0.75597</td></tr><tr><td>epoch/epoch</td><td>88</td></tr><tr><td>epoch/loss</td><td>0.578</td></tr><tr><td>epoch/precision</td><td>0.1352</td></tr><tr><td>epoch/recall</td><td>0.64634</td></tr><tr><td>f1_score</td><td>0.20472</td></tr><tr><td>precision</td><td>0.1215</td></tr><tr><td>recall</td><td>0.65</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-sweep-30</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/t8q3u4i7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/t8q3u4i7/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000702-t8q3u4i7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhimhvn2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 91\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02919329434218575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000717-bhimhvn2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/bhimhvn2/workspace' target=\"_blank\">comfy-sweep-31</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/bhimhvn2/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/bhimhvn2/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.7101 - loss: 0.4484 - precision: 0.0511 - recall: 0.2359\n",
      "Epoch 2/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.2531 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.2234 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2272 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.2048 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1844 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1962 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.1880 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9538 - loss: 0.1852 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2103 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.2097 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.2162 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9557 - loss: 0.1741 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.2227 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9383 - loss: 0.2305 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.2025 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1909 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1949 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2040 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1986 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2100 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1956 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2056 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1835 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1916 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1900 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.2005 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9551 - loss: 0.1811 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2151 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1914 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.2196 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1967 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1947 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2094 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.2081 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1900 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1939 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1896 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1939 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.1918 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1917 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2082 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.1888 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2102 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1957 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.2056 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2111 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2035 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 64/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1958 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 65/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1824 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 66/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.2002 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 67/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.2029 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 68/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1921 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 69/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1987 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 70/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 71/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 72/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 73/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 74/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.2187 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 75/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1941 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 76/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 77/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.2044 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 78/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2032 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 79/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.2020 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 80/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.2028 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 81/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1860 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 82/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2114 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 83/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1934 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 84/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2184 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 85/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2180 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 86/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 87/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2035 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 88/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1957 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 89/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 90/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2060 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 91/91\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1961 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a22378683b4d14a154f098d96bb0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▄▄▅▅▄▄▅▅▆▇▅▁▇▆▆▅▅▅▄▄▅▂▆▅▅▅▅▅█▆▆▅▇▄▆▂▄▅▅▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▃▃▄▃▃▃▂▂▃▆▂▃▂▃▄▃▃▃▃▄▂▃▃▂▃▃▁▂▂▃▃▄▂▆▄▃▃▂</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▂▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>636</td></tr><tr><td>batch/loss</td><td>0.19924</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>90</td></tr><tr><td>epoch/loss</td><td>0.19924</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-31</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/bhimhvn2/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/bhimhvn2/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000717-bhimhvn2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vyz0712o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.012823047067944324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000733-vyz0712o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vyz0712o/workspace' target=\"_blank\">copper-sweep-32</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vyz0712o/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vyz0712o/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9425 - loss: 0.4210 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.2432 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.2090 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2170 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2095 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1942 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9428 - loss: 0.2110 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.2080 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1988 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.1988 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/12\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1914 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aaa29936927462fa5bdf90e2c06bb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▃▄▄▆▄▄▆▄▅▆▄▅▄▄▄▅▇▅▄▆▃▄▃▄▄▄▄▅▄█▆▄▄▅▅▄█▄▄</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▄▄▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▁▁▁▁▁▁▂</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>107</td></tr><tr><td>batch/loss</td><td>0.21133</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>11</td></tr><tr><td>epoch/loss</td><td>0.21133</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-sweep-32</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vyz0712o/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vyz0712o/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000733-vyz0712o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s2oymh4y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 48\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0631258833853658\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000744-s2oymh4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/s2oymh4y/workspace' target=\"_blank\">elated-sweep-33</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/s2oymh4y/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/s2oymh4y/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5104 - loss: 0.7369 - precision: 0.0618 - recall: 0.5747\n",
      "Epoch 2/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 0.7717 - precision: 0.0690 - recall: 1.0000 \n",
      "Epoch 3/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6059 - loss: 0.7132 - precision: 0.0454 - recall: 0.3043 \n",
      "Epoch 4/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8316 - loss: 0.6741 - precision: 0.0213 - recall: 0.1120         \n",
      "Epoch 5/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3678 - loss: 0.7077 - precision: 0.0537 - recall: 0.6144 \n",
      "Epoch 6/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8376 - loss: 0.6913 - precision: 0.0625 - recall: 0.1375 \n",
      "Epoch 7/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1618 - loss: 0.7193 - precision: 0.0538 - recall: 0.8437         \n",
      "Epoch 8/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8132 - loss: 0.6876 - precision: 0.0248 - recall: 0.1365         \n",
      "Epoch 9/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5703 - loss: 0.7085 - precision: 0.0632 - recall: 0.4679 \n",
      "Epoch 10/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.6827 - precision: 0.0243 - recall: 0.0884 \n",
      "Epoch 11/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0621 - loss: 0.7352 - precision: 0.0613 - recall: 1.0000 \n",
      "Epoch 12/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.6898 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2484 - loss: 0.7011 - precision: 0.0513 - recall: 0.7848        \n",
      "Epoch 14/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6108 - loss: 0.6852 - precision: 0.0474 - recall: 0.3472\n",
      "Epoch 15/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6200 - loss: 0.6783 - precision: 0.0480 - recall: 0.3451\n",
      "Epoch 16/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1771 - loss: 0.7817 - precision: 0.0691 - recall: 0.8932        \n",
      "Epoch 17/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.6950 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5015 - loss: 0.6957 - precision: 0.0441 - recall: 0.4731         \n",
      "Epoch 19/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.6745 - precision: 0.0398 - recall: 0.3788         \n",
      "Epoch 20/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1607 - loss: 0.7361 - precision: 0.0616 - recall: 0.8889 \n",
      "Epoch 21/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.6882 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7545 - loss: 0.6512 - precision: 0.0423 - recall: 0.2029 \n",
      "Epoch 23/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0674 - loss: 0.7398 - precision: 0.0607 - recall: 0.9902 \n",
      "Epoch 24/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5836 - loss: 0.6959 - precision: 0.0405 - recall: 0.3869         \n",
      "Epoch 25/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1808 - loss: 0.6951 - precision: 0.0498 - recall: 0.7883 \n",
      "Epoch 26/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6272 - loss: 0.6742 - precision: 0.0578 - recall: 0.4065 \n",
      "Epoch 27/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1318 - loss: 0.6621 - precision: 0.0476 - recall: 0.8950 \n",
      "Epoch 28/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0539 - loss: 0.6916 - precision: 0.0539 - recall: 1.0000 \n",
      "Epoch 29/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4789 - loss: 0.6998 - precision: 0.0587 - recall: 0.5548 \n",
      "Epoch 30/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7328 - loss: 0.6392 - precision: 0.0316 - recall: 0.2145         \n",
      "Epoch 31/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1499 - loss: 0.6742 - precision: 0.0501 - recall: 0.8820 \n",
      "Epoch 32/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3144 - loss: 0.6657 - precision: 0.0475 - recall: 0.7180         \n",
      "Epoch 33/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0587 - loss: 0.7205 - precision: 0.0587 - recall: 1.0000 \n",
      "Epoch 34/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2408 - loss: 0.7360 - precision: 0.0579 - recall: 0.7513 \n",
      "Epoch 35/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.6303 - precision: 0.0058 - recall: 0.0063         \n",
      "Epoch 36/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0559 - loss: 0.7035 - precision: 0.0559 - recall: 1.0000 \n",
      "Epoch 37/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.6470 - precision: 0.0316 - recall: 0.1814 \n",
      "Epoch 38/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2463 - loss: 0.7035 - precision: 0.0501 - recall: 0.7595         \n",
      "Epoch 39/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4001 - loss: 0.7097 - precision: 0.0593 - recall: 0.6325 \n",
      "Epoch 40/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.6871 - precision: 0.0274 - recall: 0.1408         \n",
      "Epoch 41/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0585 - loss: 0.7139 - precision: 0.0578 - recall: 0.9993 \n",
      "Epoch 42/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.6775 - precision: 0.0058 - recall: 0.0063         \n",
      "Epoch 43/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0638 - loss: 0.7109 - precision: 0.0570 - recall: 0.9929 \n",
      "Epoch 44/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6258 - loss: 0.6805 - precision: 0.0396 - recall: 0.3212         \n",
      "Epoch 45/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2676 - loss: 0.7469 - precision: 0.0589 - recall: 0.7585         \n",
      "Epoch 46/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.6756 - precision: 0.0125 - recall: 0.0247         \n",
      "Epoch 47/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7420 - loss: 0.6467 - precision: 0.0319 - recall: 0.1792 \n",
      "Epoch 48/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0536 - loss: 0.6890 - precision: 0.0536 - recall: 1.0000 \n",
      "Epoch 49/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7313 - loss: 0.6838 - precision: 0.0409 - recall: 0.2016 \n",
      "Epoch 50/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2576 - loss: 0.7101 - precision: 0.0475 - recall: 0.6635         \n",
      "Epoch 51/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4218 - loss: 0.7197 - precision: 0.0434 - recall: 0.4856         \n",
      "Epoch 52/52\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4088 - loss: 0.6675 - precision: 0.0424 - recall: 0.5543         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5979b5b08923412686ccab2da1900271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▁▅▅█▁▅█▁█▆▇▁▃▅▄▇▁▅▆▁▁▇▁▃▂█▁█▄▅▁▁▆▂▇▁▇▂▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇█▅▄▄▄▄▄▄▅▃▅▅▅▄▅▂▇▅▁▃▄▄▄▅▇▄▄▅▄▅▅▄▅▆▃▄▅▄▅</td></tr><tr><td>batch/precision</td><td>▇█▆▆█▇▆▃▇▁▆▆▇▇▆▇▆█▇▇▆▇▆▇▇▇▁▇▄▇▇▇▇▆▇▄▇▅▆▆</td></tr><tr><td>batch/recall</td><td>▆█▃▄▂█▄▁█▁▃▂█▆▄▅▂█▄▃██▂█▆▆▁█▁▅▄██▃▇▂█▂▆▄</td></tr><tr><td>epoch/accuracy</td><td>▅▁▅▅█▁▅▇▁█▇▇▁▄▃▄█▂▅▂▃▁▆▄▃▁▇▁█▁▅▁▇▆▂▇▁▇▃▅</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▂▁▂▁▁▂▁▃▁▂▂▂▂▂▁▄▂▁▂▁▃▃▂▂▂▁▃▂▃▂▂▂▄▂▁▂▂▂</td></tr><tr><td>epoch/precision</td><td>█▇▆▇█▇▆▅▇▁▆▆▇▇▇▇▁▇▇▆▆▇▇▇▇▇▆▇▅▇▇▇▆▆▇▄▇▅▆▆</td></tr><tr><td>epoch/recall</td><td>▄█▃▄▁█▄▂█▁▂▂█▄▆▅▁▇▄▆▅█▃▅▆█▁█▁▇▄█▁▃▇▁█▂▅▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.05305</td></tr><tr><td>batch/accuracy</td><td>0.50133</td></tr><tr><td>batch/batch_step</td><td>1663</td></tr><tr><td>batch/loss</td><td>0.69939</td></tr><tr><td>batch/precision</td><td>0.0473</td></tr><tr><td>batch/recall</td><td>0.42683</td></tr><tr><td>epoch/accuracy</td><td>0.50133</td></tr><tr><td>epoch/epoch</td><td>51</td></tr><tr><td>epoch/loss</td><td>0.69939</td></tr><tr><td>epoch/precision</td><td>0.0473</td></tr><tr><td>epoch/recall</td><td>0.42683</td></tr><tr><td>f1_score</td><td>0.10076</td></tr><tr><td>precision</td><td>0.05305</td></tr><tr><td>recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-sweep-33</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/s2oymh4y/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/s2oymh4y/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000744-s2oymh4y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x8noebsd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 176\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 79\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08686937235015521\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000810-x8noebsd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x8noebsd/workspace' target=\"_blank\">northern-sweep-34</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x8noebsd/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/x8noebsd/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.7781 - loss: 0.3993 - precision: 0.0614 - recall: 0.2196\n",
      "Epoch 2/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1936 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.2166 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2076 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1916 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.2084 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2114 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1966 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1862 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.2073 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1991 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.2008 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.2192 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.2040 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2110 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1852 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2079 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.2186 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1886 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.2148 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1973 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1962 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2119 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1898 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2140 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1873 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.1909 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1888 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1976 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.2015 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1890 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1923 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2077 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1979 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9403 - loss: 0.2154 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.2217 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2056 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9485 - loss: 0.1922 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2061 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1927 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1868 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1798 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 64/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2097 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 65/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9410 - loss: 0.2152 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 66/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9437 - loss: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 67/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.2118 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 68/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1712 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 69/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2155 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 70/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2104 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 71/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2090 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 72/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.2087 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 73/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9438 - loss: 0.1993 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 74/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 75/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9381 - loss: 0.2154 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 76/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.2048 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 77/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1886 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 78/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 79/79\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1991 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d997c5865dc4344b2e5ba5577fe4cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▆▇▇▆▇▇▇▆▆▇▇▇▆▇▇▇█▇▇▇▆▆▇▇▆▆▇▆▇█▇▇█▆▇▆▆▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▂▄▂▃▃▃▂▃▃▃▃▃▃▃▂▃▃▁▂▃▂▃▄▃▃▄▃▃▃▃▂▃▃▁▄▃▃▃▃</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▁▂▁▁▂▂▁▂▁▁▁▂▂▁▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▂▂▁▁▂▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>710</td></tr><tr><td>batch/loss</td><td>0.19501</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>78</td></tr><tr><td>epoch/loss</td><td>0.19501</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-sweep-34</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x8noebsd/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/x8noebsd/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000810-x8noebsd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r76sxxvx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01812643118282017\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0edc8a14824e6ca6ef8a5919811ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112172255525365, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000826-r76sxxvx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/r76sxxvx/workspace' target=\"_blank\">dauntless-sweep-35</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/r76sxxvx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/r76sxxvx/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9400 - loss: 0.3927 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9484 - loss: 0.2815 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2392 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.2177 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.2378 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2231 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2187 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2139 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.1956 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.2035 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.1918 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.2187 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9501 - loss: 0.1964 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.2129 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.2088 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.2060 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9476 - loss: 0.1942 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.2145 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9455 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.2076 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9450 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1892 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.2040 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1971 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.2047 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.2151 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.2153 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1974 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/40\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2091 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d7998baff348519e4a1f5d9eca0cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▅▅▆▅▅▁▅▅▆█▇▅▆▅▅▅▆▅▅▆▅▅▅▆▆▆▅▅▆▆▅▆▄▆▅▆▆▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▃▂▃▄▃▂▂▁▁▃▂▂▃▃▂▂▃▂▂▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▃</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>▆█▄▃▃▁▃▂▁▁▄▂▁▁▂▄▃▃▃▂▁▁▃▂▃▁▁▂▁▁▁▂▂▃▁▂▃▂▄▃</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>279</td></tr><tr><td>batch/loss</td><td>0.21682</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>39</td></tr><tr><td>epoch/loss</td><td>0.21682</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-sweep-35</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/r76sxxvx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/r76sxxvx/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000826-r76sxxvx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x3irb857 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 53\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.05335301973518374\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000841-x3irb857</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x3irb857/workspace' target=\"_blank\">twilight-sweep-36</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x3irb857/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/x3irb857/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.6547 - loss: 0.4216 - precision: 0.0288 - recall: 0.2513\n",
      "Epoch 2/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.2558 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2198 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.2141 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2224 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.1869 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.2182 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9429 - loss: 0.2221 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.1939 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.2219 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1949 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2049 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.2047 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1895 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2068 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2241 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2105 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.2091 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9511 - loss: 0.1904 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.2006 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2058 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9433 - loss: 0.2128 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1974 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1999 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1988 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2009 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.2021 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9379 - loss: 0.2234 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.2193 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2119 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1910 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1981 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.2052 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9463 - loss: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1874 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.2274 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2020 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1869 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/53\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9404 - loss: 0.2105 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bd3722210f48bfa722475faed6e488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▁▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▂▁▂▁▂▁▁▂▂▂▂▂▁▂▁▂▂▁▂▁▂▂▁▂▂▁▁▁▁▂▂▁▁▂▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>423</td></tr><tr><td>batch/loss</td><td>0.19055</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>52</td></tr><tr><td>epoch/loss</td><td>0.19055</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-36</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/x3irb857/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/x3irb857/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000841-x3irb857/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9wrenfx7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 216\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 63\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.003405497911026467\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000903-9wrenfx7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9wrenfx7/workspace' target=\"_blank\">eternal-sweep-37</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9wrenfx7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/9wrenfx7/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.4689 - loss: 0.6730 - precision: 0.0575 - recall: 0.5551\n",
      "Epoch 2/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9473 - loss: 0.3365 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.2170 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.2435 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.2099 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2152 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2181 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9441 - loss: 0.2142 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2099 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9531 - loss: 0.1850 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1773 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1993 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2075 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1999 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2124 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2135 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.2209 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9477 - loss: 0.1952 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2005 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1886 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1884 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.2145 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.2202 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.1976 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1970 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1810 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1906 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9485 - loss: 0.1899 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2124 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.2214 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.2176 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1949 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1918 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.2141 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2011 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1833 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1966 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9461 - loss: 0.1934 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.1880 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1839 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9427 - loss: 0.2034 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1956 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.2156 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/63\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2087 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0cf2538e30459e89ee4b8394f5893a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁█▇▇█████████▇████████████████████████▇█</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>440</td></tr><tr><td>batch/loss</td><td>0.19776</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>62</td></tr><tr><td>epoch/loss</td><td>0.19776</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eternal-sweep-37</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9wrenfx7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/9wrenfx7/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000903-9wrenfx7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6pv11lhx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.09770356563969736\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000918-6pv11lhx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/6pv11lhx/workspace' target=\"_blank\">warm-sweep-38</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/6pv11lhx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/6pv11lhx/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8525 - loss: 0.2870 - precision: 0.0500 - recall: 0.1150\n",
      "Epoch 2/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.2421 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.2060 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1968 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2264 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.2070 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2156 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9341 - loss: 0.2412 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1927 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.2238 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2177 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1912 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.2026 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2108 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9498 - loss: 0.1917 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1990 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1987 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.2061 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1795 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2115 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1949 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2026 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.2187 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9570 - loss: 0.1704 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9295 - loss: 0.2506 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1709 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1981 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1888 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1930 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2135 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2200 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1900 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1921 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1795 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2148 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2123 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2167 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.2148 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.2137 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1837 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.2052 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.2435 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.2177 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1899 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1944 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.2199 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 64/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 65/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.2242 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 66/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2086 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 67/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1867 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 68/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 69/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1974 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 70/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.2178 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 71/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2110 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 72/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 73/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 74/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2164 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 75/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.2204 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 76/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 77/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1894 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 78/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1924 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 79/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1958 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 80/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2120 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 81/81\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.2304 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff07dcca259042ecace6c0cf384f7800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▅▆▆▅▆▇▆▆█▆▆▅▆▆▅▄▁▇▄▆▅▆▅▆▆▆▅▆▅▆▅▆▆▆▄▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▄▇▅▅▅▅▃▅▅▁▅▄▅▅▅▅▇█▄▇▅▅▅▆▄▅▅▅▅▆▅▆▅▄▄▇▅▅▅</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▃▂▂▂▂▂▁▂▁▁▁▂▂▁▂▁▂▁▂▁▂▁▁▂▁▁▂▂▂▂▁▁▁▂▂▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>3077</td></tr><tr><td>batch/loss</td><td>0.20384</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>80</td></tr><tr><td>epoch/loss</td><td>0.20384</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">warm-sweep-38</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/6pv11lhx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/6pv11lhx/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000918-6pv11lhx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2khduqi5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.038161774056619115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000950-2khduqi5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2khduqi5/workspace' target=\"_blank\">distinctive-sweep-39</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2khduqi5/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2khduqi5/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.6022 - loss: 0.6769 - precision: 0.0712 - recall: 0.5560\n",
      "Epoch 2/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5018 - loss: 0.6404 - precision: 0.0719 - recall: 0.7367 \n",
      "Epoch 3/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6032 - loss: 0.6353 - precision: 0.0958 - recall: 0.7309 \n",
      "Epoch 4/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5089 - loss: 0.6390 - precision: 0.0789 - recall: 0.7710 \n",
      "Epoch 5/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5183 - loss: 0.6871 - precision: 0.1016 - recall: 0.7796 \n",
      "Epoch 6/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7839 - loss: 0.6249 - precision: 0.0982 - recall: 0.3942 \n",
      "Epoch 7/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4314 - loss: 0.6381 - precision: 0.0722 - recall: 0.8230 \n",
      "Epoch 8/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5244 - loss: 0.6640 - precision: 0.0851 - recall: 0.7166 \n",
      "Epoch 9/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.6376 - precision: 0.1031 - recall: 0.6375 \n",
      "Epoch 10/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5374 - loss: 0.6232 - precision: 0.0827 - recall: 0.7609 \n",
      "Epoch 11/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6133 - loss: 0.6287 - precision: 0.0918 - recall: 0.6920 \n",
      "Epoch 12/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5572 - loss: 0.6498 - precision: 0.0798 - recall: 0.6631 \n",
      "Epoch 13/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6159 - loss: 0.6509 - precision: 0.1018 - recall: 0.6840 \n",
      "Epoch 14/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5242 - loss: 0.6231 - precision: 0.0783 - recall: 0.7154 \n",
      "Epoch 15/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5572 - loss: 0.6486 - precision: 0.0903 - recall: 0.7234 \n",
      "Epoch 16/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6245 - loss: 0.6309 - precision: 0.0988 - recall: 0.6685 \n",
      "Epoch 17/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6280 - loss: 0.6041 - precision: 0.0939 - recall: 0.6831 \n",
      "Epoch 18/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5046 - loss: 0.5998 - precision: 0.0685 - recall: 0.7452 \n",
      "Epoch 19/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5524 - loss: 0.5959 - precision: 0.0797 - recall: 0.7564 \n",
      "Epoch 20/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5613 - loss: 0.6613 - precision: 0.1065 - recall: 0.8018 \n",
      "Epoch 21/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6367 - loss: 0.6845 - precision: 0.0912 - recall: 0.5536 \n",
      "Epoch 22/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5716 - loss: 0.6267 - precision: 0.0900 - recall: 0.7151 \n",
      "Epoch 23/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6278 - loss: 0.5657 - precision: 0.0914 - recall: 0.7512 \n",
      "Epoch 24/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4053 - loss: 0.6620 - precision: 0.0840 - recall: 0.9025 \n",
      "Epoch 25/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7481 - loss: 0.6102 - precision: 0.1142 - recall: 0.5414 \n",
      "Epoch 26/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4407 - loss: 0.6438 - precision: 0.0786 - recall: 0.8321 \n",
      "Epoch 27/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 0.6270 - precision: 0.1001 - recall: 0.7559 \n",
      "Epoch 28/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5617 - loss: 0.6282 - precision: 0.0914 - recall: 0.7518 \n",
      "Epoch 29/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6544 - loss: 0.5727 - precision: 0.1089 - recall: 0.7773 \n",
      "Epoch 30/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5497 - loss: 0.6145 - precision: 0.1015 - recall: 0.8238 \n",
      "Epoch 31/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6121 - loss: 0.6304 - precision: 0.1014 - recall: 0.6979 \n",
      "Epoch 32/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.5972 - precision: 0.1212 - recall: 0.6680 \n",
      "Epoch 33/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5688 - loss: 0.5996 - precision: 0.0972 - recall: 0.7842 \n",
      "Epoch 34/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5841 - loss: 0.5496 - precision: 0.0887 - recall: 0.8592 \n",
      "Epoch 35/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.5903 - precision: 0.1141 - recall: 0.5958 \n",
      "Epoch 36/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6058 - loss: 0.5515 - precision: 0.0900 - recall: 0.7953 \n",
      "Epoch 37/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5930 - loss: 0.5686 - precision: 0.0864 - recall: 0.7399 \n",
      "Epoch 38/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6096 - loss: 0.5633 - precision: 0.1012 - recall: 0.8273 \n",
      "Epoch 39/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5178 - loss: 0.6241 - precision: 0.0940 - recall: 0.8361 \n",
      "Epoch 40/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6779 - loss: 0.5813 - precision: 0.0973 - recall: 0.6389 \n",
      "Epoch 41/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6214 - loss: 0.6003 - precision: 0.1086 - recall: 0.7782 \n",
      "Epoch 42/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6116 - loss: 0.6150 - precision: 0.1108 - recall: 0.7589 \n",
      "Epoch 43/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7998 - loss: 0.5619 - precision: 0.1326 - recall: 0.5421 \n",
      "Epoch 44/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4797 - loss: 0.6120 - precision: 0.0888 - recall: 0.8779 \n",
      "Epoch 45/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6205 - loss: 0.6384 - precision: 0.1103 - recall: 0.7443 \n",
      "Epoch 46/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7947 - loss: 0.5317 - precision: 0.1469 - recall: 0.6661 \n",
      "Epoch 47/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4896 - loss: 0.6245 - precision: 0.0832 - recall: 0.7866 \n",
      "Epoch 48/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7833 - loss: 0.5752 - precision: 0.1242 - recall: 0.5800 \n",
      "Epoch 49/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5506 - loss: 0.5950 - precision: 0.0995 - recall: 0.8419 \n",
      "Epoch 50/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6987 - loss: 0.5775 - precision: 0.1291 - recall: 0.7590 \n",
      "Epoch 51/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7160 - loss: 0.5681 - precision: 0.1225 - recall: 0.6935 \n",
      "Epoch 52/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.5698 - precision: 0.1075 - recall: 0.8573 \n",
      "Epoch 53/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.5468 - precision: 0.1174 - recall: 0.6907 \n",
      "Epoch 54/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6528 - loss: 0.5575 - precision: 0.1243 - recall: 0.8178 \n",
      "Epoch 55/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7457 - loss: 0.5362 - precision: 0.1380 - recall: 0.7215 \n",
      "Epoch 56/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.5903 - precision: 0.1262 - recall: 0.6814 \n",
      "Epoch 57/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6635 - loss: 0.5523 - precision: 0.1209 - recall: 0.7973 \n",
      "Epoch 58/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - loss: 0.5848 - precision: 0.1416 - recall: 0.7439 \n",
      "Epoch 59/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7491 - loss: 0.5331 - precision: 0.1436 - recall: 0.7421 \n",
      "Epoch 60/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6275 - loss: 0.5852 - precision: 0.1226 - recall: 0.8149 \n",
      "Epoch 61/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.5606 - precision: 0.1556 - recall: 0.7195 \n",
      "Epoch 62/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6454 - loss: 0.5937 - precision: 0.1261 - recall: 0.7817 \n",
      "Epoch 63/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6986 - loss: 0.5320 - precision: 0.1210 - recall: 0.7640 \n",
      "Epoch 64/64\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7182 - loss: 0.5602 - precision: 0.1477 - recall: 0.8047 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04347923c406442192b2018c38881bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▅▄▂▇▁▆▂▄▄▄▅▄▄▃▁▇▁▄▃▇▄▇▄▅▆▅█▅▆█▇▇▅▅▆▆▇▇▇▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>██▆▂▇▄▆▆▇▆▄▇▅▇█▁▆▅▅▃▂▄▄▄▁▄▄▄▃▃▂▃▃▂▅▄▂▄▂▁</td></tr><tr><td>batch/precision</td><td>▁▂▂▃▂▄▂▃▃▃▃▂▃▃▂▄▂▃▄▆▃▆▄▄▃▅█▄▆▄█▆▅▅▆█▆▇▇▇</td></tr><tr><td>batch/recall</td><td>▁▄█▁▇▄▇▅▄▅▄▄▆▅█▂█▆▇▄▆▄▆▆▃▆▂▆▅▁▆▄▆▆▅▆▄▅▅█</td></tr><tr><td>epoch/accuracy</td><td>▅▅▅▁▁▇▂▄▅▅▆▄▄▆▅█▁▄▅▄▆▄▅▅▅▆▇▆█▆▅▇▆▆▇▆▇▆██</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▆▇▇▆▆▅▅▆▅▅▅▄▄▄▅▅▄▄▄▄▃▃▃▃▂▃▄▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▂▂▁▁▄▂▂▂▃▃▂▃▃▃▅▁▃▃▃▄▄▄▄▄▅▅▅▇▄▅▆▅▅▅▅▆▆██</td></tr><tr><td>epoch/recall</td><td>▂▄▃▇▇▂▇▅▃▄▃▄▆▄▄▁█▆▆▆▅█▆▆▆▆▃▇▅▅▇▅▆▆▅▆▆▆▅▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.60743</td></tr><tr><td>batch/accuracy</td><td>0.7374</td></tr><tr><td>batch/batch_step</td><td>767</td></tr><tr><td>batch/loss</td><td>0.55862</td></tr><tr><td>batch/precision</td><td>0.13991</td></tr><tr><td>batch/recall</td><td>0.7439</td></tr><tr><td>epoch/accuracy</td><td>0.7374</td></tr><tr><td>epoch/epoch</td><td>63</td></tr><tr><td>epoch/loss</td><td>0.55862</td></tr><tr><td>epoch/precision</td><td>0.13991</td></tr><tr><td>epoch/recall</td><td>0.7439</td></tr><tr><td>f1_score</td><td>0.14943</td></tr><tr><td>precision</td><td>0.08442</td></tr><tr><td>recall</td><td>0.65</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-39</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2khduqi5/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2khduqi5/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_000950-2khduqi5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zq818zzc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06202145103055252\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001005-zq818zzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/zq818zzc/workspace' target=\"_blank\">distinctive-sweep-40</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/zq818zzc/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/zq818zzc/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4035 - loss: 0.7336 - precision: 0.0598 - recall: 0.6362\n",
      "Epoch 2/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5173 - loss: 0.6921 - precision: 0.0510 - recall: 0.4755 \n",
      "Epoch 3/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1620 - loss: 0.6810 - precision: 0.0565 - recall: 0.9390 \n",
      "Epoch 4/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7875 - loss: 0.6964 - precision: 0.0915 - recall: 0.2955 \n",
      "Epoch 5/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5142 - loss: 0.6949 - precision: 0.0882 - recall: 0.7738 \n",
      "Epoch 6/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4995 - loss: 0.7080 - precision: 0.0660 - recall: 0.5871 \n",
      "Epoch 7/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5388 - loss: 0.6746 - precision: 0.0840 - recall: 0.7000 \n",
      "Epoch 8/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6967 - loss: 0.6490 - precision: 0.0850 - recall: 0.4863 \n",
      "Epoch 9/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5378 - loss: 0.6446 - precision: 0.0801 - recall: 0.7242 \n",
      "Epoch 10/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6153 - loss: 0.6771 - precision: 0.0985 - recall: 0.6723 \n",
      "Epoch 11/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5833 - loss: 0.6580 - precision: 0.0843 - recall: 0.6542 \n",
      "Epoch 12/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5406 - loss: 0.6264 - precision: 0.0614 - recall: 0.6155 \n",
      "Epoch 13/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6697 - loss: 0.6551 - precision: 0.0921 - recall: 0.5424 \n",
      "Epoch 14/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4979 - loss: 0.6932 - precision: 0.0871 - recall: 0.7378 \n",
      "Epoch 15/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7068 - loss: 0.5887 - precision: 0.0928 - recall: 0.5786 \n",
      "Epoch 16/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5347 - loss: 0.6647 - precision: 0.0862 - recall: 0.7232 \n",
      "Epoch 17/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5714 - loss: 0.6101 - precision: 0.0819 - recall: 0.7420 \n",
      "Epoch 18/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5704 - loss: 0.6065 - precision: 0.0745 - recall: 0.6933 \n",
      "Epoch 19/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3287 - loss: 0.6619 - precision: 0.0674 - recall: 0.9202 \n",
      "Epoch 20/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6914 - loss: 0.6234 - precision: 0.1124 - recall: 0.6492 \n",
      "Epoch 21/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5089 - loss: 0.6186 - precision: 0.0719 - recall: 0.7713 \n",
      "Epoch 22/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5859 - loss: 0.6337 - precision: 0.0855 - recall: 0.7085 \n",
      "Epoch 23/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6893 - loss: 0.5997 - precision: 0.0974 - recall: 0.6010 \n",
      "Epoch 24/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2531 - loss: 0.6767 - precision: 0.0594 - recall: 0.9369 \n",
      "Epoch 25/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7248 - loss: 0.6748 - precision: 0.1048 - recall: 0.5138 \n",
      "Epoch 26/26\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6823 - loss: 0.5734 - precision: 0.0643 - recall: 0.5156 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3befb6188643679d93f8b0581e535d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▂▅▆▅▂█▆▅▄▅▄▇▆▄▆▆▅▆▄▆▅▄▆▄▆▅▅▆▂▇▆▅▆▅▇▁▄▇▇▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▆▆▆▆▅▆▆▅▆▄▅▅▆▅▅▄▅▄▇▅▄▇▅▄▄▅▅▄▄▅▅▄▄▅▅▄▁▅</td></tr><tr><td>batch/precision</td><td>▃▂▁▂▃▅▃▅▂▃▄▄▅▃█▅▄▁▄▅▆▃▅▆▄▄▃▅▃█▅▃▆▄▆▁▃▅▁▄</td></tr><tr><td>batch/recall</td><td>▆▃▂▃▇▁▃▅▅▄▆▃▄▆▆▅▅▃▆▅▅▅▅▆▄▆▅▅█▅▅▅▆▆▃█▇▃▃▅</td></tr><tr><td>epoch/accuracy</td><td>▄▅▁█▇▆▄█▄▇▇▄▇▄▆▇▅▇▃▇▅▆▆▃█▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▄▅▃▃▅▃▂▃▂▄▂▃▂▂▃▁▃▁▄▃▂▃</td></tr><tr><td>epoch/precision</td><td>▂▁▃▃▆▄▄▆▄▇▆▅▆▄▆▆▆▆▄▇▅▆▅▄█▅</td></tr><tr><td>epoch/recall</td><td>▄▂█▁▅▄▇▄▆▅▅▆▄▆▆▃▆▅█▅▆▆▅▇▅▅</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.14589</td></tr><tr><td>batch/accuracy</td><td>0.59218</td></tr><tr><td>batch/batch_step</td><td>415</td></tr><tr><td>batch/loss</td><td>0.65697</td></tr><tr><td>batch/precision</td><td>0.08163</td></tr><tr><td>batch/recall</td><td>0.63415</td></tr><tr><td>epoch/accuracy</td><td>0.59218</td></tr><tr><td>epoch/epoch</td><td>25</td></tr><tr><td>epoch/loss</td><td>0.65697</td></tr><tr><td>epoch/precision</td><td>0.08163</td></tr><tr><td>epoch/recall</td><td>0.63415</td></tr><tr><td>f1_score</td><td>0.1105</td></tr><tr><td>precision</td><td>0.05848</td></tr><tr><td>recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-40</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/zq818zzc/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/zq818zzc/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001005-zq818zzc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: soxfpnpl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 44\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.04791772014530458\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001026-soxfpnpl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/soxfpnpl/workspace' target=\"_blank\">restful-sweep-41</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/soxfpnpl/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/soxfpnpl/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7210 - loss: 0.7762 - precision: 0.0507 - recall: 0.3066     \n",
      "Epoch 2/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3166 - loss: 0.6851 - precision: 0.0546 - recall: 0.7392 \n",
      "Epoch 3/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7022 - loss: 0.7228 - precision: 0.0793 - recall: 0.3534         \n",
      "Epoch 4/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1821 - loss: 0.6870 - precision: 0.0612 - recall: 0.9701 \n",
      "Epoch 5/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6025 - loss: 0.6475 - precision: 0.0761 - recall: 0.6251 \n",
      "Epoch 6/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4665 - loss: 0.6703 - precision: 0.0733 - recall: 0.7580 \n",
      "Epoch 7/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6544 - loss: 0.6339 - precision: 0.0795 - recall: 0.5604 \n",
      "Epoch 8/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5090 - loss: 0.6419 - precision: 0.0699 - recall: 0.7190 \n",
      "Epoch 9/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6190 - loss: 0.6122 - precision: 0.0850 - recall: 0.7073 \n",
      "Epoch 10/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5262 - loss: 0.6369 - precision: 0.0667 - recall: 0.6524 \n",
      "Epoch 11/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5487 - loss: 0.6021 - precision: 0.0753 - recall: 0.7687 \n",
      "Epoch 12/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6007 - loss: 0.6681 - precision: 0.0995 - recall: 0.6852 \n",
      "Epoch 13/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6109 - loss: 0.6370 - precision: 0.0793 - recall: 0.5874 \n",
      "Epoch 14/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6345 - loss: 0.6197 - precision: 0.0746 - recall: 0.5695 \n",
      "Epoch 15/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5923 - loss: 0.6076 - precision: 0.0813 - recall: 0.7093 \n",
      "Epoch 16/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5960 - loss: 0.6727 - precision: 0.0918 - recall: 0.6624 \n",
      "Epoch 17/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.6400 - precision: 0.0962 - recall: 0.5630 \n",
      "Epoch 18/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.6257 - precision: 0.0736 - recall: 0.6672 \n",
      "Epoch 19/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5544 - loss: 0.6156 - precision: 0.0818 - recall: 0.7511 \n",
      "Epoch 20/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6783 - loss: 0.6240 - precision: 0.0942 - recall: 0.5828 \n",
      "Epoch 21/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4928 - loss: 0.6677 - precision: 0.0720 - recall: 0.6941 \n",
      "Epoch 22/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6021 - loss: 0.6599 - precision: 0.0985 - recall: 0.6862 \n",
      "Epoch 23/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5837 - loss: 0.6921 - precision: 0.1024 - recall: 0.7010 \n",
      "Epoch 24/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6760 - loss: 0.6265 - precision: 0.0957 - recall: 0.6081 \n",
      "Epoch 25/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5027 - loss: 0.6689 - precision: 0.0846 - recall: 0.7592 \n",
      "Epoch 26/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5844 - loss: 0.6695 - precision: 0.0764 - recall: 0.5759 \n",
      "Epoch 27/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6882 - loss: 0.5964 - precision: 0.0840 - recall: 0.5373 \n",
      "Epoch 28/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4159 - loss: 0.6520 - precision: 0.0595 - recall: 0.7299 \n",
      "Epoch 29/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6092 - loss: 0.6281 - precision: 0.0840 - recall: 0.6353 \n",
      "Epoch 30/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5567 - loss: 0.6848 - precision: 0.0966 - recall: 0.6753 \n",
      "Epoch 31/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5810 - loss: 0.6571 - precision: 0.0811 - recall: 0.6461 \n",
      "Epoch 32/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6258 - loss: 0.6154 - precision: 0.0987 - recall: 0.6794 \n",
      "Epoch 33/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4845 - loss: 0.6619 - precision: 0.0891 - recall: 0.7895 \n",
      "Epoch 34/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6442 - loss: 0.5973 - precision: 0.0950 - recall: 0.6942 \n",
      "Epoch 35/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4918 - loss: 0.5916 - precision: 0.0737 - recall: 0.8580 \n",
      "Epoch 36/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5028 - loss: 0.6594 - precision: 0.0825 - recall: 0.7199 \n",
      "Epoch 37/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6703 - loss: 0.6406 - precision: 0.1226 - recall: 0.7166 \n",
      "Epoch 38/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5901 - loss: 0.6405 - precision: 0.0923 - recall: 0.7028 \n",
      "Epoch 39/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 0.6100 - precision: 0.1006 - recall: 0.6872 \n",
      "Epoch 40/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 0.6470 - precision: 0.0724 - recall: 0.6928 \n",
      "Epoch 41/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6557 - loss: 0.6189 - precision: 0.0950 - recall: 0.6098 \n",
      "Epoch 42/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6074 - loss: 0.5975 - precision: 0.0869 - recall: 0.7043 \n",
      "Epoch 43/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 0.6257 - precision: 0.0896 - recall: 0.7817 \n",
      "Epoch 44/44\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6681 - loss: 0.6548 - precision: 0.0981 - recall: 0.6001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d7d0c8b0a448b7b3f6c396844f1fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▁▆▁▅▄▆▅▄▅▅▅▅▅▅▄▅▅▄▅▅▆▄▄▆▃▄▅▅▄▅▄▄▅▅▄▆▅▄▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▅▄▃▄▃▃▃▁▄▃▂▃▃▃▁▂▄▃▄▄▃▃▃▃▃▃▁▃▃▃▃▄▃▃▃▁▃▃</td></tr><tr><td>batch/precision</td><td>▁▄█▅▆▅▆▆▄▅▇▅▅▆▆▄▅▅▅▇▇▇▆▆▆▅▆▆▅▆▇▆▆▆▇▄█▆▇▇</td></tr><tr><td>batch/recall</td><td>▁█▄█▆▇▅▆▅▇▆▅▅▆▆▆▆▅▅▆▆▅▇▆▅▇▆▆▆▇▅▆▇▆▆▅▆▆▇▅</td></tr><tr><td>epoch/accuracy</td><td>▄▆▄▁▇▄▇▆▇▆▇▆▇▆▆█▆▅█▄▅▇▅▅█▃▇▅▅▇▇▅▄▇▆▇▅▇▇█</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▄▄▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▃▂▂▂▂▂▃▁▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▂▆▄▆▅▇▄▅▄▆▅▆▆▅▅█▄▅▇▄▄▇▃▇▄▅▆▆▅▄█▆▇▅▇▇█</td></tr><tr><td>epoch/recall</td><td>▃▁▃█▃▅▃▄▄▃▃▄▄▄▅▃▄▅▃▅▅▃▅▅▃▆▄▄▅▄▃▅▆▄▄▄▆▄▄▃</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.64721</td></tr><tr><td>batch/accuracy</td><td>0.69695</td></tr><tr><td>batch/batch_step</td><td>483</td></tr><tr><td>batch/loss</td><td>0.62253</td></tr><tr><td>batch/precision</td><td>0.10359</td></tr><tr><td>batch/recall</td><td>0.59756</td></tr><tr><td>epoch/accuracy</td><td>0.69695</td></tr><tr><td>epoch/epoch</td><td>43</td></tr><tr><td>epoch/loss</td><td>0.62253</td></tr><tr><td>epoch/precision</td><td>0.10359</td></tr><tr><td>epoch/recall</td><td>0.59756</td></tr><tr><td>f1_score</td><td>0.18405</td></tr><tr><td>precision</td><td>0.1049</td></tr><tr><td>recall</td><td>0.75</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-41</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/soxfpnpl/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/soxfpnpl/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001026-soxfpnpl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1d0kl7bh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 47\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0540870168416033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001043-1d0kl7bh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1d0kl7bh/workspace' target=\"_blank\">classic-sweep-42</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1d0kl7bh/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1d0kl7bh/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9508 - loss: 0.3164 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2192 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9334 - loss: 0.2443 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.2064 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1974 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.2046 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9396 - loss: 0.2283 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2175 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.2045 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1885 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1965 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9386 - loss: 0.2225 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2108 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2060 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2132 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1932 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.2208 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.2190 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1835 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9473 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1819 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1956 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1815 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.2181 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2195 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2196 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1956 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2040 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2015 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2018 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2057 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.1977 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9406 - loss: 0.2156 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2135 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/47\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2048 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b822d2e3764499f8196a12b56a11604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▄▂▃▄█▃▃▅▄▄▁▃▃▄▄▄▃▃▃▄▄▃▅▄▅▄▆▃▂▃▃▆▄▄▄▄▄▄▄▄</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▅▄▁▅▅▃▄▄▆▅▄▄▄▄▄▄▅▄▄▄▃▄▃▄▂▅▅▅▅▂▃▄▄▄▄▄▄▄</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▃▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▁▂▂▁▁▁▁▁▁▁▂</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>892</td></tr><tr><td>batch/loss</td><td>0.20586</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>46</td></tr><tr><td>epoch/loss</td><td>0.20586</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-42</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1d0kl7bh/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1d0kl7bh/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001043-1d0kl7bh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2kgkvk92 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 46\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.05442086857281251\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001058-2kgkvk92</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2kgkvk92/workspace' target=\"_blank\">silver-sweep-43</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2kgkvk92/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2kgkvk92/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9238 - loss: 0.3188 - precision: 0.0909 - recall: 0.0377\n",
      "Epoch 2/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.2064 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.2090 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9530 - loss: 0.1832 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.2028 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9384 - loss: 0.2220 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.2050 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1857 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.2016 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2111 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1977 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.2146 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.2167 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.2259 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1998 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1990 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1816 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2146 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9344 - loss: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1709 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.2011 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2188 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1842 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.2170 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2124 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1801 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.2081 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1853 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.2007 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1926 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2133 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2018 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1731 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.2006 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1961 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2008 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2134 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.2028 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2110 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/46\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1864 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ff34ac34a1422c9e2cf5520b1ee22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▅▄▅▅▄▆▆▄▅▄▄▄█▆▄▅▄▅▁▅▅▅▇▅▄▆▅▅▄▇▆█▅▆▄▄▇▄▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▄▄▄▄▃▄▄▃▄▄▄▃▃▄▄▄▄▆▄▄▄▂▄▄▃▃▄▄▂▃▁▃▃▄▄▂▄▄</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/loss</td><td>█▃▃▂▂▂▂▂▂▁▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>965</td></tr><tr><td>batch/loss</td><td>0.20448</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>45</td></tr><tr><td>epoch/loss</td><td>0.20448</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-43</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2kgkvk92/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2kgkvk92/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001058-2kgkvk92/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: atj3e68p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 152\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.05915296974221089\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001113-atj3e68p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/atj3e68p/workspace' target=\"_blank\">pious-sweep-44</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/atj3e68p/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/atj3e68p/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9464 - loss: 0.3755 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.2298 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1993 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/5\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1996 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a144ddef09a4e399e32ff09accaef03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▅▄▅▅▅▄▄▄▁▄▅▄▃▃▃▄█▇▅▆▅▅▄▄▅▄▃▄▄▄▄▄▆▆▅▅▄▃▄▄</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁████</td></tr><tr><td>epoch/epoch</td><td>▁▃▅▆█</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>49</td></tr><tr><td>batch/loss</td><td>0.20387</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>4</td></tr><tr><td>epoch/loss</td><td>0.20387</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-44</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/atj3e68p/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/atj3e68p/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001113-atj3e68p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qt5atw0l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 29\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0568004993963981\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001135-qt5atw0l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/qt5atw0l/workspace' target=\"_blank\">flowing-sweep-45</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/qt5atw0l/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/qt5atw0l/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4815 - loss: 0.7373 - precision: 0.0517 - recall: 0.4971\n",
      "Epoch 2/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1106 - loss: 0.7331 - precision: 0.0626 - recall: 0.9711 \n",
      "Epoch 3/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.7159 - precision: 0.0199 - recall: 0.0099         \n",
      "Epoch 4/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7596 - loss: 0.6949 - precision: 0.0603 - recall: 0.3193         \n",
      "Epoch 5/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6719 - loss: 0.6567 - precision: 0.0764 - recall: 0.4280         \n",
      "Epoch 6/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4462 - loss: 0.7091 - precision: 0.0820 - recall: 0.7628 \n",
      "Epoch 7/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4788 - loss: 0.6877 - precision: 0.0728 - recall: 0.7237 \n",
      "Epoch 8/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4702 - loss: 0.6866 - precision: 0.0773 - recall: 0.7049 \n",
      "Epoch 9/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6921 - loss: 0.7092 - precision: 0.0679 - recall: 0.3425         \n",
      "Epoch 10/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6289 - loss: 0.6827 - precision: 0.0961 - recall: 0.6209 \n",
      "Epoch 11/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5108 - loss: 0.6490 - precision: 0.0827 - recall: 0.7779 \n",
      "Epoch 12/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4893 - loss: 0.6858 - precision: 0.0732 - recall: 0.6895 \n",
      "Epoch 13/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.6574 - precision: 0.0896 - recall: 0.3949 \n",
      "Epoch 14/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5675 - loss: 0.6689 - precision: 0.0904 - recall: 0.6925 \n",
      "Epoch 15/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6279 - loss: 0.6210 - precision: 0.0812 - recall: 0.6220 \n",
      "Epoch 16/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2887 - loss: 0.6168 - precision: 0.0517 - recall: 0.9162 \n",
      "Epoch 17/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6010 - loss: 0.6934 - precision: 0.0962 - recall: 0.6782 \n",
      "Epoch 18/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6150 - loss: 0.6550 - precision: 0.0818 - recall: 0.5935 \n",
      "Epoch 19/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6237 - loss: 0.6544 - precision: 0.0838 - recall: 0.6188 \n",
      "Epoch 20/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4707 - loss: 0.6354 - precision: 0.0653 - recall: 0.7186 \n",
      "Epoch 21/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3860 - loss: 0.6701 - precision: 0.0798 - recall: 0.8749 \n",
      "Epoch 22/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5573 - loss: 0.6252 - precision: 0.0712 - recall: 0.6373 \n",
      "Epoch 23/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5595 - loss: 0.6278 - precision: 0.0825 - recall: 0.7206 \n",
      "Epoch 24/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4489 - loss: 0.6251 - precision: 0.0747 - recall: 0.8482 \n",
      "Epoch 25/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5124 - loss: 0.6475 - precision: 0.0863 - recall: 0.7852 \n",
      "Epoch 26/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6335 - loss: 0.6401 - precision: 0.0862 - recall: 0.6060 \n",
      "Epoch 27/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4402 - loss: 0.6074 - precision: 0.0585 - recall: 0.7816 \n",
      "Epoch 28/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5818 - loss: 0.5909 - precision: 0.0747 - recall: 0.6907 \n",
      "Epoch 29/29\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3189 - loss: 0.6327 - precision: 0.0648 - recall: 0.9377 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b88f732eb2246b2bf79791fd448cd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▆▁██▆▆▄▅▄▄▇▅▆▄▅▄▇▅▅▆▃▅▅▆▆▄▅▃▅▄▅▄▄▆▆▄▅▅▃</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▆▅▅▄▅▅▆▄▄▅█▄▃▄▄▄▃▄▁▂▃▅▆▃▃▄▃▄▂▂▃▂▄█▃▂▂▃▄</td></tr><tr><td>batch/precision</td><td>▄▄▄▁▄▆▇▆▆▅▆▆▅▇▇▅▅▇▆▆▆▄▇█▆▆▆▅▆▅▅▆▅▆█▇▄▆▆▆</td></tr><tr><td>batch/recall</td><td>▆▃█▁▁▅▅▆▆▇▆▂▄▅▇▅▆▄▆▆▅█▆▆▅▅▆▆▇▅▇▆▇▇▅▆▆▆▆▇</td></tr><tr><td>epoch/accuracy</td><td>▅▁█▅▃▄▃▃▄▆▄▄▅▄▅▂▄▅▅▄▂▄▅▄▄▅▃▄▂</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▆▅▅▅▂▅▃▅▃▃▂▃▂▄▄▃▁▃▃▃▂▂▂▃▃▂▃▂</td></tr><tr><td>epoch/precision</td><td>▂▃▁▇▃▆▅▄▄█▆▅█▆█▄▇▆▇▅▄▆▇▆▇▇▅▆▅</td></tr><tr><td>epoch/recall</td><td>▃█▁▅▆▆▇▇▅▅▆▇▅▆▆█▆▆▆▆█▇▆▇▇▆▇▆█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.52785</td></tr><tr><td>batch/accuracy</td><td>0.38263</td></tr><tr><td>batch/batch_step</td><td>434</td></tr><tr><td>batch/loss</td><td>0.643</td></tr><tr><td>batch/precision</td><td>0.07337</td></tr><tr><td>batch/recall</td><td>0.89024</td></tr><tr><td>epoch/accuracy</td><td>0.38263</td></tr><tr><td>epoch/epoch</td><td>28</td></tr><tr><td>epoch/loss</td><td>0.643</td></tr><tr><td>epoch/precision</td><td>0.07337</td></tr><tr><td>epoch/recall</td><td>0.89024</td></tr><tr><td>f1_score</td><td>0.15238</td></tr><tr><td>precision</td><td>0.08421</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-sweep-45</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/qt5atw0l/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/qt5atw0l/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001135-qt5atw0l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r2c29arv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 85\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.03736036574052716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001150-r2c29arv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/r2c29arv/workspace' target=\"_blank\">devout-sweep-46</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/r2c29arv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/r2c29arv/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9423 - loss: 0.7183 - precision: 0.5686 - recall: 0.0161       \n",
      "Epoch 2/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.7095 - precision: 0.1080 - recall: 0.2838 \n",
      "Epoch 3/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7426 - loss: 0.6579 - precision: 0.0989 - recall: 0.5165 \n",
      "Epoch 4/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5319 - loss: 0.6465 - precision: 0.0676 - recall: 0.6713 \n",
      "Epoch 5/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5248 - loss: 0.6762 - precision: 0.0756 - recall: 0.6967 \n",
      "Epoch 6/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5669 - loss: 0.6685 - precision: 0.0820 - recall: 0.7073 \n",
      "Epoch 7/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6244 - loss: 0.6386 - precision: 0.0812 - recall: 0.6573 \n",
      "Epoch 8/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5720 - loss: 0.6597 - precision: 0.0726 - recall: 0.6203 \n",
      "Epoch 9/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6331 - loss: 0.6507 - precision: 0.0884 - recall: 0.6659 \n",
      "Epoch 10/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5408 - loss: 0.6955 - precision: 0.0813 - recall: 0.6772 \n",
      "Epoch 11/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5518 - loss: 0.7090 - precision: 0.0932 - recall: 0.7247 \n",
      "Epoch 12/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6087 - loss: 0.6706 - precision: 0.0936 - recall: 0.7031 \n",
      "Epoch 13/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6345 - loss: 0.6610 - precision: 0.0808 - recall: 0.5974 \n",
      "Epoch 14/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5780 - loss: 0.7030 - precision: 0.0973 - recall: 0.7133 \n",
      "Epoch 15/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6065 - loss: 0.6890 - precision: 0.0959 - recall: 0.6703 \n",
      "Epoch 16/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6475 - loss: 0.6374 - precision: 0.0816 - recall: 0.5858 \n",
      "Epoch 17/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5590 - loss: 0.7301 - precision: 0.0923 - recall: 0.6640 \n",
      "Epoch 18/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7056 - loss: 0.6285 - precision: 0.0832 - recall: 0.4998 \n",
      "Epoch 19/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6287 - loss: 0.6521 - precision: 0.0938 - recall: 0.6809 \n",
      "Epoch 20/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6491 - loss: 0.6348 - precision: 0.0940 - recall: 0.6906 \n",
      "Epoch 21/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5659 - loss: 0.6850 - precision: 0.0807 - recall: 0.6420 \n",
      "Epoch 22/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6474 - loss: 0.6373 - precision: 0.0897 - recall: 0.6522 \n",
      "Epoch 23/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5676 - loss: 0.6847 - precision: 0.0865 - recall: 0.6649 \n",
      "Epoch 24/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6719 - loss: 0.6108 - precision: 0.0955 - recall: 0.6604 \n",
      "Epoch 25/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6119 - loss: 0.6311 - precision: 0.0827 - recall: 0.6758 \n",
      "Epoch 26/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5998 - loss: 0.6590 - precision: 0.0910 - recall: 0.6894 \n",
      "Epoch 27/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5850 - loss: 0.6907 - precision: 0.1002 - recall: 0.7158 \n",
      "Epoch 28/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5873 - loss: 0.6931 - precision: 0.1102 - recall: 0.7530 \n",
      "Epoch 29/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7069 - loss: 0.6082 - precision: 0.1030 - recall: 0.6393 \n",
      "Epoch 30/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5657 - loss: 0.6953 - precision: 0.0919 - recall: 0.6906 \n",
      "Epoch 31/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5976 - loss: 0.6887 - precision: 0.0946 - recall: 0.6677 \n",
      "Epoch 32/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6097 - loss: 0.6883 - precision: 0.0833 - recall: 0.5969 \n",
      "Epoch 33/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6411 - loss: 0.6695 - precision: 0.1136 - recall: 0.7314 \n",
      "Epoch 34/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6131 - loss: 0.6183 - precision: 0.0923 - recall: 0.7586 \n",
      "Epoch 35/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5965 - loss: 0.6549 - precision: 0.0967 - recall: 0.7163 \n",
      "Epoch 36/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6375 - loss: 0.6276 - precision: 0.0958 - recall: 0.7014 \n",
      "Epoch 37/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7018 - loss: 0.5881 - precision: 0.0981 - recall: 0.6664 \n",
      "Epoch 38/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5888 - loss: 0.6369 - precision: 0.0770 - recall: 0.6505 \n",
      "Epoch 39/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6608 - loss: 0.6262 - precision: 0.0733 - recall: 0.5096 \n",
      "Epoch 40/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6303 - loss: 0.6121 - precision: 0.0874 - recall: 0.6975 \n",
      "Epoch 41/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5979 - loss: 0.6061 - precision: 0.0702 - recall: 0.6344 \n",
      "Epoch 42/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5675 - loss: 0.6359 - precision: 0.0798 - recall: 0.7229 \n",
      "Epoch 43/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5314 - loss: 0.6746 - precision: 0.0788 - recall: 0.6697 \n",
      "Epoch 44/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6508 - loss: 0.6316 - precision: 0.0970 - recall: 0.6768 \n",
      "Epoch 45/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5603 - loss: 0.6755 - precision: 0.0825 - recall: 0.6672 \n",
      "Epoch 46/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5688 - loss: 0.6767 - precision: 0.0916 - recall: 0.7033 \n",
      "Epoch 47/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6407 - loss: 0.6007 - precision: 0.0940 - recall: 0.6989 \n",
      "Epoch 48/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6025 - loss: 0.6456 - precision: 0.0945 - recall: 0.7013 \n",
      "Epoch 49/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6529 - loss: 0.6355 - precision: 0.0911 - recall: 0.6482 \n",
      "Epoch 50/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6080 - loss: 0.6402 - precision: 0.0842 - recall: 0.6391 \n",
      "Epoch 51/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5827 - loss: 0.6419 - precision: 0.0780 - recall: 0.6446 \n",
      "Epoch 52/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6053 - loss: 0.6445 - precision: 0.0896 - recall: 0.6934 \n",
      "Epoch 53/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6148 - loss: 0.6588 - precision: 0.1057 - recall: 0.7419 \n",
      "Epoch 54/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6750 - loss: 0.6514 - precision: 0.0962 - recall: 0.5647 \n",
      "Epoch 55/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6050 - loss: 0.6343 - precision: 0.0894 - recall: 0.7102 \n",
      "Epoch 56/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6369 - loss: 0.6450 - precision: 0.1074 - recall: 0.7085 \n",
      "Epoch 57/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6641 - loss: 0.6279 - precision: 0.0838 - recall: 0.5641 \n",
      "Epoch 58/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5681 - loss: 0.6174 - precision: 0.0907 - recall: 0.7815 \n",
      "Epoch 59/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6051 - loss: 0.6758 - precision: 0.1052 - recall: 0.7229 \n",
      "Epoch 60/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6695 - loss: 0.6213 - precision: 0.0943 - recall: 0.6390 \n",
      "Epoch 61/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6272 - loss: 0.6225 - precision: 0.0926 - recall: 0.6950 \n",
      "Epoch 62/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5490 - loss: 0.6434 - precision: 0.0863 - recall: 0.7241 \n",
      "Epoch 63/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6591 - loss: 0.6254 - precision: 0.1079 - recall: 0.7111 \n",
      "Epoch 64/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6254 - loss: 0.6438 - precision: 0.0771 - recall: 0.5554 \n",
      "Epoch 65/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6803 - loss: 0.6317 - precision: 0.0887 - recall: 0.5617 \n",
      "Epoch 66/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6277 - loss: 0.6381 - precision: 0.1053 - recall: 0.7370 \n",
      "Epoch 67/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6786 - loss: 0.6160 - precision: 0.1184 - recall: 0.7092 \n",
      "Epoch 68/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6185 - loss: 0.6489 - precision: 0.0931 - recall: 0.6709 \n",
      "Epoch 69/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6256 - loss: 0.5984 - precision: 0.0795 - recall: 0.6468 \n",
      "Epoch 70/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5941 - loss: 0.6758 - precision: 0.1103 - recall: 0.7596 \n",
      "Epoch 71/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6518 - loss: 0.6201 - precision: 0.0938 - recall: 0.6705 \n",
      "Epoch 72/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6020 - loss: 0.6338 - precision: 0.0774 - recall: 0.6219 \n",
      "Epoch 73/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6252 - loss: 0.6238 - precision: 0.0898 - recall: 0.6971 \n",
      "Epoch 74/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6405 - loss: 0.6114 - precision: 0.0913 - recall: 0.6788 \n",
      "Epoch 75/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5988 - loss: 0.7033 - precision: 0.1002 - recall: 0.6589 \n",
      "Epoch 76/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6566 - loss: 0.6215 - precision: 0.0714 - recall: 0.4996 \n",
      "Epoch 77/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6287 - loss: 0.6184 - precision: 0.0897 - recall: 0.6732 \n",
      "Epoch 78/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6465 - loss: 0.6355 - precision: 0.0876 - recall: 0.5999 \n",
      "Epoch 79/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6101 - loss: 0.6573 - precision: 0.0873 - recall: 0.6516 \n",
      "Epoch 80/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6441 - loss: 0.6721 - precision: 0.1014 - recall: 0.6332 \n",
      "Epoch 81/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6631 - loss: 0.6168 - precision: 0.0868 - recall: 0.6145 \n",
      "Epoch 82/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6044 - loss: 0.6671 - precision: 0.0878 - recall: 0.6445 \n",
      "Epoch 83/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6483 - loss: 0.6338 - precision: 0.1069 - recall: 0.6856 \n",
      "Epoch 84/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 0.6418 - precision: 0.1023 - recall: 0.7338 \n",
      "Epoch 85/85\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5925 - loss: 0.6629 - precision: 0.0909 - recall: 0.6755 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45426a5482714876b43a59c9c0004def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▄▁▂▂▂▂▂▃▃▃▃▂▃▂▃▂▃▃▂▃▂▂▂▂▃▃▂▃▃▃▃▂▂▃▃▃▃▂▂</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>██▆▆▅▆▅▄▄▄▄▃▄▃▃▄▃▃▃▃▃▂▃▃▂▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁</td></tr><tr><td>batch/precision</td><td>█▁▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>batch/recall</td><td>▁▅█▇▇█▇▇▆█▇▇█▇█▇█▇█▇▇███▇▆▇█▇█▇▇▇▇█▇▇███</td></tr><tr><td>epoch/accuracy</td><td>█▄▁▂▂▂▂▂▃▃▃▃▂▃▂▃▂▃▃▂▃▂▂▂▂▃▃▂▃▃▃▃▂▂▃▃▃▃▂▂</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>██▆▆▅▆▅▄▄▄▄▃▄▃▃▄▃▃▃▃▃▂▃▃▂▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▂▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>epoch/recall</td><td>▁▅█▇▇█▇▇▆█▇▇█▇█▇█▇█▇▇███▇▆▇█▇█▇▇▇▇█▇▇███</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.69496</td></tr><tr><td>batch/accuracy</td><td>0.5935</td></tr><tr><td>batch/batch_step</td><td>1359</td></tr><tr><td>batch/loss</td><td>0.63071</td></tr><tr><td>batch/precision</td><td>0.09091</td></tr><tr><td>batch/recall</td><td>0.71951</td></tr><tr><td>epoch/accuracy</td><td>0.5935</td></tr><tr><td>epoch/epoch</td><td>84</td></tr><tr><td>epoch/loss</td><td>0.63071</td></tr><tr><td>epoch/precision</td><td>0.09091</td></tr><tr><td>epoch/recall</td><td>0.71951</td></tr><tr><td>f1_score</td><td>0.13534</td></tr><tr><td>precision</td><td>0.07965</td></tr><tr><td>recall</td><td>0.45</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-46</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/r2c29arv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/r2c29arv/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001150-r2c29arv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yyo1ddff with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 92\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0976179751449771\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001206-yyo1ddff</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/yyo1ddff/workspace' target=\"_blank\">fast-sweep-47</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/yyo1ddff/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/yyo1ddff/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5823 - loss: 0.7082 - precision: 0.0664 - recall: 0.4626\n",
      "Epoch 2/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.6608 - precision: 0.0810 - recall: 0.3907 \n",
      "Epoch 3/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5040 - loss: 0.7210 - precision: 0.0837 - recall: 0.6974 \n",
      "Epoch 4/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.6791 - precision: 0.0702 - recall: 0.4013 \n",
      "Epoch 5/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5819 - loss: 0.7073 - precision: 0.0909 - recall: 0.6502 \n",
      "Epoch 6/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6109 - loss: 0.7131 - precision: 0.0859 - recall: 0.5557 \n",
      "Epoch 7/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6507 - loss: 0.6643 - precision: 0.0856 - recall: 0.5819 \n",
      "Epoch 8/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5845 - loss: 0.6633 - precision: 0.0788 - recall: 0.6395 \n",
      "Epoch 9/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6199 - loss: 0.6755 - precision: 0.0980 - recall: 0.6845 \n",
      "Epoch 10/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6714 - loss: 0.6828 - precision: 0.0961 - recall: 0.5723 \n",
      "Epoch 11/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6375 - loss: 0.6575 - precision: 0.0925 - recall: 0.6450 \n",
      "Epoch 12/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6102 - loss: 0.6799 - precision: 0.0948 - recall: 0.6606 \n",
      "Epoch 13/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6568 - loss: 0.6472 - precision: 0.0904 - recall: 0.6032 \n",
      "Epoch 14/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5560 - loss: 0.7043 - precision: 0.0900 - recall: 0.6712 \n",
      "Epoch 15/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6879 - loss: 0.6367 - precision: 0.0884 - recall: 0.5451 \n",
      "Epoch 16/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4995 - loss: 0.7100 - precision: 0.0871 - recall: 0.7291 \n",
      "Epoch 17/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6996 - loss: 0.6537 - precision: 0.0770 - recall: 0.4307         \n",
      "Epoch 18/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6196 - loss: 0.6490 - precision: 0.0919 - recall: 0.6968 \n",
      "Epoch 19/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6366 - loss: 0.6527 - precision: 0.0925 - recall: 0.6435 \n",
      "Epoch 20/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6522 - loss: 0.6467 - precision: 0.0775 - recall: 0.5383 \n",
      "Epoch 21/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6332 - loss: 0.6350 - precision: 0.0840 - recall: 0.6166 \n",
      "Epoch 22/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6364 - loss: 0.6110 - precision: 0.0781 - recall: 0.6308 \n",
      "Epoch 23/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4842 - loss: 0.6863 - precision: 0.0807 - recall: 0.7194 \n",
      "Epoch 24/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6290 - loss: 0.7134 - precision: 0.0922 - recall: 0.5555 \n",
      "Epoch 25/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7003 - loss: 0.6672 - precision: 0.1011 - recall: 0.5505 \n",
      "Epoch 26/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6099 - loss: 0.6380 - precision: 0.0830 - recall: 0.6727 \n",
      "Epoch 27/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5779 - loss: 0.6333 - precision: 0.0719 - recall: 0.6281 \n",
      "Epoch 28/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5477 - loss: 0.6940 - precision: 0.1013 - recall: 0.7520 \n",
      "Epoch 29/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7574 - loss: 0.5725 - precision: 0.0744 - recall: 0.4175 \n",
      "Epoch 30/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5757 - loss: 0.6154 - precision: 0.0864 - recall: 0.7605 \n",
      "Epoch 31/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5825 - loss: 0.6335 - precision: 0.0776 - recall: 0.6708 \n",
      "Epoch 32/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6081 - loss: 0.6469 - precision: 0.0802 - recall: 0.6012 \n",
      "Epoch 33/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6069 - loss: 0.6496 - precision: 0.0877 - recall: 0.6751 \n",
      "Epoch 34/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6474 - loss: 0.6524 - precision: 0.0962 - recall: 0.6425 \n",
      "Epoch 35/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5792 - loss: 0.6938 - precision: 0.0994 - recall: 0.7047 \n",
      "Epoch 36/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7243 - loss: 0.6106 - precision: 0.0925 - recall: 0.5162 \n",
      "Epoch 37/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5882 - loss: 0.6177 - precision: 0.0851 - recall: 0.7257 \n",
      "Epoch 38/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5885 - loss: 0.6442 - precision: 0.0878 - recall: 0.6891 \n",
      "Epoch 39/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5682 - loss: 0.6811 - precision: 0.0962 - recall: 0.7448 \n",
      "Epoch 40/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6165 - loss: 0.6717 - precision: 0.1045 - recall: 0.7063 \n",
      "Epoch 41/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6415 - loss: 0.6227 - precision: 0.0925 - recall: 0.6611 \n",
      "Epoch 42/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5772 - loss: 0.6778 - precision: 0.0994 - recall: 0.7223 \n",
      "Epoch 43/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6190 - loss: 0.6701 - precision: 0.1030 - recall: 0.6846 \n",
      "Epoch 44/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6676 - loss: 0.6466 - precision: 0.0905 - recall: 0.5688 \n",
      "Epoch 45/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5081 - loss: 0.7111 - precision: 0.0941 - recall: 0.7399 \n",
      "Epoch 46/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6477 - loss: 0.6625 - precision: 0.0951 - recall: 0.5874 \n",
      "Epoch 47/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6421 - loss: 0.6226 - precision: 0.0953 - recall: 0.6894 \n",
      "Epoch 48/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5771 - loss: 0.6699 - precision: 0.0829 - recall: 0.6475 \n",
      "Epoch 49/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6378 - loss: 0.6416 - precision: 0.0913 - recall: 0.6367 \n",
      "Epoch 50/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5785 - loss: 0.6458 - precision: 0.0791 - recall: 0.6346 \n",
      "Epoch 51/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6444 - loss: 0.5892 - precision: 0.0783 - recall: 0.6109 \n",
      "Epoch 52/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6430 - loss: 0.6099 - precision: 0.0731 - recall: 0.5328 \n",
      "Epoch 53/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6040 - loss: 0.6398 - precision: 0.0913 - recall: 0.7080 \n",
      "Epoch 54/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5888 - loss: 0.6636 - precision: 0.0995 - recall: 0.7027 \n",
      "Epoch 55/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6728 - loss: 0.6080 - precision: 0.0920 - recall: 0.6489 \n",
      "Epoch 56/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6017 - loss: 0.6447 - precision: 0.0860 - recall: 0.6631 \n",
      "Epoch 57/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6522 - loss: 0.6155 - precision: 0.1035 - recall: 0.7118 \n",
      "Epoch 58/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6000 - loss: 0.6663 - precision: 0.0902 - recall: 0.6518 \n",
      "Epoch 59/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6957 - loss: 0.6012 - precision: 0.0983 - recall: 0.6040 \n",
      "Epoch 60/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6407 - loss: 0.6244 - precision: 0.0936 - recall: 0.6767 \n",
      "Epoch 61/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6477 - loss: 0.6572 - precision: 0.0985 - recall: 0.6185 \n",
      "Epoch 62/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6178 - loss: 0.6440 - precision: 0.0902 - recall: 0.6553 \n",
      "Epoch 63/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6012 - loss: 0.6564 - precision: 0.0986 - recall: 0.7150 \n",
      "Epoch 64/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7265 - loss: 0.5730 - precision: 0.0703 - recall: 0.4525 \n",
      "Epoch 65/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6506 - precision: 0.0730 - recall: 0.6670 \n",
      "Epoch 66/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5941 - loss: 0.6449 - precision: 0.0916 - recall: 0.6845 \n",
      "Epoch 67/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6274 - loss: 0.6926 - precision: 0.0814 - recall: 0.5431 \n",
      "Epoch 68/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6267 - loss: 0.6355 - precision: 0.0928 - recall: 0.6677 \n",
      "Epoch 69/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6163 - loss: 0.5994 - precision: 0.0846 - recall: 0.6834 \n",
      "Epoch 70/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6185 - loss: 0.6325 - precision: 0.0892 - recall: 0.6881 \n",
      "Epoch 71/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6007 - loss: 0.6337 - precision: 0.1000 - recall: 0.7447 \n",
      "Epoch 72/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5482 - loss: 0.6937 - precision: 0.0796 - recall: 0.6519 \n",
      "Epoch 73/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.6037 - precision: 0.0959 - recall: 0.6096 \n",
      "Epoch 74/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6361 - loss: 0.5784 - precision: 0.0736 - recall: 0.6097 \n",
      "Epoch 75/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6001 - loss: 0.6125 - precision: 0.0890 - recall: 0.7456 \n",
      "Epoch 76/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5772 - loss: 0.6624 - precision: 0.0886 - recall: 0.6819 \n",
      "Epoch 77/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.6401 - precision: 0.1032 - recall: 0.5635 \n",
      "Epoch 78/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6436 - loss: 0.6389 - precision: 0.0905 - recall: 0.6139 \n",
      "Epoch 79/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.6333 - precision: 0.0915 - recall: 0.7075 \n",
      "Epoch 80/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6123 - loss: 0.6733 - precision: 0.0793 - recall: 0.5469 \n",
      "Epoch 81/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6174 - loss: 0.6853 - precision: 0.0992 - recall: 0.6177 \n",
      "Epoch 82/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6576 - loss: 0.6494 - precision: 0.0982 - recall: 0.6208 \n",
      "Epoch 83/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5716 - loss: 0.6407 - precision: 0.0796 - recall: 0.6556 \n",
      "Epoch 84/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6330 - loss: 0.6112 - precision: 0.0778 - recall: 0.5926 \n",
      "Epoch 85/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6284 - loss: 0.6186 - precision: 0.0838 - recall: 0.6205 \n",
      "Epoch 86/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.6078 - precision: 0.0891 - recall: 0.7073 \n",
      "Epoch 87/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5579 - loss: 0.6412 - precision: 0.0783 - recall: 0.6993 \n",
      "Epoch 88/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6528 - loss: 0.5940 - precision: 0.0845 - recall: 0.6508 \n",
      "Epoch 89/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5830 - loss: 0.6271 - precision: 0.0812 - recall: 0.6351 \n",
      "Epoch 90/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5687 - loss: 0.6616 - precision: 0.0868 - recall: 0.6592 \n",
      "Epoch 91/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.6082 - precision: 0.0940 - recall: 0.6230 \n",
      "Epoch 92/92\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5450 - loss: 0.6797 - precision: 0.0988 - recall: 0.7481 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77a489c900b4a9a95f5b78fd764cda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▂▁▄▃▅▅▅▅▅▅▄▅█▄▄▇▄▄▄▁▃▅▅▆▄▅▅▆▃▄▄▆▄▄▅▅▅▃▄▃</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▇█▄▇▆▅▆▆▅▆▅▃▇▆▄▅▆▇█▇▅▅▂▆▅▇▁▇▅▇▅▅▇█▅▄▅▆▆</td></tr><tr><td>batch/precision</td><td>▄▄▅▄▆▆▅▅▆▅▅▅▅▆▆▅▆▆▆▆▂▅▅▆▅▆▆▁▆▅█▆▆▅▄▆▆▄▅▆</td></tr><tr><td>batch/recall</td><td>▄▆▄▆▅▅▄▄▆▆▅▅▂▅▆▄▆▆▆▇▂▅▄█▆▅▅▁▆▆▇▅▇▄▁▆▆▇▆▇</td></tr><tr><td>epoch/accuracy</td><td>▂▁▃▄▇▄▇▇▅▆▅▆█▄▅▇▅▅▅▃▅▄▅▅▅▆▆▇▄▆▅▇▅▆▅▆▅▃▄▄</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▆▆▅▅▄▅▄▄▃▄▄▄▃▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▁</td></tr><tr><td>epoch/precision</td><td>▁▃▄▅▆▅▆▆▆▆▅▇▇▅▇▆▇▇▆▆▇▆▅▆▇▇▆█▆▆▇▇▇▇▅▇▆▆▅▇</td></tr><tr><td>epoch/recall</td><td>▂▇▅▆▂▅▂▂▆▃▅▅▁▅▆▁▆▆▆█▆▆▄▆▆▅▄▃▆▄▆▄▇▅▅▅▅█▅█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.70292</td></tr><tr><td>batch/accuracy</td><td>0.58355</td></tr><tr><td>batch/batch_step</td><td>827</td></tr><tr><td>batch/loss</td><td>0.62555</td></tr><tr><td>batch/precision</td><td>0.09132</td></tr><tr><td>batch/recall</td><td>0.7439</td></tr><tr><td>epoch/accuracy</td><td>0.58355</td></tr><tr><td>epoch/epoch</td><td>91</td></tr><tr><td>epoch/loss</td><td>0.62555</td></tr><tr><td>epoch/precision</td><td>0.09132</td></tr><tr><td>epoch/recall</td><td>0.7439</td></tr><tr><td>f1_score</td><td>0.15152</td></tr><tr><td>precision</td><td>0.08929</td></tr><tr><td>recall</td><td>0.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-47</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/yyo1ddff/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/yyo1ddff/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001206-yyo1ddff/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jhoe2mae with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 63\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.022012024815950295\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001222-jhoe2mae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/jhoe2mae/workspace' target=\"_blank\">fine-sweep-48</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/jhoe2mae/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/jhoe2mae/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7577 - loss: 0.4605 - precision: 0.0385 - recall: 0.2050\n",
      "Epoch 2/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.2248 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.2282 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.2391 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2075 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.2035 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2082 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.2162 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1964 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.2249 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2068 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2141 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1960 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.2220 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9355 - loss: 0.2405 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1988 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2060 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1915 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2108 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.2085 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1796 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2079 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9410 - loss: 0.2171 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1970 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2033 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1966 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2007 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1899 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.2357 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2085 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1977 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1973 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1934 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9570 - loss: 0.1701 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1801 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1944 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1922 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1954 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1956 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.2024 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9374 - loss: 0.2178 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2012 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1867 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1996 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.2151 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2117 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1957 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/63\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9346 - loss: 0.2218 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▇▆▇▇▇▇▆▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇█▇▇▇▆▇▇▇▆▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▃▃▄▃▃▃▃▄▃▃▅▃▃▃▃▄▃▂▃▃▂▃▃▃▃▃▃▁▃▃▃▃▂▃▃▄▃▃▃</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▁▁▂▂▁▂▁▁▁▁▂▁▁▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>944</td></tr><tr><td>batch/loss</td><td>0.19845</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>62</td></tr><tr><td>epoch/loss</td><td>0.19845</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-sweep-48</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/jhoe2mae/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/jhoe2mae/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001222-jhoe2mae/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vfgwbup6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0631020151305243\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001238-vfgwbup6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vfgwbup6/workspace' target=\"_blank\">rosy-sweep-49</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vfgwbup6/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vfgwbup6/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9430 - loss: 0.4927 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.2346 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2159 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2122 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.2298 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.2221 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2259 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9388 - loss: 0.2343 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9532 - loss: 0.1907 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2170 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/12\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.2391 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▆▇▇▆▇▇▇▇▆▇▇▆▆▇▆▆▇▇▇▇▆▆▆▅▆▆▇█▇▇▇▇▇█▇▇▁▆▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▇▅▅▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂▃▂▂▂▁▁▂▂▂▂▁▂▁▄▂▂▂</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████</td></tr><tr><td>epoch/epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>epoch/loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>155</td></tr><tr><td>batch/loss</td><td>0.2148</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>11</td></tr><tr><td>epoch/loss</td><td>0.2148</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rosy-sweep-49</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vfgwbup6/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vfgwbup6/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001238-vfgwbup6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 81me5bvq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 46\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.09430135127880244\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001248-81me5bvq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/81me5bvq/workspace' target=\"_blank\">bright-sweep-50</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/81me5bvq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/81me5bvq/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4931 - loss: 0.8979 - precision: 0.0630 - recall: 0.5113 \n",
      "Epoch 2/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5445 - loss: 0.7259 - precision: 0.0835 - recall: 0.5998        \n",
      "Epoch 3/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5275 - loss: 0.6634 - precision: 0.0718 - recall: 0.6652\n",
      "Epoch 4/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6836 - loss: 0.6556 - precision: 0.0847 - recall: 0.4920\n",
      "Epoch 5/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5771 - loss: 0.7054 - precision: 0.0960 - recall: 0.6774\n",
      "Epoch 6/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5182 - loss: 0.6621 - precision: 0.0651 - recall: 0.5873        \n",
      "Epoch 7/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6482 - loss: 0.6689 - precision: 0.0986 - recall: 0.6318\n",
      "Epoch 8/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5038 - loss: 0.6440 - precision: 0.0781 - recall: 0.7500        \n",
      "Epoch 9/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3930 - loss: 0.6805 - precision: 0.0757 - recall: 0.8495\n",
      "Epoch 10/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5202 - loss: 0.6351 - precision: 0.0679 - recall: 0.6602\n",
      "Epoch 11/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5838 - loss: 0.6953 - precision: 0.1065 - recall: 0.7381\n",
      "Epoch 12/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4187 - loss: 0.6586 - precision: 0.0743 - recall: 0.8233\n",
      "Epoch 13/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5465 - loss: 0.6251 - precision: 0.0699 - recall: 0.6541        \n",
      "Epoch 14/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3543 - loss: 0.6380 - precision: 0.0625 - recall: 0.8409 \n",
      "Epoch 15/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4013 - loss: 0.7361 - precision: 0.0824 - recall: 0.7606 \n",
      "Epoch 16/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4749 - loss: 0.6474 - precision: 0.0683 - recall: 0.7139         \n",
      "Epoch 17/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5578 - loss: 0.6053 - precision: 0.0879 - recall: 0.7777        \n",
      "Epoch 18/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5051 - loss: 0.6600 - precision: 0.0739 - recall: 0.6867\n",
      "Epoch 19/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6086 - loss: 0.6606 - precision: 0.0873 - recall: 0.6305 \n",
      "Epoch 20/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6064 - loss: 0.6556 - precision: 0.0840 - recall: 0.5995         \n",
      "Epoch 21/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4718 - loss: 0.6380 - precision: 0.0658 - recall: 0.7107        \n",
      "Epoch 22/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5861 - loss: 0.6795 - precision: 0.0945 - recall: 0.6631\n",
      "Epoch 23/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3023 - loss: 0.6847 - precision: 0.0717 - recall: 0.9172\n",
      "Epoch 24/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5308 - loss: 0.6649 - precision: 0.0837 - recall: 0.7253 \n",
      "Epoch 25/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5280 - loss: 0.6567 - precision: 0.0827 - recall: 0.7274\n",
      "Epoch 26/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5316 - loss: 0.6599 - precision: 0.0911 - recall: 0.7712 \n",
      "Epoch 27/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5685 - loss: 0.6069 - precision: 0.0856 - recall: 0.7361\n",
      "Epoch 28/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5311 - loss: 0.7310 - precision: 0.1172 - recall: 0.8194\n",
      "Epoch 29/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6084 - loss: 0.6277 - precision: 0.0784 - recall: 0.5478         \n",
      "Epoch 30/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4983 - loss: 0.6937 - precision: 0.0832 - recall: 0.7143 \n",
      "Epoch 31/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5413 - loss: 0.6393 - precision: 0.0726 - recall: 0.7123 \n",
      "Epoch 32/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4463 - loss: 0.6708 - precision: 0.0830 - recall: 0.8116 \n",
      "Epoch 33/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5606 - loss: 0.6591 - precision: 0.0779 - recall: 0.6788        \n",
      "Epoch 34/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4782 - loss: 0.6303 - precision: 0.0783 - recall: 0.8170 \n",
      "Epoch 35/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4079 - loss: 0.6466 - precision: 0.0635 - recall: 0.7466 \n",
      "Epoch 36/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5722 - loss: 0.7031 - precision: 0.0964 - recall: 0.6464 \n",
      "Epoch 37/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6124 - loss: 0.5915 - precision: 0.0763 - recall: 0.6420         \n",
      "Epoch 38/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5212 - loss: 0.6124 - precision: 0.0801 - recall: 0.7635 \n",
      "Epoch 39/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4563 - loss: 0.6196 - precision: 0.0676 - recall: 0.7633 \n",
      "Epoch 40/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5307 - loss: 0.6323 - precision: 0.0805 - recall: 0.7579 \n",
      "Epoch 41/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5886 - loss: 0.6170 - precision: 0.0775 - recall: 0.6816 \n",
      "Epoch 42/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4186 - loss: 0.6541 - precision: 0.0812 - recall: 0.8668\n",
      "Epoch 43/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3065 - loss: 0.7165 - precision: 0.0848 - recall: 0.9562\n",
      "Epoch 44/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6932 - loss: 0.6354 - precision: 0.0679 - recall: 0.4372        \n",
      "Epoch 45/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5287 - loss: 0.6650 - precision: 0.0747 - recall: 0.6559        \n",
      "Epoch 46/46\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5859 - loss: 0.6920 - precision: 0.0910 - recall: 0.6927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▂▅▆▆▂▃▄▅▆▄▁▃▄▅▅▅▅▆▂▄▅▄▅▄▄▅▄▅▄▆▅▅▅▅▂▄█▅▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▄▃▄▄▄▄▃▃▃▃▃▃▃▃▄▃▄▄▃▄▃▆▃▄▂▃▃▄▅▂▁▂▃▃▄▂▄▄</td></tr><tr><td>batch/precision</td><td>▂▂▄▃▄▁▃▄▂▄▃▁▃▃▄▃▄▃▃▃▃▅▃█▃▃▁▃▄▃▄▃▃▂▄▃▂▂▄▄</td></tr><tr><td>batch/recall</td><td>▄▆▄▃▄▆▇▆▄▅▅▇▆▆▅▅▅▄▄▇▆▆▆▆▆▅▅▆▆▆▃▅▆▅▆█▆▁▅▄</td></tr><tr><td>epoch/accuracy</td><td>▆█▅█▆▁█▃▇▆▄▆▃▃▅▅▆▆▂▅▆▅▅▄▅▄▅▄▆▄▃▅▆▄▆▇▄▃█▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▃▃▂▂▂▂▂▁▂▁▁▁▂▂▂▁▁▁▂▁▂▂▂▁▂▁▂▁▁▁▂▃▁▁▂</td></tr><tr><td>epoch/precision</td><td>▁▄▅▆▆▁▇▄▆▆▄▅▅▃▅▆▆▅▃▄▅▆▆▅▆▄▅▅▇▅▄▅▆▅▇█▄▆█▇</td></tr><tr><td>epoch/recall</td><td>▂▁▅▂▅▆▃▆▄▅▅▄▇▅▆▅▅▄▆▄▄▆▆▆▆▅▆▆▆▆▆▆▅▆▆▅▆█▄▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.52785</td></tr><tr><td>batch/accuracy</td><td>0.58554</td></tr><tr><td>batch/batch_step</td><td>2207</td></tr><tr><td>batch/loss</td><td>0.68082</td></tr><tr><td>batch/precision</td><td>0.08166</td></tr><tr><td>batch/recall</td><td>0.64634</td></tr><tr><td>epoch/accuracy</td><td>0.58554</td></tr><tr><td>epoch/epoch</td><td>45</td></tr><tr><td>epoch/loss</td><td>0.68082</td></tr><tr><td>epoch/precision</td><td>0.08166</td></tr><tr><td>epoch/recall</td><td>0.64634</td></tr><tr><td>f1_score</td><td>0.15238</td></tr><tr><td>precision</td><td>0.08421</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bright-sweep-50</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/81me5bvq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/81me5bvq/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001248-81me5bvq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 73qjzmj3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 33\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02369845510551647\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001310-73qjzmj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/73qjzmj3/workspace' target=\"_blank\">rose-sweep-51</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/73qjzmj3/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/73qjzmj3/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7739 - loss: 0.6565 - precision: 0.0557 - recall: 0.2189\n",
      "Epoch 2/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7566 - loss: 0.6633 - precision: 0.0785 - recall: 0.3197 \n",
      "Epoch 3/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6478 - loss: 0.6563 - precision: 0.0914 - recall: 0.6151 \n",
      "Epoch 4/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.6746 - precision: 0.1275 - recall: 0.4731 \n",
      "Epoch 5/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6606 - loss: 0.6481 - precision: 0.0819 - recall: 0.5294 \n",
      "Epoch 6/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6638 - loss: 0.6358 - precision: 0.0932 - recall: 0.6028 \n",
      "Epoch 7/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7258 - loss: 0.6160 - precision: 0.1011 - recall: 0.5644 \n",
      "Epoch 8/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4883 - loss: 0.6457 - precision: 0.0771 - recall: 0.7603 \n",
      "Epoch 9/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5516 - loss: 0.6416 - precision: 0.0807 - recall: 0.7231 \n",
      "Epoch 10/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4909 - loss: 0.6756 - precision: 0.0905 - recall: 0.7765 \n",
      "Epoch 11/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5469 - loss: 0.6403 - precision: 0.0759 - recall: 0.7149 \n",
      "Epoch 12/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 0.6140 - precision: 0.0832 - recall: 0.6475 \n",
      "Epoch 13/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4914 - loss: 0.6314 - precision: 0.0752 - recall: 0.8228 \n",
      "Epoch 14/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5575 - loss: 0.6927 - precision: 0.0916 - recall: 0.6863 \n",
      "Epoch 15/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6139 - loss: 0.6481 - precision: 0.0981 - recall: 0.7336 \n",
      "Epoch 16/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5181 - loss: 0.6486 - precision: 0.0804 - recall: 0.7227 \n",
      "Epoch 17/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4291 - loss: 0.6730 - precision: 0.0831 - recall: 0.8434 \n",
      "Epoch 18/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.6498 - precision: 0.0999 - recall: 0.4549 \n",
      "Epoch 19/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7044 - loss: 0.6288 - precision: 0.1047 - recall: 0.5674 \n",
      "Epoch 20/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4552 - loss: 0.6530 - precision: 0.0836 - recall: 0.8468 \n",
      "Epoch 21/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6429 - loss: 0.6863 - precision: 0.0961 - recall: 0.5913 \n",
      "Epoch 22/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6524 - loss: 0.6417 - precision: 0.1008 - recall: 0.6345 \n",
      "Epoch 23/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5843 - loss: 0.6369 - precision: 0.0948 - recall: 0.7346 \n",
      "Epoch 24/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6698 - loss: 0.6505 - precision: 0.1043 - recall: 0.6288 \n",
      "Epoch 25/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6280 - loss: 0.5999 - precision: 0.0849 - recall: 0.6542 \n",
      "Epoch 26/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6013 - loss: 0.6209 - precision: 0.0955 - recall: 0.7173 \n",
      "Epoch 27/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6909 - loss: 0.5990 - precision: 0.0972 - recall: 0.5862 \n",
      "Epoch 28/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6381 - loss: 0.6305 - precision: 0.0907 - recall: 0.6227 \n",
      "Epoch 29/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5814 - loss: 0.6131 - precision: 0.0954 - recall: 0.8189 \n",
      "Epoch 30/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4817 - loss: 0.6443 - precision: 0.0818 - recall: 0.8279 \n",
      "Epoch 31/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5113 - loss: 0.6104 - precision: 0.0784 - recall: 0.8177 \n",
      "Epoch 32/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6931 - loss: 0.6201 - precision: 0.0962 - recall: 0.5768 \n",
      "Epoch 33/33\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6209 - loss: 0.5996 - precision: 0.1014 - recall: 0.7235 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▇█▅█▆▄▆▆▁▃▂▂▅▄▂▃▄▄▁▁▇▆▁▄▆▄▃▅▅▄▄▆▅▃▂▂▅▆▄</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▄▆▆▅▅▅▄▃▅▅▅▆▂▂▄▅▆▄▄▅▄▄▄▆█▆▃▄▄▁▆▂▄▄▃▄▃▃▅▄</td></tr><tr><td>batch/precision</td><td>▁▅▅▅█▄▄▅▆▄▅▆▄▆▅▄▅▆▄▄▄▆▆▅▆█▅▅▆▄▅▅▆▅▅▅▃▅▆▅</td></tr><tr><td>batch/recall</td><td>▁▃▂▆▅▄▆▅▅▇▇▇█▆▆▇▆█▅▇█▄▅█▅▆▆▇▆▆▆▆▅▆▇█▇▅▅▇</td></tr><tr><td>epoch/accuracy</td><td>▇█▅█▅▆▆▁▄▁▄▃▂▃▅▁▁█▅▁▅▄▄▅▅▄▆▄▄▁▃▆▄</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>▅▆▃▃▃▂▄▅▇▃█▄▇▄█▅▃▄▃▃▅▂▃▃▃▁▁▄█▃▄▄▁</td></tr><tr><td>epoch/precision</td><td>▃▄▅█▃▅▆▁▃▁▄▃▂▃▅▁▂▇▅▃▅▄▄▆▅▄▆▄▄▃▄▆▄</td></tr><tr><td>epoch/recall</td><td>▂▁▅▃▄▄▄▇▆▇▅▆▇▆▅▇█▃▅█▅▅▆▅▆▆▄▆▆█▇▄▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56499</td></tr><tr><td>batch/accuracy</td><td>0.58886</td></tr><tr><td>batch/batch_step</td><td>230</td></tr><tr><td>batch/loss</td><td>0.57534</td></tr><tr><td>batch/precision</td><td>0.09242</td></tr><tr><td>batch/recall</td><td>0.7439</td></tr><tr><td>epoch/accuracy</td><td>0.58886</td></tr><tr><td>epoch/epoch</td><td>32</td></tr><tr><td>epoch/loss</td><td>0.57534</td></tr><tr><td>epoch/precision</td><td>0.09242</td></tr><tr><td>epoch/recall</td><td>0.7439</td></tr><tr><td>f1_score</td><td>0.16327</td></tr><tr><td>precision</td><td>0.09091</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rose-sweep-51</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/73qjzmj3/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/73qjzmj3/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001310-73qjzmj3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f970ou09 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 52\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08518165109142678\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001326-f970ou09</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/f970ou09/workspace' target=\"_blank\">glorious-sweep-52</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/f970ou09/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/f970ou09/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4952 - loss: 0.7618 - precision: 0.0439 - recall: 0.4673         \n",
      "Epoch 2/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2759 - loss: 0.7135 - precision: 0.0555 - recall: 0.7175            \n",
      "Epoch 3/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3591 - loss: 0.7008 - precision: 0.0508 - recall: 0.6347\n",
      "Epoch 4/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3814 - loss: 0.7088 - precision: 0.0566 - recall: 0.6308\n",
      "Epoch 5/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1650 - loss: 0.7283 - precision: 0.0606 - recall: 0.8869\n",
      "Epoch 6/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5699 - loss: 0.7005 - precision: 0.0492 - recall: 0.4312        \n",
      "Epoch 7/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2653 - loss: 0.7067 - precision: 0.0433 - recall: 0.6698        \n",
      "Epoch 8/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1097 - loss: 0.7800 - precision: 0.0687 - recall: 0.9600\n",
      "Epoch 9/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8046 - loss: 0.7075 - precision: 0.0269 - recall: 0.1557        \n",
      "Epoch 10/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5728 - loss: 0.6847 - precision: 0.0372 - recall: 0.3313\n",
      "Epoch 11/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1095 - loss: 0.7147 - precision: 0.0581 - recall: 0.9523\n",
      "Epoch 12/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3252 - loss: 0.7206 - precision: 0.0483 - recall: 0.6170        \n",
      "Epoch 13/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.6874 - precision: 0.0202 - recall: 0.0591        \n",
      "Epoch 14/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1395 - loss: 0.7231 - precision: 0.0586 - recall: 0.9027\n",
      "Epoch 15/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6574 - loss: 0.7605 - precision: 0.0397 - recall: 0.2667        \n",
      "Epoch 16/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3755 - loss: 0.7152 - precision: 0.0472 - recall: 0.5755       \n",
      "Epoch 17/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3904 - loss: 0.7266 - precision: 0.0522 - recall: 0.5998        \n",
      "Epoch 18/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5871 - loss: 0.6936 - precision: 0.0496 - recall: 0.3962        \n",
      "Epoch 19/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2033 - loss: 0.7586 - precision: 0.0682 - recall: 0.8901        \n",
      "Epoch 20/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6478 - loss: 0.7025 - precision: 0.0400 - recall: 0.3185        \n",
      "Epoch 21/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5625 - loss: 0.6479 - precision: 0.0472 - recall: 0.4769        \n",
      "Epoch 22/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1637 - loss: 0.7563 - precision: 0.0667 - recall: 0.9159\n",
      "Epoch 23/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6252 - loss: 0.6990 - precision: 0.0357 - recall: 0.2969        \n",
      "Epoch 24/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1247 - loss: 0.7434 - precision: 0.0627 - recall: 0.9315\n",
      "Epoch 25/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7697 - loss: 0.6555 - precision: 0.0286 - recall: 0.1776        \n",
      "Epoch 26/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2398 - loss: 0.6995 - precision: 0.0520 - recall: 0.7752       \n",
      "Epoch 27/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1497 - loss: 0.7246 - precision: 0.0571 - recall: 0.8831        \n",
      "Epoch 28/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.6764 - precision: 0.0156 - recall: 0.0517        \n",
      "Epoch 29/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1860 - loss: 0.7037 - precision: 0.0556 - recall: 0.8512\n",
      "Epoch 30/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5879 - loss: 0.6893 - precision: 0.0408 - recall: 0.3923        \n",
      "Epoch 31/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6701 - loss: 0.7234 - precision: 0.0368 - recall: 0.2913        \n",
      "Epoch 32/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.6449 - precision: 0.0203 - recall: 0.1002        \n",
      "Epoch 33/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0747 - loss: 0.6942 - precision: 0.0516 - recall: 0.9263            \n",
      "Epoch 34/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5680 - loss: 0.7674 - precision: 0.0554 - recall: 0.4255        \n",
      "Epoch 35/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8402 - loss: 0.6485 - precision: 0.0243 - recall: 0.1282        \n",
      "Epoch 36/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2389 - loss: 0.7218 - precision: 0.0595 - recall: 0.7991            \n",
      "Epoch 37/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4830 - loss: 0.6680 - precision: 0.0430 - recall: 0.4605            \n",
      "Epoch 38/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4741 - loss: 0.6644 - precision: 0.0332 - recall: 0.3602\n",
      "Epoch 39/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2572 - loss: 0.6628 - precision: 0.0391 - recall: 0.5941            \n",
      "Epoch 40/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6752 - loss: 0.6934 - precision: 0.0457 - recall: 0.2731\n",
      "Epoch 41/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3561 - loss: 0.7193 - precision: 0.0536 - recall: 0.6100\n",
      "Epoch 42/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8779 - loss: 0.6414 - precision: 0.0221 - recall: 0.0947        \n",
      "Epoch 43/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3268 - loss: 0.7051 - precision: 0.0521 - recall: 0.6615\n",
      "Epoch 44/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.6941 - precision: 0.0064 - recall: 0.0069        \n",
      "Epoch 45/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0494 - loss: 0.6723 - precision: 0.0494 - recall: 0.9844            \n",
      "Epoch 46/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8641 - loss: 0.6489 - precision: 0.0217 - recall: 0.0976        \n",
      "Epoch 47/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3008 - loss: 0.6809 - precision: 0.0484 - recall: 0.6827\n",
      "Epoch 48/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5892 - loss: 0.6839 - precision: 0.0439 - recall: 0.3476\n",
      "Epoch 49/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3220 - loss: 0.6653 - precision: 0.0442 - recall: 0.6199            \n",
      "Epoch 50/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4547 - loss: 0.6626 - precision: 0.0438 - recall: 0.4867            \n",
      "Epoch 51/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0936 - loss: 0.6944 - precision: 0.0531 - recall: 0.9456\n",
      "Epoch 52/52\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5363 - loss: 0.7012 - precision: 0.0360 - recall: 0.2961            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▄▃▁▁▃▂█▅▁█▁▅▃▅▂▄▁▅▃▂▁▆▄▆▅██▃▂▃▆█▁██▁▇▄▁▅</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▅▄█▆▄▄▄▃▄▄▄▄▆▅▄▄▆▄▄▄▄▄▄▅▄▇▄▄▂▄▄▁▃▃▂▃▄▄▄▄</td></tr><tr><td>batch/precision</td><td>▄▅█▆▅▄▁▄▅▁▅▄▇▇▅▅▆▅▅▅▅▄▅▅▅▁▁▅▃▅▄▁▅▁▁▅▄▅▅▄</td></tr><tr><td>batch/recall</td><td>▅▆██▆▆▁▄█▁█▄▆▅▇▄█▄▆▇█▃▅▃▄▁▁▇▄▆▃▁█▁▁█▂▅█▄</td></tr><tr><td>epoch/accuracy</td><td>▄▆▄▆▅▂▃▅▃▃▄▆▅▆▄▆▆▅▄▆▃▆▅▄▆▂▅▄▄▄▄▅▆█▁▆▆▃▆▄</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▃▁▄▂▁▃▂▂▁▂▁▂▂▂▂▂▂▂▁▂▁▂▂▂▁▂▁▂▂▁▁▁▂▂▁▁▁▃</td></tr><tr><td>epoch/precision</td><td>▄▃▃▃▃▃▄▁▄▃▄▂▃▂▄▃▅▂▄▁▄▃▃▃▅▃▄▃▂▂▃▃▄█▃▄▂▃▃▁</td></tr><tr><td>epoch/recall</td><td>▅▃▄▃▃▆▆▃▆▅▅▂▄▃▆▃▄▄▆▂▆▂▄▅▄▇▄▅▄▄▄▄▃▁█▃▂▅▃▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.42573</td></tr><tr><td>batch/batch_step</td><td>3275</td></tr><tr><td>batch/loss</td><td>0.70315</td></tr><tr><td>batch/precision</td><td>0.04419</td></tr><tr><td>batch/recall</td><td>0.46341</td></tr><tr><td>epoch/accuracy</td><td>0.42573</td></tr><tr><td>epoch/epoch</td><td>51</td></tr><tr><td>epoch/loss</td><td>0.70315</td></tr><tr><td>epoch/precision</td><td>0.04419</td></tr><tr><td>epoch/recall</td><td>0.46341</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-sweep-52</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/f970ou09/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/f970ou09/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001326-f970ou09/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: psr8nc4e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.051567789491943274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001357-psr8nc4e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/psr8nc4e/workspace' target=\"_blank\">volcanic-sweep-53</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/psr8nc4e/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/psr8nc4e/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8907 - loss: 0.3669 - precision: 0.0370 - recall: 0.0330\n",
      "Epoch 2/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.2028 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.2190 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2070 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1896 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1991 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1955 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2021 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.2139 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1852 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.2322 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1971 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1840 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1964 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2145 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1709 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.2106 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.2325 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1904 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9393 - loss: 0.2179 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.2004 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1972 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9595 - loss: 0.1740 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.2280 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2160 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2132 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9370 - loss: 0.2236 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1763 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9415 - loss: 0.2132 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1917 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.2205 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2179 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/56\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.2100 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▃▄▄▄▄▅▄▄▅▄▄▄▄▃▄▄▃▃▃▄▄▃█▄▄▅▄▄▄▄▃▄▄▄▄▄▄▃▄</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▃▄▄▄▃▄▄▃▄▄▄▄▅▄▄▅▄▅▄▄▅▁▄▄▃▄▄▄▄▄▄▃▄▄▄▄▄▄</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▃▂▂▂▂▁▁▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▂</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>839</td></tr><tr><td>batch/loss</td><td>0.2078</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>55</td></tr><tr><td>epoch/loss</td><td>0.2078</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-sweep-53</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/psr8nc4e/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/psr8nc4e/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001357-psr8nc4e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bqibi66b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 26\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06246996954165944\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001412-bqibi66b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/bqibi66b/workspace' target=\"_blank\">sparkling-sweep-54</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/bqibi66b/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/bqibi66b/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9453 - loss: 0.2707 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 2/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9357 - loss: 0.2416 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9549 - loss: 0.1792 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2137 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1904 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1902 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2084 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1897 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 9/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9370 - loss: 0.2246 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.2331 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9289 - loss: 0.2507 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2099 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1887 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.2150 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 15/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.2189 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2233 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1789 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.2039 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 19/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9401 - loss: 0.2227 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 20/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1975 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 21/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1995 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 22/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 23/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1893 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 24/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2028 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 25/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2115 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 26/26\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▂▃▃▂▃▃█▃▄▅▃▃▂▃▂▃▂▂▃▃▃▃▂▃▃▄▄▄▃▄▄▃▁▃▄▂▃▃▃▃</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▆▇▅▆▁▅▅▄▆▅▅▅▆▅▆▆▅▅▆▅▆▆▅▅▅▅▅▅▅▅▇▅▅▆▅▅▅▅</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▁▂▂▃▂▁▂▁▁▁▃▁▁▁▂▂▁▂▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>1637</td></tr><tr><td>batch/loss</td><td>0.20307</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>25</td></tr><tr><td>epoch/loss</td><td>0.20307</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sparkling-sweep-54</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/bqibi66b/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/bqibi66b/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001412-bqibi66b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qpqqogma with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 160\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 98\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0485137913228671\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29594b42b5854d2f914ff793ee5fbc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111237479999545, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001429-qpqqogma</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/qpqqogma/workspace' target=\"_blank\">dainty-sweep-55</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/qpqqogma/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/qpqqogma/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4428 - loss: 0.7568 - precision: 0.0737 - recall: 0.6658\n",
      "Epoch 2/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7485 - loss: 0.6817 - precision: 0.0379 - recall: 0.1682 \n",
      "Epoch 3/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7103 - loss: 0.6836 - precision: 0.0964 - recall: 0.4899 \n",
      "Epoch 4/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6817 - loss: 0.5994 - precision: 0.0813 - recall: 0.5870 \n",
      "Epoch 5/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4115 - loss: 0.6798 - precision: 0.0654 - recall: 0.7477 \n",
      "Epoch 6/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6226 - loss: 0.6671 - precision: 0.0881 - recall: 0.6155 \n",
      "Epoch 7/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6641 - loss: 0.6913 - precision: 0.1109 - recall: 0.6391 \n",
      "Epoch 8/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5709 - loss: 0.6603 - precision: 0.0725 - recall: 0.5898 \n",
      "Epoch 9/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6969 - loss: 0.6414 - precision: 0.0815 - recall: 0.4709 \n",
      "Epoch 10/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5058 - loss: 0.6532 - precision: 0.0865 - recall: 0.8262 \n",
      "Epoch 11/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5378 - loss: 0.7440 - precision: 0.0894 - recall: 0.6510 \n",
      "Epoch 12/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5065 - loss: 0.6607 - precision: 0.0838 - recall: 0.7711 \n",
      "Epoch 13/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7117 - loss: 0.6918 - precision: 0.0870 - recall: 0.4391 \n",
      "Epoch 14/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6218 - loss: 0.6570 - precision: 0.0880 - recall: 0.6047 \n",
      "Epoch 15/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6250 - loss: 0.6378 - precision: 0.0973 - recall: 0.7073 \n",
      "Epoch 16/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6168 - loss: 0.6466 - precision: 0.0889 - recall: 0.6425 \n",
      "Epoch 17/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5586 - loss: 0.6666 - precision: 0.0854 - recall: 0.6675 \n",
      "Epoch 18/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6527 - loss: 0.6034 - precision: 0.0940 - recall: 0.6841 \n",
      "Epoch 19/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5173 - loss: 0.6517 - precision: 0.0803 - recall: 0.7214 \n",
      "Epoch 20/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6724 - loss: 0.6159 - precision: 0.0921 - recall: 0.6056 \n",
      "Epoch 21/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5274 - loss: 0.6256 - precision: 0.0763 - recall: 0.7351 \n",
      "Epoch 22/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6158 - loss: 0.6474 - precision: 0.0951 - recall: 0.6619 \n",
      "Epoch 23/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5372 - loss: 0.6301 - precision: 0.0911 - recall: 0.7613 \n",
      "Epoch 24/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5725 - loss: 0.6359 - precision: 0.0952 - recall: 0.7453 \n",
      "Epoch 25/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5770 - loss: 0.6598 - precision: 0.0967 - recall: 0.7497 \n",
      "Epoch 26/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6907 - loss: 0.6160 - precision: 0.0778 - recall: 0.4966 \n",
      "Epoch 27/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4802 - loss: 0.6537 - precision: 0.0906 - recall: 0.8025 \n",
      "Epoch 28/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7906 - loss: 0.6857 - precision: 0.1260 - recall: 0.4000 \n",
      "Epoch 29/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5421 - loss: 0.6389 - precision: 0.0934 - recall: 0.7829 \n",
      "Epoch 30/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7146 - loss: 0.6730 - precision: 0.1180 - recall: 0.5641 \n",
      "Epoch 31/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5220 - loss: 0.6293 - precision: 0.1000 - recall: 0.8538 \n",
      "Epoch 32/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7233 - loss: 0.5591 - precision: 0.1099 - recall: 0.6386 \n",
      "Epoch 33/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4538 - loss: 0.6158 - precision: 0.0886 - recall: 0.9198 \n",
      "Epoch 34/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7260 - loss: 0.5713 - precision: 0.0740 - recall: 0.4345 \n",
      "Epoch 35/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5015 - loss: 0.6371 - precision: 0.0912 - recall: 0.8526 \n",
      "Epoch 36/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6921 - loss: 0.6794 - precision: 0.1312 - recall: 0.6442 \n",
      "Epoch 37/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6672 - loss: 0.5877 - precision: 0.1019 - recall: 0.6889 \n",
      "Epoch 38/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5763 - loss: 0.6273 - precision: 0.1044 - recall: 0.7770 \n",
      "Epoch 39/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6969 - loss: 0.5814 - precision: 0.1024 - recall: 0.6299 \n",
      "Epoch 40/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4798 - loss: 0.6210 - precision: 0.0839 - recall: 0.8532 \n",
      "Epoch 41/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6830 - loss: 0.6036 - precision: 0.1032 - recall: 0.6553 \n",
      "Epoch 42/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6915 - loss: 0.5773 - precision: 0.1072 - recall: 0.6814 \n",
      "Epoch 43/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4587 - loss: 0.6432 - precision: 0.0835 - recall: 0.8000 \n",
      "Epoch 44/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7564 - loss: 0.5632 - precision: 0.1161 - recall: 0.6215 \n",
      "Epoch 45/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5464 - loss: 0.6333 - precision: 0.1019 - recall: 0.8147 \n",
      "Epoch 46/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6784 - loss: 0.6548 - precision: 0.1104 - recall: 0.5994 \n",
      "Epoch 47/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6897 - loss: 0.6003 - precision: 0.1092 - recall: 0.6633 \n",
      "Epoch 48/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6366 - loss: 0.5848 - precision: 0.1005 - recall: 0.7399 \n",
      "Epoch 49/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6457 - loss: 0.5772 - precision: 0.1122 - recall: 0.8030 \n",
      "Epoch 50/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6125 - loss: 0.6296 - precision: 0.1018 - recall: 0.7316 \n",
      "Epoch 51/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5796 - loss: 0.6070 - precision: 0.0923 - recall: 0.7546 \n",
      "Epoch 52/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6435 - loss: 0.6387 - precision: 0.1102 - recall: 0.7053 \n",
      "Epoch 53/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6615 - loss: 0.5730 - precision: 0.0946 - recall: 0.6662 \n",
      "Epoch 54/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6093 - loss: 0.5688 - precision: 0.1002 - recall: 0.7926 \n",
      "Epoch 55/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6541 - loss: 0.5632 - precision: 0.0982 - recall: 0.7655 \n",
      "Epoch 56/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6070 - loss: 0.5508 - precision: 0.0966 - recall: 0.7991 \n",
      "Epoch 57/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5947 - loss: 0.5797 - precision: 0.1066 - recall: 0.8246 \n",
      "Epoch 58/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6936 - loss: 0.5576 - precision: 0.1159 - recall: 0.7319 \n",
      "Epoch 59/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5130 - loss: 0.5945 - precision: 0.0908 - recall: 0.8458 \n",
      "Epoch 60/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6952 - loss: 0.5282 - precision: 0.0964 - recall: 0.6603 \n",
      "Epoch 61/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5108 - loss: 0.6148 - precision: 0.0998 - recall: 0.8789 \n",
      "Epoch 62/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7035 - loss: 0.5898 - precision: 0.1331 - recall: 0.7636 \n",
      "Epoch 63/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6197 - loss: 0.5634 - precision: 0.1070 - recall: 0.7891 \n",
      "Epoch 64/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6317 - loss: 0.6494 - precision: 0.1265 - recall: 0.7486 \n",
      "Epoch 65/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7063 - loss: 0.5709 - precision: 0.1162 - recall: 0.6953 \n",
      "Epoch 66/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6269 - loss: 0.5726 - precision: 0.1156 - recall: 0.8172 \n",
      "Epoch 67/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6356 - loss: 0.5825 - precision: 0.1108 - recall: 0.7447 \n",
      "Epoch 68/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6606 - loss: 0.5454 - precision: 0.0903 - recall: 0.6856 \n",
      "Epoch 69/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6428 - loss: 0.5682 - precision: 0.1238 - recall: 0.8213 \n",
      "Epoch 70/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7520 - loss: 0.5394 - precision: 0.1285 - recall: 0.6233 \n",
      "Epoch 71/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5268 - loss: 0.5662 - precision: 0.0948 - recall: 0.8960 \n",
      "Epoch 72/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6930 - loss: 0.5832 - precision: 0.1176 - recall: 0.6802 \n",
      "Epoch 73/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7104 - loss: 0.5285 - precision: 0.1326 - recall: 0.8148 \n",
      "Epoch 74/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5833 - loss: 0.5598 - precision: 0.1014 - recall: 0.8621 \n",
      "Epoch 75/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6144 - loss: 0.5659 - precision: 0.1179 - recall: 0.8323 \n",
      "Epoch 76/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7662 - loss: 0.5348 - precision: 0.1275 - recall: 0.6278 \n",
      "Epoch 77/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6116 - loss: 0.5526 - precision: 0.1018 - recall: 0.7598 \n",
      "Epoch 78/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6763 - loss: 0.5816 - precision: 0.1252 - recall: 0.7276 \n",
      "Epoch 79/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7724 - loss: 0.5420 - precision: 0.1366 - recall: 0.6117 \n",
      "Epoch 80/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6849 - loss: 0.5289 - precision: 0.1135 - recall: 0.7923 \n",
      "Epoch 81/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6746 - loss: 0.5300 - precision: 0.1161 - recall: 0.7580 \n",
      "Epoch 82/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7240 - loss: 0.5363 - precision: 0.1387 - recall: 0.7055 \n",
      "Epoch 83/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7362 - loss: 0.5073 - precision: 0.1273 - recall: 0.6877 \n",
      "Epoch 84/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6594 - loss: 0.5117 - precision: 0.1062 - recall: 0.7758 \n",
      "Epoch 85/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7059 - loss: 0.5156 - precision: 0.1168 - recall: 0.7128 \n",
      "Epoch 86/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7106 - loss: 0.5018 - precision: 0.1278 - recall: 0.7795 \n",
      "Epoch 87/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6899 - loss: 0.5064 - precision: 0.1209 - recall: 0.7926 \n",
      "Epoch 88/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5938 - loss: 0.5312 - precision: 0.1102 - recall: 0.9042 \n",
      "Epoch 89/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7355 - loss: 0.5732 - precision: 0.1334 - recall: 0.6805 \n",
      "Epoch 90/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7571 - loss: 0.5118 - precision: 0.1465 - recall: 0.7156 \n",
      "Epoch 91/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6637 - loss: 0.5151 - precision: 0.1260 - recall: 0.8413 \n",
      "Epoch 92/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6513 - loss: 0.5450 - precision: 0.1190 - recall: 0.7917 \n",
      "Epoch 93/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6904 - loss: 0.5571 - precision: 0.1130 - recall: 0.6978 \n",
      "Epoch 94/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6519 - loss: 0.5589 - precision: 0.1274 - recall: 0.7864 \n",
      "Epoch 95/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7724 - loss: 0.5334 - precision: 0.1488 - recall: 0.6447 \n",
      "Epoch 96/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6909 - loss: 0.5305 - precision: 0.1246 - recall: 0.7617 \n",
      "Epoch 97/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7526 - loss: 0.4840 - precision: 0.1320 - recall: 0.7268 \n",
      "Epoch 98/98\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7336 - loss: 0.5161 - precision: 0.1285 - recall: 0.7273 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▅▄▃▄▆▃▅▅▃▆▇▂▁▆▃▂▁▂▅▃▅▃▆▅▄▆▄▇▆▇▅▆▇▆▃█▅█▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▆▃▅▄▇▅▄▄▄▄▄▄▄▄█▄▄▅▄▂▄▃▁▃▃▃▃▃▂▃▁▃▂▁▂▂▂▂▂▂</td></tr><tr><td>batch/precision</td><td>▁▁▃▂▄▃▁▃▃▃▂▃▃▂█▃▂▂▃▂▂▃▂▄▄▅▄▁▅▄▃▄▅▆▄▄▆▄▆▅</td></tr><tr><td>batch/recall</td><td>▂▄▃▄▃▂▃▃▃▄▁▁▇▆▂▅▆▅▆▄▅▄▇▄▄▆▄▄▂▄▃▄▅▄▄█▃▅▂▃</td></tr><tr><td>epoch/accuracy</td><td>▂▆▃▅▅▇▅▆▆▄▅█▆▃▃▅▃▁▄▆▆▆▆▇▆▆▇▆▇▆▄▆▇█▇▆█▇██</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▇▇▅▇▅▅▅▅▅▅▅▅▅▄▄▄▅▄▄▄▃▄▃▃▃▃▃▃▃▄▂▂▂▁▁▁▂▁▂</td></tr><tr><td>epoch/precision</td><td>▁▄▂▃▄▄▄▄▄▃▄▅▅▃▃▄▄▂▄▅▅▅▅▆▆▅▆▆▆▆▄▆▇█▇▆█▇██</td></tr><tr><td>epoch/recall</td><td>▃▂▄▅▅▂▅▄▃▅▆▁▄█▇▆██▇▆▅▆▆▅▆▅▅▅▄▇▇▆▆▅▅▇▅▆▅▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55703</td></tr><tr><td>batch/accuracy</td><td>0.71883</td></tr><tr><td>batch/batch_step</td><td>979</td></tr><tr><td>batch/loss</td><td>0.53279</td></tr><tr><td>batch/precision</td><td>0.13147</td></tr><tr><td>batch/recall</td><td>0.7439</td></tr><tr><td>epoch/accuracy</td><td>0.71883</td></tr><tr><td>epoch/epoch</td><td>97</td></tr><tr><td>epoch/loss</td><td>0.53279</td></tr><tr><td>epoch/precision</td><td>0.13147</td></tr><tr><td>epoch/recall</td><td>0.7439</td></tr><tr><td>f1_score</td><td>0.1608</td></tr><tr><td>precision</td><td>0.08939</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dainty-sweep-55</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/qpqqogma/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/qpqqogma/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001429-qpqqogma/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pppp5e8h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 160\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.016579818948024024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001450-pppp5e8h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/pppp5e8h/workspace' target=\"_blank\">sunny-sweep-56</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/pppp5e8h/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/pppp5e8h/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.7101 - loss: 0.4581 - precision: 0.0696 - recall: 0.3276\n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2470 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2254 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1908 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2109 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1839 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9410 - loss: 0.2175 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2166 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.2259 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2057 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2046 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.2115 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2058 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2086 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1843 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1930 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1993 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1986 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.2064 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1956 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2068 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.1993 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1918 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2081 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1914 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2034 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1888 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9376 - loss: 0.2173 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2105 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.2130 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.2176 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1908 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.2134 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.2220 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1952 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2011 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁████▇█▇▇██████▇████████████████████████</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▃▂▂▂▂▂▃▃▂▂▂▂▂▂▃▂▂▂▁▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▂▁▂▂▁▁▁▁▁▁▂▁▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>499</td></tr><tr><td>batch/loss</td><td>0.19658</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/loss</td><td>0.19658</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sunny-sweep-56</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/pppp5e8h/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/pppp5e8h/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001450-pppp5e8h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d8276e70 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 232\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 28\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.04310212012331228\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001516-d8276e70</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/d8276e70/workspace' target=\"_blank\">treasured-sweep-57</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/d8276e70/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/d8276e70/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9439 - loss: 0.3793 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.2221 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2146 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.2056 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.1938 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.2135 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1989 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9490 - loss: 0.1974 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1881 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9452 - loss: 0.2055 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.2034 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1897 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1771 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.1883 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9439 - loss: 0.2075 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9434 - loss: 0.2076 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.2007 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.2075 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.1791 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9419 - loss: 0.2085 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.2091 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/28\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1966 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▅▄▃▄▅█▁▃▃▁▄▃▆▄▄▇▂▄▃▇▆▃▆▅▄▅▄▄▄▄▃▄▅▁▄▃▅▇▄</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▂▂▂▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▄▂▃▂▁▁▁▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▂▂</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>195</td></tr><tr><td>batch/loss</td><td>0.20058</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>27</td></tr><tr><td>epoch/loss</td><td>0.20058</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">treasured-sweep-57</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/d8276e70/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/d8276e70/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001516-d8276e70/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pnlkscn5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 208\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 56\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.03155858716503611\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001538-pnlkscn5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/pnlkscn5/workspace' target=\"_blank\">proud-sweep-58</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/pnlkscn5/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/pnlkscn5/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.4730 - loss: 0.6661 - precision: 0.0569 - recall: 0.6045\n",
      "Epoch 2/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 0.6784 - precision: 0.0909 - recall: 0.7410 \n",
      "Epoch 3/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.6687 - precision: 0.0846 - recall: 0.2915 \n",
      "Epoch 4/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4964 - loss: 0.6522 - precision: 0.0758 - recall: 0.7218 \n",
      "Epoch 5/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.6317 - precision: 0.1120 - recall: 0.4484 \n",
      "Epoch 6/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5295 - loss: 0.6532 - precision: 0.0827 - recall: 0.7195 \n",
      "Epoch 7/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6683 - loss: 0.6235 - precision: 0.1003 - recall: 0.6463 \n",
      "Epoch 8/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5827 - loss: 0.6396 - precision: 0.0809 - recall: 0.6660 \n",
      "Epoch 9/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5735 - loss: 0.6549 - precision: 0.0790 - recall: 0.6443 \n",
      "Epoch 10/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6698 - loss: 0.6515 - precision: 0.1015 - recall: 0.6217 \n",
      "Epoch 11/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6694 - loss: 0.6735 - precision: 0.0884 - recall: 0.5162 \n",
      "Epoch 12/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6168 - loss: 0.6378 - precision: 0.0960 - recall: 0.6998 \n",
      "Epoch 13/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.6184 - precision: 0.0926 - recall: 0.4623 \n",
      "Epoch 14/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4757 - loss: 0.6276 - precision: 0.0780 - recall: 0.8160 \n",
      "Epoch 15/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5949 - loss: 0.6477 - precision: 0.0894 - recall: 0.6357 \n",
      "Epoch 16/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.6415 - precision: 0.1219 - recall: 0.6143 \n",
      "Epoch 17/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5192 - loss: 0.6120 - precision: 0.0717 - recall: 0.7549 \n",
      "Epoch 18/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6411 - loss: 0.5993 - precision: 0.0922 - recall: 0.6678 \n",
      "Epoch 19/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 0.6101 - precision: 0.0926 - recall: 0.6482 \n",
      "Epoch 20/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6089 - loss: 0.6277 - precision: 0.0916 - recall: 0.6805 \n",
      "Epoch 21/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5921 - loss: 0.6420 - precision: 0.0791 - recall: 0.6079 \n",
      "Epoch 22/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6404 - loss: 0.6127 - precision: 0.0970 - recall: 0.6737 \n",
      "Epoch 23/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6214 - loss: 0.6256 - precision: 0.1088 - recall: 0.7484 \n",
      "Epoch 24/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6840 - loss: 0.6029 - precision: 0.0988 - recall: 0.6122 \n",
      "Epoch 25/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5659 - loss: 0.6142 - precision: 0.0870 - recall: 0.7349 \n",
      "Epoch 26/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6487 - loss: 0.6199 - precision: 0.0971 - recall: 0.6431 \n",
      "Epoch 27/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5943 - loss: 0.6160 - precision: 0.0919 - recall: 0.6979 \n",
      "Epoch 28/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6142 - loss: 0.5869 - precision: 0.1088 - recall: 0.8319 \n",
      "Epoch 29/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6349 - loss: 0.6005 - precision: 0.0866 - recall: 0.6257 \n",
      "Epoch 30/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6060 - loss: 0.5855 - precision: 0.0994 - recall: 0.7915 \n",
      "Epoch 31/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6183 - loss: 0.6173 - precision: 0.1033 - recall: 0.7082 \n",
      "Epoch 32/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5984 - loss: 0.6125 - precision: 0.0980 - recall: 0.7231 \n",
      "Epoch 33/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6686 - loss: 0.5888 - precision: 0.1021 - recall: 0.6646 \n",
      "Epoch 34/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5080 - loss: 0.5810 - precision: 0.0798 - recall: 0.8233 \n",
      "Epoch 35/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5706 - loss: 0.6121 - precision: 0.0902 - recall: 0.7724 \n",
      "Epoch 36/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 0.5424 - precision: 0.1045 - recall: 0.6527 \n",
      "Epoch 37/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4958 - loss: 0.6298 - precision: 0.0974 - recall: 0.8715 \n",
      "Epoch 38/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7659 - loss: 0.5857 - precision: 0.1191 - recall: 0.5773 \n",
      "Epoch 39/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4757 - loss: 0.6056 - precision: 0.0907 - recall: 0.8859 \n",
      "Epoch 40/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 0.6063 - precision: 0.1028 - recall: 0.6947 \n",
      "Epoch 41/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5869 - precision: 0.1308 - recall: 0.6646 \n",
      "Epoch 42/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6382 - loss: 0.5979 - precision: 0.1127 - recall: 0.7606 \n",
      "Epoch 43/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6528 - loss: 0.5792 - precision: 0.1043 - recall: 0.7151 \n",
      "Epoch 44/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.6132 - precision: 0.1056 - recall: 0.7263 \n",
      "Epoch 45/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5950 - precision: 0.1234 - recall: 0.6840 \n",
      "Epoch 46/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4569 - loss: 0.5862 - precision: 0.0772 - recall: 0.8504 \n",
      "Epoch 47/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6214 - loss: 0.5947 - precision: 0.1003 - recall: 0.7182 \n",
      "Epoch 48/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6874 - loss: 0.5819 - precision: 0.1278 - recall: 0.7579 \n",
      "Epoch 49/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6238 - loss: 0.5703 - precision: 0.1055 - recall: 0.7521 \n",
      "Epoch 50/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6633 - loss: 0.5789 - precision: 0.1070 - recall: 0.7318 \n",
      "Epoch 51/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6281 - loss: 0.5382 - precision: 0.0876 - recall: 0.6993 \n",
      "Epoch 52/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5931 - loss: 0.5636 - precision: 0.0929 - recall: 0.7906 \n",
      "Epoch 53/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6460 - loss: 0.5889 - precision: 0.1136 - recall: 0.7530 \n",
      "Epoch 54/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7382 - loss: 0.5613 - precision: 0.1510 - recall: 0.7492 \n",
      "Epoch 55/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6467 - loss: 0.5597 - precision: 0.1044 - recall: 0.7480 \n",
      "Epoch 56/56\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6835 - loss: 0.5398 - precision: 0.1220 - recall: 0.8015 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▄▃▇█▄▄▃▆▅▇▄▆▅▅▅▅▄▃▅▅▅▄▄▆▃▆█▂▆▅▅▇▁▅▄▅▄▅▅▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇█▆▅▇▅▅▄▇▆▇▆▄▅▅▆▄▃▅▄▂▄▅▄▄▄▃▄▃▄▃▁▄▄▃▃▁▂▄▃</td></tr><tr><td>batch/precision</td><td>▁▅▅▅▄▄▄▆▆▅▅▆▆▅▅▅▅▄▅▆▄▅▅▆▄▇█▄▇▆▆█▄▆▆▇▄▆██</td></tr><tr><td>batch/recall</td><td>▂▆▂▁▅▅▆▄▅▁▄▄▅▅▅▄▆▆▅▇▅▆▅▄▆▅▃█▅▆▆▆█▅▆▆▇▆▆▆</td></tr><tr><td>epoch/accuracy</td><td>▁▄██▄▅▃▇▅█▆▆▃▆▅▆▄▆▅▅▆▅▄▇▃▇▂▂▆▇▅▄▁▆▆▆▅▅▇▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▆▇▆▇▇▄▄▄▇▄▆▅▅▅▅▃▅▅▄▃▃▄▃▅▃▂▃▂▂▂▂▄▃▂▃▃▁▁▂</td></tr><tr><td>epoch/precision</td><td>▁▃▄▆▃▄▃▅▄▄▄▅▃▄▄▄▄▅▄▄▅▄▄▆▃▇▃▃▆▆▅▄▃▆▆▆▅▅█▇</td></tr><tr><td>epoch/recall</td><td>▄▆▁▃▄▄▆▄▆▁▄▄▆▄▅▄▆▄▅▅▄▆▆▄▇▄██▅▅▆▆█▅▆▆▆▆▆▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.64987</td></tr><tr><td>batch/accuracy</td><td>0.69695</td></tr><tr><td>batch/batch_step</td><td>447</td></tr><tr><td>batch/loss</td><td>0.56738</td></tr><tr><td>batch/precision</td><td>0.12274</td></tr><tr><td>batch/recall</td><td>0.7439</td></tr><tr><td>epoch/accuracy</td><td>0.69695</td></tr><tr><td>epoch/epoch</td><td>55</td></tr><tr><td>epoch/loss</td><td>0.56738</td></tr><tr><td>epoch/precision</td><td>0.12274</td></tr><tr><td>epoch/recall</td><td>0.7439</td></tr><tr><td>f1_score</td><td>0.175</td></tr><tr><td>precision</td><td>0.1</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">proud-sweep-58</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/pnlkscn5/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/pnlkscn5/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001538-pnlkscn5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ht4agzxk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 62\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.02910273861247067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001550-ht4agzxk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ht4agzxk/workspace' target=\"_blank\">drawn-sweep-59</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ht4agzxk/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ht4agzxk/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7265 - loss: 0.6125 - precision: 0.0232 - recall: 0.1579\n",
      "Epoch 2/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.3675 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.2786 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9420 - loss: 0.2474 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.2215 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.2099 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2241 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.2191 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.2118 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.2389 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2165 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.2020 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.2132 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9418 - loss: 0.2240 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.2149 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2178 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9545 - loss: 0.1903 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2155 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.2102 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.2022 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.2126 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2242 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2324 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.2146 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.2110 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1909 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2165 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.2192 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2242 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9511 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9500 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9453 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.2241 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.2122 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.2091 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2155 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.2081 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2217 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.2072 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9377 - loss: 0.2306 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2220 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9367 - loss: 0.2343 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.2082 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2220 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.2181 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2174 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.2062 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.2035 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9378 - loss: 0.2346 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9466 - loss: 0.2071 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.2120 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1937 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1812 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/62\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.2208 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▇▇▇▇▇█▇▇▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>805</td></tr><tr><td>batch/loss</td><td>0.20793</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>61</td></tr><tr><td>epoch/loss</td><td>0.20793</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">drawn-sweep-59</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ht4agzxk/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ht4agzxk/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001550-ht4agzxk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p2amiifq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 39\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.03945341515109421\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001606-p2amiifq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/p2amiifq/workspace' target=\"_blank\">iconic-sweep-60</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/p2amiifq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/p2amiifq/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9444 - loss: 0.2877 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 2/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9396 - loss: 0.2279 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2194 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9478 - loss: 0.1971 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1863 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9508 - loss: 0.1918 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2123 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2055 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9394 - loss: 0.2163 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1874 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2061 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1867 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1837 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.2047 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.2027 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2086 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1911 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9376 - loss: 0.2197 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1919 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1812 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1865 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.2235 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1875 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.2289 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9476 - loss: 0.1929 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2100 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2128 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.1993 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1781 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9407 - loss: 0.2149 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/39\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▁▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▄▂▂▄▂▂▃▃▂▂▂▂▂▂▂▃▃▂▃▂▁▁▁▂▂▂▂▃▂▂▂▁▁▁▂▂▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>935</td></tr><tr><td>batch/loss</td><td>0.19594</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>38</td></tr><tr><td>epoch/loss</td><td>0.19594</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">iconic-sweep-60</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/p2amiifq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/p2amiifq/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001606-p2amiifq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 33pv6amb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 120\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 79\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.031615606200396926\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001622-33pv6amb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/33pv6amb/workspace' target=\"_blank\">colorful-sweep-61</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/33pv6amb/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/33pv6amb/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.3996 - loss: 0.7118 - precision: 0.0602 - recall: 0.6734\n",
      "Epoch 2/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5684 - loss: 0.6356 - precision: 0.0634 - recall: 0.5729 \n",
      "Epoch 3/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4984 - loss: 0.6937 - precision: 0.0763 - recall: 0.6626 \n",
      "Epoch 4/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6800 - loss: 0.6068 - precision: 0.0754 - recall: 0.5133 \n",
      "Epoch 5/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4487 - loss: 0.6714 - precision: 0.0693 - recall: 0.7199 \n",
      "Epoch 6/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6427 - loss: 0.6366 - precision: 0.0885 - recall: 0.5630 \n",
      "Epoch 7/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4240 - loss: 0.6405 - precision: 0.0701 - recall: 0.8191 \n",
      "Epoch 8/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4760 - loss: 0.6555 - precision: 0.0757 - recall: 0.7540 \n",
      "Epoch 9/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6172 - loss: 0.6250 - precision: 0.0820 - recall: 0.6331 \n",
      "Epoch 10/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7279 - loss: 0.6162 - precision: 0.0958 - recall: 0.5042 \n",
      "Epoch 11/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4260 - loss: 0.6417 - precision: 0.0712 - recall: 0.7964 \n",
      "Epoch 12/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6861 - loss: 0.6499 - precision: 0.1203 - recall: 0.6692 \n",
      "Epoch 13/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5336 - loss: 0.6556 - precision: 0.0841 - recall: 0.7193 \n",
      "Epoch 14/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7237 - loss: 0.5955 - precision: 0.0739 - recall: 0.4266 \n",
      "Epoch 15/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5673 - loss: 0.5991 - precision: 0.0895 - recall: 0.8157 \n",
      "Epoch 16/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4213 - loss: 0.6428 - precision: 0.0753 - recall: 0.8367 \n",
      "Epoch 17/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6885 - loss: 0.6427 - precision: 0.0963 - recall: 0.5303 \n",
      "Epoch 18/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4969 - loss: 0.6502 - precision: 0.0768 - recall: 0.7666 \n",
      "Epoch 19/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6340 - loss: 0.6778 - precision: 0.1019 - recall: 0.6357 \n",
      "Epoch 20/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6403 - loss: 0.6042 - precision: 0.0890 - recall: 0.6229 \n",
      "Epoch 21/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.6397 - precision: 0.0887 - recall: 0.6714 \n",
      "Epoch 22/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4838 - loss: 0.6466 - precision: 0.0851 - recall: 0.8231 \n",
      "Epoch 23/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.6615 - precision: 0.1319 - recall: 0.0921         \n",
      "Epoch 24/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5942 - loss: 0.6386 - precision: 0.0899 - recall: 0.7280 \n",
      "Epoch 25/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6018 - loss: 0.5994 - precision: 0.0760 - recall: 0.6383 \n",
      "Epoch 26/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3110 - loss: 0.6403 - precision: 0.0678 - recall: 0.9349 \n",
      "Epoch 27/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6518 - loss: 0.6231 - precision: 0.0818 - recall: 0.5484         \n",
      "Epoch 28/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5501 - loss: 0.6116 - precision: 0.0766 - recall: 0.7071 \n",
      "Epoch 29/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5639 - loss: 0.6463 - precision: 0.0829 - recall: 0.6995 \n",
      "Epoch 30/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6902 - loss: 0.5832 - precision: 0.1037 - recall: 0.6944 \n",
      "Epoch 31/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2836 - loss: 0.6485 - precision: 0.0748 - recall: 0.9947 \n",
      "Epoch 32/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4197 - loss: 0.6865 - precision: 0.0841 - recall: 0.8452 \n",
      "Epoch 33/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7468 - loss: 0.5909 - precision: 0.1511 - recall: 0.6459 \n",
      "Epoch 34/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4916 - loss: 0.6638 - precision: 0.0962 - recall: 0.8200 \n",
      "Epoch 35/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6840 - loss: 0.6275 - precision: 0.1100 - recall: 0.6364 \n",
      "Epoch 36/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4463 - loss: 0.6559 - precision: 0.0790 - recall: 0.8213 \n",
      "Epoch 37/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6615 - loss: 0.5994 - precision: 0.1021 - recall: 0.6432 \n",
      "Epoch 38/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3727 - loss: 0.5957 - precision: 0.0594 - recall: 0.8410 \n",
      "Epoch 39/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4474 - loss: 0.6069 - precision: 0.0707 - recall: 0.8168 \n",
      "Epoch 40/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5893 - loss: 0.6487 - precision: 0.0802 - recall: 0.6460 \n",
      "Epoch 41/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6198 - loss: 0.5919 - precision: 0.0931 - recall: 0.7314 \n",
      "Epoch 42/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5018 - loss: 0.5851 - precision: 0.0739 - recall: 0.8289 \n",
      "Epoch 43/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5125 - loss: 0.6317 - precision: 0.0872 - recall: 0.8140 \n",
      "Epoch 44/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6026 - loss: 0.5947 - precision: 0.0678 - recall: 0.6033 \n",
      "Epoch 45/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6341 - loss: 0.5909 - precision: 0.0792 - recall: 0.6266 \n",
      "Epoch 46/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4689 - loss: 0.6413 - precision: 0.0781 - recall: 0.8432 \n",
      "Epoch 47/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5655 - loss: 0.5903 - precision: 0.0837 - recall: 0.7752 \n",
      "Epoch 48/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4350 - loss: 0.6122 - precision: 0.0720 - recall: 0.8512 \n",
      "Epoch 49/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4143 - loss: 0.5928 - precision: 0.0650 - recall: 0.8657 \n",
      "Epoch 50/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7222 - loss: 0.6402 - precision: 0.0892 - recall: 0.4463 \n",
      "Epoch 51/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6935 - loss: 0.5974 - precision: 0.1067 - recall: 0.6520 \n",
      "Epoch 52/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6301 - loss: 0.6385 - precision: 0.0844 - recall: 0.6080 \n",
      "Epoch 53/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5176 - loss: 0.5886 - precision: 0.0740 - recall: 0.8304 \n",
      "Epoch 54/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5843 - loss: 0.5561 - precision: 0.0828 - recall: 0.7989 \n",
      "Epoch 55/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5001 - loss: 0.6089 - precision: 0.0862 - recall: 0.8656 \n",
      "Epoch 56/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5633 - loss: 0.6284 - precision: 0.0991 - recall: 0.7881 \n",
      "Epoch 57/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7451 - loss: 0.6486 - precision: 0.1167 - recall: 0.5074 \n",
      "Epoch 58/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5945 - loss: 0.5886 - precision: 0.0917 - recall: 0.7545 \n",
      "Epoch 59/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6263 - loss: 0.6135 - precision: 0.0916 - recall: 0.6708 \n",
      "Epoch 60/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6701 - loss: 0.6139 - precision: 0.1004 - recall: 0.6552 \n",
      "Epoch 61/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5828 - loss: 0.5984 - precision: 0.0868 - recall: 0.7255 \n",
      "Epoch 62/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5648 - loss: 0.5983 - precision: 0.0987 - recall: 0.8339 \n",
      "Epoch 63/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6289 - loss: 0.5738 - precision: 0.0875 - recall: 0.7255 \n",
      "Epoch 64/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6373 - loss: 0.5878 - precision: 0.1050 - recall: 0.7453 \n",
      "Epoch 65/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5695 - loss: 0.5888 - precision: 0.0898 - recall: 0.8070 \n",
      "Epoch 66/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.5495 - precision: 0.1228 - recall: 0.6332 \n",
      "Epoch 67/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3944 - loss: 0.6197 - precision: 0.0704 - recall: 0.8630 \n",
      "Epoch 68/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.5981 - precision: 0.1214 - recall: 0.4874 \n",
      "Epoch 69/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6035 - loss: 0.5925 - precision: 0.0986 - recall: 0.7435 \n",
      "Epoch 70/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7014 - loss: 0.5530 - precision: 0.1000 - recall: 0.6612 \n",
      "Epoch 71/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5922 - loss: 0.5894 - precision: 0.0953 - recall: 0.7381 \n",
      "Epoch 72/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4982 - loss: 0.6101 - precision: 0.0894 - recall: 0.8241 \n",
      "Epoch 73/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7807 - loss: 0.6298 - precision: 0.1511 - recall: 0.6070 \n",
      "Epoch 74/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5240 - loss: 0.6140 - precision: 0.0864 - recall: 0.8121 \n",
      "Epoch 75/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7566 - loss: 0.6609 - precision: 0.1513 - recall: 0.5675 \n",
      "Epoch 76/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7690 - loss: 0.5901 - precision: 0.1363 - recall: 0.6020 \n",
      "Epoch 77/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6765 - loss: 0.5943 - precision: 0.1219 - recall: 0.7504 \n",
      "Epoch 78/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5736 - loss: 0.6197 - precision: 0.0849 - recall: 0.7097 \n",
      "Epoch 79/79\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7125 - loss: 0.5714 - precision: 0.1015 - recall: 0.6402 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▅▃▄▂▅▆▄▅▄▅▅█▅▄▅▁▄▆▅▂▅▄▅▅▄▆▄▄▆▅▄▅▅▂▇▃▇▄▅▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▂█▆▄▆▆▆▄▆▇▅▃▄▂▅▅▅▆▄▁▃▄▃▄▅▄▅▅▅▄▄▄▄▅▃▃▄▄▅▄</td></tr><tr><td>batch/precision</td><td>▄▄▅▃▅█▅▅▄▆▅▁▅▂▄▄▅▆▅▃▅▄▄▄▄▆▅▆▆▅▅▅▅▄▆▄▇▅▇▆</td></tr><tr><td>batch/recall</td><td>▅▆▆▇▅▆▆▆▆▆▅▁▅▅▆█▆▅▆█▆▆▅▆▆▆▆█▅▆▇▆▆█▅▇▅▇▆▅</td></tr><tr><td>epoch/accuracy</td><td>▄▄▅▄▅▄▄▅▄▅▆█▅▅▄▁▅▅▅▄▅▄▆▅▃▆▄▅▅▅▅▅▅▄▅▆▆▆▆▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▅▅▅▄▄▄▄▆▄▄▆▄▃▃▅▃▃▄▃▂▂▂▃▄▄▃▄▃▁▃▁▁▄▂▂▂▂▁▁</td></tr><tr><td>epoch/precision</td><td>▁▂▄▃▃▃▄▅▃▄▆▅▄▅▄▂▅▄▄▃▅▅▆▄▂▆▅▄▅▆▅▅▆▃▅▆█▇██</td></tr><tr><td>epoch/recall</td><td>▄▅▅▆▅▅▆▅▆▅▅▁▅▅▆█▅▅▅▆▆▆▅▆▇▅▆▆▅▆▅▆▆▆▆▅▅▅▆▅</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.61538</td></tr><tr><td>batch/accuracy</td><td>0.71021</td></tr><tr><td>batch/batch_step</td><td>1026</td></tr><tr><td>batch/loss</td><td>0.59669</td></tr><tr><td>batch/precision</td><td>0.11828</td></tr><tr><td>batch/recall</td><td>0.67073</td></tr><tr><td>epoch/accuracy</td><td>0.71021</td></tr><tr><td>epoch/epoch</td><td>78</td></tr><tr><td>epoch/loss</td><td>0.59669</td></tr><tr><td>epoch/precision</td><td>0.11828</td></tr><tr><td>epoch/recall</td><td>0.67073</td></tr><tr><td>f1_score</td><td>0.12121</td></tr><tr><td>precision</td><td>0.06897</td></tr><tr><td>recall</td><td>0.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colorful-sweep-61</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/33pv6amb/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/33pv6amb/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001622-33pv6amb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o5vp72ep with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.09975404086854683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001637-o5vp72ep</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/o5vp72ep/workspace' target=\"_blank\">zany-sweep-62</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/o5vp72ep/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/o5vp72ep/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4534 - loss: 0.8901 - precision: 0.0491 - recall: 0.4757\n",
      "Epoch 2/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9448 - loss: 0.7137 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7484 - loss: 0.6439 - precision: 0.0710 - recall: 0.3709         \n",
      "Epoch 4/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6863 - loss: 0.6863 - precision: 0.0864 - recall: 0.4809 \n",
      "Epoch 5/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3055 - loss: 0.6825 - precision: 0.0688 - recall: 0.8854 \n",
      "Epoch 6/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.6802 - precision: 0.0890 - recall: 0.4728 \n",
      "Epoch 7/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0976 - loss: 0.7231 - precision: 0.0573 - recall: 1.0000 \n",
      "Epoch 8/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3832 - loss: 0.6726 - precision: 0.0650 - recall: 0.8074 \n",
      "Epoch 9/9\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1412 - loss: 0.6848 - precision: 0.0591 - recall: 0.9742 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▂▅▃▄▅█████▇▆▆▆▆▆▆▅▄▃▂▂▂▇▆▆▅▁▁▁▁▂▂▃▄▄▂▁▁▁</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>batch/loss</td><td>▃▄█▇▆▃▃▃▃▁▂▃▃▂▃▃▂▃▃▃▃▃▂▂▃▃▃▃▄▃▃▂▂▂▃▃▃▃▃▃</td></tr><tr><td>batch/precision</td><td>▃▃▄▄▄▁▁▁▁▁▆▆▅▆▆▅▆▆▅▅▅▄▄█▆▆▅▄▄▄▄▄▄▅▅▅▄▄▄▄</td></tr><tr><td>batch/recall</td><td>▄▃▆▅▄▁▁▁▁▁▃▄▅▅▄▄▅▅▇▇█▇▇▄▄▄▅██████▇▅▅████</td></tr><tr><td>epoch/accuracy</td><td>▅█▆▆▂▅▁▄▁</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>epoch/loss</td><td>█▃▁▂▁▂▃▃▂</td></tr><tr><td>epoch/precision</td><td>▅▁██▆▇▆▆▆</td></tr><tr><td>epoch/recall</td><td>▄▁▅▅▇▅█▅█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.05305</td></tr><tr><td>batch/accuracy</td><td>0.10743</td></tr><tr><td>batch/batch_step</td><td>62</td></tr><tr><td>batch/loss</td><td>0.686</td></tr><tr><td>batch/precision</td><td>0.0568</td></tr><tr><td>batch/recall</td><td>0.9878</td></tr><tr><td>epoch/accuracy</td><td>0.10743</td></tr><tr><td>epoch/epoch</td><td>8</td></tr><tr><td>epoch/loss</td><td>0.686</td></tr><tr><td>epoch/precision</td><td>0.0568</td></tr><tr><td>epoch/recall</td><td>0.9878</td></tr><tr><td>f1_score</td><td>0.10076</td></tr><tr><td>precision</td><td>0.05305</td></tr><tr><td>recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-62</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/o5vp72ep/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/o5vp72ep/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001637-o5vp72ep/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9dzoe3vk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 27\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.049687190260518994\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001649-9dzoe3vk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9dzoe3vk/workspace' target=\"_blank\">silver-sweep-63</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9dzoe3vk/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/9dzoe3vk/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0794 - loss: 0.7620 - precision: 0.0671 - recall: 0.9920\n",
      "Epoch 2/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.6664 - precision: 0.0767 - recall: 0.3706 \n",
      "Epoch 3/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4189 - loss: 0.7269 - precision: 0.0823 - recall: 0.8212 \n",
      "Epoch 4/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5648 - loss: 0.7233 - precision: 0.0791 - recall: 0.5716 \n",
      "Epoch 5/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6812 - loss: 0.6724 - precision: 0.0925 - recall: 0.5567 \n",
      "Epoch 6/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7347 - loss: 0.6258 - precision: 0.0941 - recall: 0.5244         \n",
      "Epoch 7/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4232 - loss: 0.7466 - precision: 0.0879 - recall: 0.8128 \n",
      "Epoch 8/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6061 - loss: 0.6872 - precision: 0.0890 - recall: 0.6317 \n",
      "Epoch 9/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6343 - loss: 0.6733 - precision: 0.0970 - recall: 0.6575 \n",
      "Epoch 10/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5785 - loss: 0.6885 - precision: 0.0941 - recall: 0.7072 \n",
      "Epoch 11/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6745 - loss: 0.6133 - precision: 0.0725 - recall: 0.5295 \n",
      "Epoch 12/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5032 - loss: 0.6861 - precision: 0.0722 - recall: 0.6501 \n",
      "Epoch 13/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6237 - loss: 0.6813 - precision: 0.0886 - recall: 0.5915 \n",
      "Epoch 14/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5914 - loss: 0.6891 - precision: 0.0861 - recall: 0.6314 \n",
      "Epoch 15/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7171 - loss: 0.5963 - precision: 0.0858 - recall: 0.5583 \n",
      "Epoch 16/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5400 - loss: 0.6976 - precision: 0.0870 - recall: 0.6643 \n",
      "Epoch 17/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6639 - loss: 0.6574 - precision: 0.0849 - recall: 0.5311 \n",
      "Epoch 18/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6280 - loss: 0.6475 - precision: 0.0887 - recall: 0.6250 \n",
      "Epoch 19/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5719 - loss: 0.6806 - precision: 0.0926 - recall: 0.6715 \n",
      "Epoch 20/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6697 - loss: 0.6587 - precision: 0.0857 - recall: 0.5277 \n",
      "Epoch 21/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6255 - loss: 0.6456 - precision: 0.0890 - recall: 0.6376 \n",
      "Epoch 22/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6167 - loss: 0.6824 - precision: 0.0788 - recall: 0.5315 \n",
      "Epoch 23/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6102 - loss: 0.7100 - precision: 0.0894 - recall: 0.5764         \n",
      "Epoch 24/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7414 - loss: 0.5982 - precision: 0.0880 - recall: 0.4902         \n",
      "Epoch 25/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5814 - loss: 0.6688 - precision: 0.0814 - recall: 0.6279 \n",
      "Epoch 26/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6252 - loss: 0.6691 - precision: 0.0971 - recall: 0.6322 \n",
      "Epoch 27/27\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6974 - loss: 0.5832 - precision: 0.0954 - recall: 0.6479 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▁█▆▅▆█▇█▄▇▆▇▆▆▇▇▅▇▇▆█▆▆▇▇▆▆▇▇▆▇▆▆█▇▆▆▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▆▆▅▅▆▅▁▅█▆▆▅▆▅▄▅▆▅▆▅▃▆▅▅▄▆▅▅▅▅▅▅▅▃▅▅▆▂▅</td></tr><tr><td>batch/precision</td><td>▅▅▅▆▅▆▇▁█▇▇▇▇▇▆▅▆▆▆▅▆▆▇▆▆▇▇▆▆▆▆▅▇▆▅▇▆▇█▇</td></tr><tr><td>batch/recall</td><td>██▃▆▇▅▄▁▅▇▅▆▅▆▆▄▅▆▅▄▆▅▅▆▅▆▅▆▄▅▆▄▆▆▄▅▆▅▇▅</td></tr><tr><td>epoch/accuracy</td><td>▁▇▅▆▇█▅▇▇▇▇▆▇▇█▆▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▆▆▅▅▅▅▄▄▃▃▃▃▃▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▃▄▄▆█▄▅▅▆▅▄▆▅▆▅▆▆▅▇▆▅▆█▅▆▇</td></tr><tr><td>epoch/recall</td><td>█▁▆▄▃▃▅▄▄▄▃▅▄▄▃▅▃▄▄▃▄▄▄▃▄▄▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54907</td></tr><tr><td>batch/accuracy</td><td>0.66578</td></tr><tr><td>batch/batch_step</td><td>512</td></tr><tr><td>batch/loss</td><td>0.64349</td></tr><tr><td>batch/precision</td><td>0.09579</td></tr><tr><td>batch/recall</td><td>0.60976</td></tr><tr><td>epoch/accuracy</td><td>0.66578</td></tr><tr><td>epoch/epoch</td><td>26</td></tr><tr><td>epoch/loss</td><td>0.64349</td></tr><tr><td>epoch/precision</td><td>0.09579</td></tr><tr><td>epoch/recall</td><td>0.60976</td></tr><tr><td>f1_score</td><td>0.16667</td></tr><tr><td>precision</td><td>0.09239</td></tr><tr><td>recall</td><td>0.85</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">silver-sweep-63</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/9dzoe3vk/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/9dzoe3vk/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001649-9dzoe3vk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gugzlver with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08986142354727446\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001710-gugzlver</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/gugzlver/workspace' target=\"_blank\">legendary-sweep-64</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/gugzlver/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/gugzlver/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5902 - loss: 0.6695 - precision: 0.0458 - recall: 0.3549\n",
      "Epoch 2/8\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5777 - loss: 0.6613 - precision: 0.0612 - recall: 0.5329 \n",
      "Epoch 3/8\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2554 - loss: 0.7076 - precision: 0.0622 - recall: 0.8448 \n",
      "Epoch 4/8\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4941 - loss: 0.6672 - precision: 0.0784 - recall: 0.8159 \n",
      "Epoch 5/8\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5734 - loss: 0.6391 - precision: 0.0548 - recall: 0.4810 \n",
      "Epoch 6/8\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5255 - loss: 0.6556 - precision: 0.0595 - recall: 0.5675 \n",
      "Epoch 7/8\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5912 - loss: 0.6409 - precision: 0.0748 - recall: 0.6560 \n",
      "Epoch 8/8\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5811 - loss: 0.6397 - precision: 0.0682 - recall: 0.5979 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▅▇▇▇▇▃▇██▆▁▁▁▁▂▄▅▅▅▅▄▆█▇▇▄▆▆▆▆▇▇▇▇▆▅▆▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▁▆▅▆▆▆▅▅▆▆▇█▇▆▆▄▅▅▆▆▆▃▄▅▆▃▄▅▆▆▃▄▅▆▆▄▃▅▅▅</td></tr><tr><td>batch/precision</td><td>▁▂▄▅▅▇▅▆▆▅▆▆▆▅▅▆▇▇▇▇▅▃▄▆▇▃▄▅▆▇█▆▇▇▇▅▄▆▇▇</td></tr><tr><td>batch/recall</td><td>▂▁▂▃▃█▄▃▃▃▇▇▇▇▇█▇▇▆▆▅▃▃▃▄▄▄▄▅▅▇▅▅▄▅▅▄▄▄▅</td></tr><tr><td>epoch/accuracy</td><td>▇▇▁▅█▆▇█</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>epoch/loss</td><td>▆█▇▇▃▄▄▁</td></tr><tr><td>epoch/precision</td><td>▁▂▂▇▆▇▆█</td></tr><tr><td>epoch/recall</td><td>▁▁█▇▃▆▄▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.51989</td></tr><tr><td>batch/accuracy</td><td>0.59748</td></tr><tr><td>batch/batch_step</td><td>111</td></tr><tr><td>batch/loss</td><td>0.66879</td></tr><tr><td>batch/precision</td><td>0.08</td></tr><tr><td>batch/recall</td><td>0.60976</td></tr><tr><td>epoch/accuracy</td><td>0.59748</td></tr><tr><td>epoch/epoch</td><td>7</td></tr><tr><td>epoch/loss</td><td>0.66879</td></tr><tr><td>epoch/precision</td><td>0.08</td></tr><tr><td>epoch/recall</td><td>0.60976</td></tr><tr><td>f1_score</td><td>0.15023</td></tr><tr><td>precision</td><td>0.0829</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-sweep-64</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/gugzlver/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/gugzlver/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001710-gugzlver/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u3qntmn6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 192\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 66\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.004146035598470784\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001721-u3qntmn6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/u3qntmn6/workspace' target=\"_blank\">lemon-sweep-65</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/u3qntmn6/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/u3qntmn6/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8984 - loss: 0.6828 - precision: 0.0385 - recall: 0.0732       \n",
      "Epoch 2/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1812 - loss: 0.7128 - precision: 0.0664 - recall: 0.9655 \n",
      "Epoch 3/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7451 - loss: 0.6635 - precision: 0.1116 - recall: 0.5270 \n",
      "Epoch 4/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6093 - loss: 0.6932 - precision: 0.0794 - recall: 0.5462 \n",
      "Epoch 5/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5571 - loss: 0.6506 - precision: 0.0877 - recall: 0.7712 \n",
      "Epoch 6/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6891 - loss: 0.6242 - precision: 0.1042 - recall: 0.6432 \n",
      "Epoch 7/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6076 - loss: 0.6180 - precision: 0.0820 - recall: 0.6724 \n",
      "Epoch 8/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5536 - loss: 0.6719 - precision: 0.0843 - recall: 0.6742 \n",
      "Epoch 9/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.6472 - precision: 0.0982 - recall: 0.5277 \n",
      "Epoch 10/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 0.6309 - precision: 0.0928 - recall: 0.7296 \n",
      "Epoch 11/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6747 - loss: 0.6136 - precision: 0.1042 - recall: 0.6853 \n",
      "Epoch 12/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6286 - loss: 0.5890 - precision: 0.0813 - recall: 0.6633 \n",
      "Epoch 13/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5906 - loss: 0.6333 - precision: 0.0864 - recall: 0.6664 \n",
      "Epoch 14/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6637 - loss: 0.6274 - precision: 0.0991 - recall: 0.6230 \n",
      "Epoch 15/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6095 - loss: 0.6439 - precision: 0.0886 - recall: 0.6280 \n",
      "Epoch 16/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6507 - loss: 0.6467 - precision: 0.1073 - recall: 0.6532 \n",
      "Epoch 17/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7005 - loss: 0.6104 - precision: 0.0884 - recall: 0.5585 \n",
      "Epoch 18/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6094 - loss: 0.6210 - precision: 0.0917 - recall: 0.6657 \n",
      "Epoch 19/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6519 - loss: 0.6207 - precision: 0.1042 - recall: 0.6756 \n",
      "Epoch 20/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6552 - loss: 0.6231 - precision: 0.1090 - recall: 0.6847 \n",
      "Epoch 21/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6643 - loss: 0.6343 - precision: 0.1062 - recall: 0.6464 \n",
      "Epoch 22/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6483 - loss: 0.5880 - precision: 0.0879 - recall: 0.6336 \n",
      "Epoch 23/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6115 - loss: 0.6158 - precision: 0.0988 - recall: 0.7341 \n",
      "Epoch 24/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6935 - loss: 0.5892 - precision: 0.1058 - recall: 0.6475 \n",
      "Epoch 25/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6244 - loss: 0.5962 - precision: 0.0940 - recall: 0.7067 \n",
      "Epoch 26/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6661 - loss: 0.6168 - precision: 0.1028 - recall: 0.6630 \n",
      "Epoch 27/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6075 - loss: 0.6700 - precision: 0.1040 - recall: 0.6875 \n",
      "Epoch 28/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7281 - loss: 0.6203 - precision: 0.1329 - recall: 0.6574 \n",
      "Epoch 29/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5788 - loss: 0.6201 - precision: 0.0901 - recall: 0.7205 \n",
      "Epoch 30/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6980 - loss: 0.6046 - precision: 0.1387 - recall: 0.7428 \n",
      "Epoch 31/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6395 - loss: 0.5806 - precision: 0.0940 - recall: 0.7320 \n",
      "Epoch 32/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6094 - loss: 0.6040 - precision: 0.0942 - recall: 0.7326 \n",
      "Epoch 33/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7119 - loss: 0.5948 - precision: 0.1221 - recall: 0.6755 \n",
      "Epoch 34/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6409 - loss: 0.5667 - precision: 0.1237 - recall: 0.8437 \n",
      "Epoch 35/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5891 - loss: 0.5916 - precision: 0.1076 - recall: 0.8220 \n",
      "Epoch 36/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.5880 - precision: 0.1247 - recall: 0.7265 \n",
      "Epoch 37/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6217 - loss: 0.6081 - precision: 0.1062 - recall: 0.7542 \n",
      "Epoch 38/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7142 - loss: 0.5541 - precision: 0.1307 - recall: 0.7509 \n",
      "Epoch 39/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5121 - loss: 0.6056 - precision: 0.0956 - recall: 0.8600 \n",
      "Epoch 40/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5926 - precision: 0.1081 - recall: 0.5573 \n",
      "Epoch 41/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5560 - loss: 0.5960 - precision: 0.1011 - recall: 0.8486 \n",
      "Epoch 42/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.5971 - precision: 0.1130 - recall: 0.6761 \n",
      "Epoch 43/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6525 - loss: 0.5821 - precision: 0.1055 - recall: 0.7547 \n",
      "Epoch 44/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6074 - loss: 0.6038 - precision: 0.1126 - recall: 0.8189 \n",
      "Epoch 45/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.6134 - precision: 0.1337 - recall: 0.7318 \n",
      "Epoch 46/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6882 - loss: 0.5925 - precision: 0.1216 - recall: 0.7191 \n",
      "Epoch 47/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6006 - loss: 0.6244 - precision: 0.1178 - recall: 0.8052 \n",
      "Epoch 48/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7510 - loss: 0.6154 - precision: 0.1397 - recall: 0.6474 \n",
      "Epoch 49/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5817 - loss: 0.5986 - precision: 0.1088 - recall: 0.8113 \n",
      "Epoch 50/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.5792 - precision: 0.1252 - recall: 0.6433 \n",
      "Epoch 51/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6266 - loss: 0.5648 - precision: 0.0920 - recall: 0.7620 \n",
      "Epoch 52/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6174 - loss: 0.5648 - precision: 0.1035 - recall: 0.7976 \n",
      "Epoch 53/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7015 - loss: 0.5660 - precision: 0.1179 - recall: 0.7309 \n",
      "Epoch 54/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5591 - loss: 0.5859 - precision: 0.0951 - recall: 0.8403 \n",
      "Epoch 55/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7312 - loss: 0.5673 - precision: 0.1200 - recall: 0.6375 \n",
      "Epoch 56/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5840 - loss: 0.6156 - precision: 0.1065 - recall: 0.7838 \n",
      "Epoch 57/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7585 - loss: 0.5773 - precision: 0.1292 - recall: 0.6399 \n",
      "Epoch 58/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5996 - loss: 0.5520 - precision: 0.1107 - recall: 0.8670 \n",
      "Epoch 59/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7089 - loss: 0.5594 - precision: 0.1163 - recall: 0.7053 \n",
      "Epoch 60/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5489 - loss: 0.5937 - precision: 0.1004 - recall: 0.8387 \n",
      "Epoch 61/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7620 - loss: 0.5412 - precision: 0.1482 - recall: 0.7506 \n",
      "Epoch 62/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 0.5657 - precision: 0.0889 - recall: 0.9213 \n",
      "Epoch 63/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7809 - loss: 0.5130 - precision: 0.1392 - recall: 0.6881 \n",
      "Epoch 64/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5116 - loss: 0.6009 - precision: 0.0894 - recall: 0.8259 \n",
      "Epoch 65/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.5796 - precision: 0.1531 - recall: 0.6785 \n",
      "Epoch 66/66\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6523 - loss: 0.5320 - precision: 0.1041 - recall: 0.7859 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▁▅▇▆▇▇▆▇▆▇▆▆▆▇▆▆▆▇▆▆▇▆▆▆▇▆▆▆▆▇▆▅▆█▇▇▅▅▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▇▆▆▅▆▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▃▂▃▃▂▂▂▁▁▃▁▂▁▂▁▂▁▂▁</td></tr><tr><td>batch/precision</td><td>▁▁▂▄▄▄▄▄▄▄▄▄▄▄▅▅▄▄▅▄▅▆▅▄▄▆▄▅▅▅▆▅▄▄█▇▇▅▄▆</td></tr><tr><td>batch/recall</td><td>▁█▅▄▅▄▅▅▅▅▄▆▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▆▆▆▅▇▇▆</td></tr><tr><td>epoch/accuracy</td><td>█▁▅▇▆▇▇▆▇▆▇▆▆▆▇▆▆▆▇▆▆▇▆▆▆▇▆▆▆▆▇▆▅▆█▇▇▅▅▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▇▆▆▅▆▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▃▂▃▃▂▂▂▁▁▃▁▂▁▂▁▂▁▂▁</td></tr><tr><td>epoch/precision</td><td>▁▁▂▄▄▄▄▄▄▄▄▄▄▄▅▅▄▄▅▄▅▆▅▄▄▆▄▅▅▅▆▅▄▄█▇▇▅▄▆</td></tr><tr><td>epoch/recall</td><td>▁█▅▄▅▄▅▅▅▅▄▆▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▆▆▆▅▇▇▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.6817</td></tr><tr><td>batch/accuracy</td><td>0.68767</td></tr><tr><td>batch/batch_step</td><td>527</td></tr><tr><td>batch/loss</td><td>0.55972</td></tr><tr><td>batch/precision</td><td>0.12086</td></tr><tr><td>batch/recall</td><td>0.7561</td></tr><tr><td>epoch/accuracy</td><td>0.68767</td></tr><tr><td>epoch/epoch</td><td>65</td></tr><tr><td>epoch/loss</td><td>0.55972</td></tr><tr><td>epoch/precision</td><td>0.12086</td></tr><tr><td>epoch/recall</td><td>0.7561</td></tr><tr><td>f1_score</td><td>0.17808</td></tr><tr><td>precision</td><td>0.10317</td></tr><tr><td>recall</td><td>0.65</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-sweep-65</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/u3qntmn6/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/u3qntmn6/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001721-u3qntmn6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2tgsp2pv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 40\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06312030176835094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001740-2tgsp2pv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2tgsp2pv/workspace' target=\"_blank\">gallant-sweep-66</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2tgsp2pv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2tgsp2pv/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8529 - loss: 0.3299 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2262 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9533 - loss: 0.1857 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2168 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1798 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1877 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9395 - loss: 0.2196 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9491 - loss: 0.1908 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9362 - loss: 0.2284 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1826 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9352 - loss: 0.2380 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2019 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.2044 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1889 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9357 - loss: 0.2295 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2095 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1942 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2109 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9374 - loss: 0.2229 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.2047 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1815 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2039 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1909 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1948 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1947 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9436 - loss: 0.2067 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2032 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1859 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2029 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2012 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.2164 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1867 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1803 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1953 - precision: 0.4500 - recall: 0.0100         \n",
      "Epoch 40/40\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2177 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▅▇█▆██▇▇▅▇▇▇▇▇▇▆█▆▆▇█▇▇▇██▇▇█▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▂▂▄▁▂▃▂▅▂▄▂▃▂▃▄▁▃▃▂▁▃▂▂▁▂▃▂▁▂▂▂▂▃▂▃▃▂▂</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▁▁▂▂▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>759</td></tr><tr><td>batch/loss</td><td>0.19882</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>39</td></tr><tr><td>epoch/loss</td><td>0.19882</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gallant-sweep-66</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/2tgsp2pv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/2tgsp2pv/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001740-2tgsp2pv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8c5xzxqj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 65\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.029141882194805537\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001755-8c5xzxqj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8c5xzxqj/workspace' target=\"_blank\">clean-sweep-67</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8c5xzxqj/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/8c5xzxqj/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3289 - loss: 0.7305 - precision: 0.0446 - recall: 0.5969\n",
      "Epoch 2/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.7154 - precision: 0.0504 - recall: 0.0549         \n",
      "Epoch 3/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3525 - loss: 0.6563 - precision: 0.0581 - recall: 0.7933 \n",
      "Epoch 4/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5927 - loss: 0.6564 - precision: 0.0884 - recall: 0.6834 \n",
      "Epoch 5/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.6423 - precision: 0.0837 - recall: 0.4119 \n",
      "Epoch 6/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7433 - loss: 0.6401 - precision: 0.0896 - recall: 0.4248 \n",
      "Epoch 7/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4750 - loss: 0.6717 - precision: 0.0753 - recall: 0.7524 \n",
      "Epoch 8/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5974 - loss: 0.6227 - precision: 0.0731 - recall: 0.6225 \n",
      "Epoch 9/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7355 - loss: 0.6239 - precision: 0.1030 - recall: 0.5674 \n",
      "Epoch 10/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1586 - loss: 0.7025 - precision: 0.0527 - recall: 0.9344 \n",
      "Epoch 11/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0559 - loss: 0.7072 - precision: 0.0559 - recall: 1.0000 \n",
      "Epoch 12/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0508 - loss: 0.6699 - precision: 0.0508 - recall: 1.0000 \n",
      "Epoch 13/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.6817 - precision: 0.0498 - recall: 0.2656 \n",
      "Epoch 14/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.7358 - precision: 0.0783 - recall: 0.3289         \n",
      "Epoch 15/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4269 - loss: 0.6771 - precision: 0.0608 - recall: 0.6794 \n",
      "Epoch 16/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4926 - loss: 0.7551 - precision: 0.0778 - recall: 0.4993 \n",
      "Epoch 17/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5032 - loss: 0.6763 - precision: 0.0546 - recall: 0.5059 \n",
      "Epoch 18/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4145 - loss: 0.7109 - precision: 0.0760 - recall: 0.7649 \n",
      "Epoch 19/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3538 - loss: 0.6725 - precision: 0.0675 - recall: 0.8747 \n",
      "Epoch 20/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5475 - loss: 0.6585 - precision: 0.0662 - recall: 0.5920 \n",
      "Epoch 21/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4650 - loss: 0.6566 - precision: 0.0686 - recall: 0.7342 \n",
      "Epoch 22/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4555 - loss: 0.6819 - precision: 0.0712 - recall: 0.7201 \n",
      "Epoch 23/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.6512 - precision: 0.1088 - recall: 0.3960 \n",
      "Epoch 24/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3130 - loss: 0.6769 - precision: 0.0609 - recall: 0.8656 \n",
      "Epoch 25/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.6566 - precision: 0.1275 - recall: 0.3850 \n",
      "Epoch 26/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5239 - loss: 0.6536 - precision: 0.0804 - recall: 0.7327 \n",
      "Epoch 27/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7582 - loss: 0.6644 - precision: 0.1022 - recall: 0.4334 \n",
      "Epoch 28/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5067 - loss: 0.6902 - precision: 0.0711 - recall: 0.6355 \n",
      "Epoch 29/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8019 - loss: 0.6834 - precision: 0.1301 - recall: 0.4097 \n",
      "Epoch 30/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7001 - loss: 0.6582 - precision: 0.0835 - recall: 0.4729 \n",
      "Epoch 31/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5089 - loss: 0.6491 - precision: 0.0794 - recall: 0.7685 \n",
      "Epoch 32/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8850 - loss: 0.6783 - precision: 0.1732 - recall: 0.2790 \n",
      "Epoch 33/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7099 - loss: 0.6457 - precision: 0.0914 - recall: 0.5184 \n",
      "Epoch 34/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3793 - loss: 0.7005 - precision: 0.0775 - recall: 0.8159 \n",
      "Epoch 35/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8849 - loss: 0.6703 - precision: 0.1024 - recall: 0.1523 \n",
      "Epoch 36/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8391 - loss: 0.6470 - precision: 0.0764 - recall: 0.2500         \n",
      "Epoch 37/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4246 - loss: 0.6298 - precision: 0.0576 - recall: 0.7423 \n",
      "Epoch 38/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6603 - loss: 0.6696 - precision: 0.1012 - recall: 0.6047 \n",
      "Epoch 39/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6642 - loss: 0.6532 - precision: 0.0687 - recall: 0.4464 \n",
      "Epoch 40/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5774 - loss: 0.6365 - precision: 0.0869 - recall: 0.7431 \n",
      "Epoch 41/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7238 - loss: 0.6815 - precision: 0.1301 - recall: 0.6104 \n",
      "Epoch 42/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6409 - loss: 0.6493 - precision: 0.0856 - recall: 0.5819 \n",
      "Epoch 43/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5780 - loss: 0.6863 - precision: 0.0789 - recall: 0.6003 \n",
      "Epoch 44/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.6307 - precision: 0.1275 - recall: 0.4809 \n",
      "Epoch 45/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5633 - loss: 0.6605 - precision: 0.0843 - recall: 0.6983 \n",
      "Epoch 46/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6435 - loss: 0.6954 - precision: 0.1039 - recall: 0.6305 \n",
      "Epoch 47/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7689 - loss: 0.6161 - precision: 0.1194 - recall: 0.5388 \n",
      "Epoch 48/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7590 - loss: 0.6332 - precision: 0.1167 - recall: 0.5346 \n",
      "Epoch 49/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6091 - loss: 0.6086 - precision: 0.0786 - recall: 0.6646 \n",
      "Epoch 50/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3999 - loss: 0.6608 - precision: 0.0801 - recall: 0.8756 \n",
      "Epoch 51/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8020 - loss: 0.7045 - precision: 0.1403 - recall: 0.4411 \n",
      "Epoch 52/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4654 - loss: 0.6821 - precision: 0.0770 - recall: 0.7532 \n",
      "Epoch 53/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8728 - loss: 0.6192 - precision: 0.1585 - recall: 0.3703 \n",
      "Epoch 54/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7009 - loss: 0.6373 - precision: 0.0876 - recall: 0.5220 \n",
      "Epoch 55/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6292 - loss: 0.6639 - precision: 0.0903 - recall: 0.6019 \n",
      "Epoch 56/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7545 - loss: 0.6593 - precision: 0.0982 - recall: 0.4206 \n",
      "Epoch 57/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7445 - loss: 0.6187 - precision: 0.0876 - recall: 0.4530 \n",
      "Epoch 58/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6664 - loss: 0.6444 - precision: 0.0921 - recall: 0.5880 \n",
      "Epoch 59/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 0.6466 - precision: 0.0955 - recall: 0.5525 \n",
      "Epoch 60/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6978 - loss: 0.6460 - precision: 0.0905 - recall: 0.4986 \n",
      "Epoch 61/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7110 - loss: 0.6265 - precision: 0.0942 - recall: 0.5479 \n",
      "Epoch 62/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7315 - loss: 0.6386 - precision: 0.0891 - recall: 0.4569 \n",
      "Epoch 63/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7207 - loss: 0.6112 - precision: 0.1067 - recall: 0.5833 \n",
      "Epoch 64/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6066 - loss: 0.6454 - precision: 0.0829 - recall: 0.6153 \n",
      "Epoch 65/65\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6716 - loss: 0.6251 - precision: 0.0934 - recall: 0.5818 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▃▇▅▆▄▇▁▁█▆▅▃▅▄▃▇▇▅▆█▄█▄▆▅▆▇▅▅▇▄▄█▆▇▆▆▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▅▄▂▄▁▆▄██▅▄▄▃▅▃▅▃▅▃▇▄▃▄▃▄▃▃▃▄▅▃▃▄▂▃▃▂▂▂</td></tr><tr><td>batch/precision</td><td>▁▂▂▂▁▂▁▁█▁▁▁▂▁▁▂▂▁▂▄▂▂▁▂▂▂▂▂▂▂▂▁▃▂▂▂▂▁▂▂</td></tr><tr><td>batch/recall</td><td>▆▂▆▅▆▅██▁▃▄▇▅▆█▂▄▆▅▃▆▁▆▅▆▄▄▆▅▄▇▇▃▅▄▄▄▄▄▅</td></tr><tr><td>epoch/accuracy</td><td>▃█▆▆▄▇▁▁▄▆▆▄▅▄▇▇▇▅▆█▆█▄▆▅▆▅▅▅▇▄▇█▆▇▆▆▇▆▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>▅▅▂▃▄█▆▄▄▅▅▅▃▃▅▅▅▂▄▆▆█▃▄▂▂▂▅▂▃▂▇▂▂▂▂▂▁▃▁</td></tr><tr><td>epoch/precision</td><td>▁▄▃▂▂▄▁▁▁▂▂▂▃▂▄▅▅▂▄▇▄▄▂▃▃▃▃▃▃▅▂▆█▄▅▄▄▅▄▄</td></tr><tr><td>epoch/recall</td><td>▆▂▅▅▆▄██▅▄▃▆▆▆▄▃▄▆▅▂▅▁▆▅▆▅▆▆▆▄▇▄▃▅▄▄▅▄▅▅</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.6817</td></tr><tr><td>batch/accuracy</td><td>0.66512</td></tr><tr><td>batch/batch_step</td><td>779</td></tr><tr><td>batch/loss</td><td>0.60833</td></tr><tr><td>batch/precision</td><td>0.09405</td></tr><tr><td>batch/recall</td><td>0.59756</td></tr><tr><td>epoch/accuracy</td><td>0.66512</td></tr><tr><td>epoch/epoch</td><td>64</td></tr><tr><td>epoch/loss</td><td>0.60833</td></tr><tr><td>epoch/precision</td><td>0.09405</td></tr><tr><td>epoch/recall</td><td>0.59756</td></tr><tr><td>f1_score</td><td>0.18919</td></tr><tr><td>precision</td><td>0.10938</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clean-sweep-67</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8c5xzxqj/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/8c5xzxqj/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001755-8c5xzxqj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tfo8a3fk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.008089984530269566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001812-tfo8a3fk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tfo8a3fk/workspace' target=\"_blank\">upbeat-sweep-68</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tfo8a3fk/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/tfo8a3fk/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4582 - loss: 0.7004 - precision: 0.0679 - recall: 0.6719\n",
      "Epoch 2/7\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7080 - loss: 0.6373 - precision: 0.0918 - recall: 0.5124 \n",
      "Epoch 3/7\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5015 - loss: 0.6794 - precision: 0.0726 - recall: 0.6498 \n",
      "Epoch 4/7\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5793 - loss: 0.6301 - precision: 0.0720 - recall: 0.6406 \n",
      "Epoch 5/7\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3894 - loss: 0.6712 - precision: 0.0737 - recall: 0.8296 \n",
      "Epoch 6/7\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6733 - loss: 0.6552 - precision: 0.0996 - recall: 0.5827 \n",
      "Epoch 7/7\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6193 - loss: 0.6254 - precision: 0.0908 - recall: 0.6876 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▂▄▃▄▄▄█▇▇▇▇▆▂▂▅▆▅▂▃▄▆▇▇▁▁▁▂▃▄█▇▇▆▅▅▅▆▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▇▆▄▆▅▅▅▃▄▃▃▄▅▄▆▅▄█▃▂▁▃▄▆▅▄▄▄▄▃▅▄▅▄▄▃▃▃▄▃</td></tr><tr><td>batch/precision</td><td>▁▂▂▂▂▂█▂▃▃▄▄▃▂▁▂▂▄▁▂▂▂▂▃▂▂▂▂▂▄▅▄▄▃▃▃▄▅▄▃</td></tr><tr><td>batch/recall</td><td>▄▄▆▄▄▄▃▁▂▃▄▄▇▆▂▃▃▇▇▇▅▁▁███▇▆▅▁▂▃▄▅▅▅▅▅▄▄</td></tr><tr><td>epoch/accuracy</td><td>▁▆▃█▁▃▅</td></tr><tr><td>epoch/epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>epoch/loss</td><td>█▃▅▆▅▃▁</td></tr><tr><td>epoch/precision</td><td>▁█▄▅▂▅▇</td></tr><tr><td>epoch/recall</td><td>▆▆▆▁▇█▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.47745</td></tr><tr><td>batch/accuracy</td><td>0.61472</td></tr><tr><td>batch/batch_step</td><td>132</td></tr><tr><td>batch/loss</td><td>0.64213</td></tr><tr><td>batch/precision</td><td>0.0876</td></tr><tr><td>batch/recall</td><td>0.64634</td></tr><tr><td>epoch/accuracy</td><td>0.61472</td></tr><tr><td>epoch/epoch</td><td>6</td></tr><tr><td>epoch/loss</td><td>0.64213</td></tr><tr><td>epoch/precision</td><td>0.0876</td></tr><tr><td>epoch/recall</td><td>0.64634</td></tr><tr><td>f1_score</td><td>0.14719</td></tr><tr><td>precision</td><td>0.08057</td></tr><tr><td>recall</td><td>0.85</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-68</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/tfo8a3fk/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/tfo8a3fk/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001812-tfo8a3fk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rl1b18zj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 81\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.06312041044199493\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001822-rl1b18zj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/rl1b18zj/workspace' target=\"_blank\">devoted-sweep-69</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/rl1b18zj/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/rl1b18zj/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9499 - loss: 0.3180 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 2/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2192 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2252 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.2232 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.2286 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.2152 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9436 - loss: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.2006 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1901 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2092 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1927 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.2177 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1802 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2120 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9541 - loss: 0.1770 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1768 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1772 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1873 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1868 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.2132 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.2257 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9364 - loss: 0.2272 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1856 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1942 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2091 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9504 - loss: 0.1819 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9406 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9536 - loss: 0.1810 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2070 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2011 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9533 - loss: 0.1805 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1987 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1921 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9445 - loss: 0.1941 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9515 - loss: 0.1838 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1991 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2021 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1716 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9422 - loss: 0.2041 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9448 - loss: 0.2013 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1801 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1887 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1876 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.1925 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1898 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1868 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9477 - loss: 0.1848 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9467 - loss: 0.1877 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9442 - loss: 0.1970 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1745 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1987 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9423 - loss: 0.2080 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9462 - loss: 0.1921 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1799 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1917 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1788 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1891 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 64/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9360 - loss: 0.2069 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 65/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9483 - loss: 0.1841 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 66/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1909 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 67/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1745 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 68/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1725 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 69/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9475 - loss: 0.1861 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 70/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1873 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 71/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1806 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 72/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1759 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 73/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1852 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 74/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9332 - loss: 0.2219 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 75/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 76/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9378 - loss: 0.2105 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 77/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 78/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1729 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 79/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 80/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2029 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 81/81\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1837 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▆▃▄▅▆▆▇▆▇▅▂▂▅▅██▆▅▁▇▆▄▅▇▄▅▅▅▃▅▆▅▆▆▆▅▇▆▅▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▇▅▅▄▄▃▄▃▄▇▇▄▄▁▃▄▄▇▃▄▅▄▃▄▄▄▃▅▄▃▃▂▃▃▄▃▄▄▃</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▂▃▃▂▂▂▂▂▃▃▂▂▂▁▂▂▂▂▂▁▂▁▂▂▁▁▁▁▂▁▂▁▂▂▂▁▂▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>890</td></tr><tr><td>batch/loss</td><td>0.18603</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>80</td></tr><tr><td>epoch/loss</td><td>0.18603</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-sweep-69</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/rl1b18zj/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/rl1b18zj/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001822-rl1b18zj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b96uckja with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 144\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 24\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00642182872088332\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001838-b96uckja</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/b96uckja/workspace' target=\"_blank\">effortless-sweep-70</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/b96uckja/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/b96uckja/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8947 - loss: 0.4353 - precision: 0.1750 - recall: 0.2037\n",
      "Epoch 2/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2585 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9482 - loss: 0.2086 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.2129 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2095 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2134 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1949 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2084 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1738 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1996 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1914 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9383 - loss: 0.2173 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2224 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9471 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2142 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9457 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.2017 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2128 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.2167 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.2120 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.2221 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.2198 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/24\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1927 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▄▆▆▆▆▆▇▇▆▅▆▆▆▆█▇▆▆▆▅▂▆▇▆▆▆▆█▆▅▆▆▅▆▅▃▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▃▂▂▂▂▂▂▂▃▂▂▂▂▁▂▂▂▂▂▅▂▁▂▂▂▂▁▂▃▂▂▂▂▃▄▂▂▂</td></tr><tr><td>batch/precision</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▃▂▂▂▂▁▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>263</td></tr><tr><td>batch/loss</td><td>0.19778</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>23</td></tr><tr><td>epoch/loss</td><td>0.19778</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-sweep-70</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/b96uckja/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/b96uckja/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240401_001838-b96uckja/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l1ht1bjs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 45\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.047753139938962914\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_001859-l1ht1bjs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/l1ht1bjs/workspace' target=\"_blank\">kind-sweep-71</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/l1ht1bjs/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/l1ht1bjs/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6102 - loss: 0.7660 - precision: 0.0453 - recall: 0.3195        \n",
      "Epoch 2/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1530 - loss: 0.6833 - precision: 0.0563 - recall: 0.9588 \n",
      "Epoch 3/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6993 - loss: 0.6857 - precision: 0.1031 - recall: 0.5116 \n",
      "Epoch 4/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3513 - loss: 0.6866 - precision: 0.0662 - recall: 0.8029 \n",
      "Epoch 5/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4320 - loss: 0.6615 - precision: 0.0701 - recall: 0.7953 \n",
      "Epoch 6/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6670 - loss: 0.6309 - precision: 0.0774 - recall: 0.5483 \n",
      "Epoch 7/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5409 - loss: 0.6527 - precision: 0.0778 - recall: 0.6861 \n",
      "Epoch 8/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7902 - loss: 0.6389 - precision: 0.0696 - recall: 0.2526 \n",
      "Epoch 9/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2747 - loss: 0.6637 - precision: 0.0554 - recall: 0.8561 \n",
      "Epoch 10/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7179 - loss: 0.6508 - precision: 0.0693 - recall: 0.3655         \n",
      "Epoch 11/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5204 - loss: 0.6970 - precision: 0.0648 - recall: 0.5963 \n",
      "Epoch 12/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7640 - loss: 0.6376 - precision: 0.1079 - recall: 0.4594 \n",
      "Epoch 13/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4370 - loss: 0.6613 - precision: 0.0723 - recall: 0.7914 \n",
      "Epoch 14/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6099 - loss: 0.6610 - precision: 0.0757 - recall: 0.5414 \n",
      "Epoch 15/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6823 - loss: 0.5937 - precision: 0.1055 - recall: 0.6955 \n",
      "Epoch 16/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3243 - loss: 0.6405 - precision: 0.0577 - recall: 0.8044         \n",
      "Epoch 17/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5819 - loss: 0.6341 - precision: 0.0876 - recall: 0.7244 \n",
      "Epoch 18/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6788 - loss: 0.6052 - precision: 0.0837 - recall: 0.5538 \n",
      "Epoch 19/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5488 - loss: 0.6133 - precision: 0.0799 - recall: 0.7376 \n",
      "Epoch 20/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4545 - loss: 0.6505 - precision: 0.0802 - recall: 0.8162 \n",
      "Epoch 21/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4694 - loss: 0.6793 - precision: 0.0906 - recall: 0.8275 \n",
      "Epoch 22/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6605 - loss: 0.6941 - precision: 0.1081 - recall: 0.6463 \n",
      "Epoch 23/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3996 - loss: 0.6051 - precision: 0.0625 - recall: 0.8137 \n",
      "Epoch 24/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4982 - loss: 0.6316 - precision: 0.0645 - recall: 0.6664 \n",
      "Epoch 25/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4668 - loss: 0.6402 - precision: 0.0797 - recall: 0.8229 \n",
      "Epoch 26/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5474 - loss: 0.6019 - precision: 0.0744 - recall: 0.7269 \n",
      "Epoch 27/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0661 - loss: 0.6674 - precision: 0.0494 - recall: 0.9957 \n",
      "Epoch 28/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6444 - loss: 0.6427 - precision: 0.0898 - recall: 0.6595 \n",
      "Epoch 29/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7882 - loss: 0.6144 - precision: 0.0981 - recall: 0.4210 \n",
      "Epoch 30/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6229 - loss: 0.7013 - precision: 0.0729 - recall: 0.4911 \n",
      "Epoch 31/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5750 - loss: 0.6194 - precision: 0.0753 - recall: 0.6936 \n",
      "Epoch 32/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7126 - loss: 0.6628 - precision: 0.1146 - recall: 0.6155 \n",
      "Epoch 33/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6560 - loss: 0.6422 - precision: 0.0790 - recall: 0.5458 \n",
      "Epoch 34/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6617 - loss: 0.6220 - precision: 0.0722 - recall: 0.5193 \n",
      "Epoch 35/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6073 - loss: 0.6400 - precision: 0.0882 - recall: 0.6633 \n",
      "Epoch 36/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7143 - loss: 0.6652 - precision: 0.0779 - recall: 0.4436         \n",
      "Epoch 37/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7178 - loss: 0.6712 - precision: 0.1002 - recall: 0.5086 \n",
      "Epoch 38/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7045 - loss: 0.6642 - precision: 0.1031 - recall: 0.5519 \n",
      "Epoch 39/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6723 - loss: 0.6605 - precision: 0.0909 - recall: 0.5346 \n",
      "Epoch 40/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6108 - loss: 0.6718 - precision: 0.1050 - recall: 0.7296 \n",
      "Epoch 41/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7102 - loss: 0.6299 - precision: 0.1000 - recall: 0.5679 \n",
      "Epoch 42/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6225 - loss: 0.6420 - precision: 0.0878 - recall: 0.6336 \n",
      "Epoch 43/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6378 - loss: 0.6235 - precision: 0.0878 - recall: 0.6280 \n",
      "Epoch 44/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6513 - loss: 0.6734 - precision: 0.0902 - recall: 0.5411 \n",
      "Epoch 45/45\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6579 - loss: 0.5799 - precision: 0.0816 - recall: 0.5907 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a67df8bd9d74b939e5e680cc0df1c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m wandb\u001b[38;5;241m.\u001b[39magent(sweep_id\u001b[38;5;241m=\u001b[39msweep_id, function\u001b[38;5;241m=\u001b[39mtrain_with_wandb, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Stop sweep recording.\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py:334\u001b[0m, in \u001b[0;36mteardown\u001b[0;34m(exit_code)\u001b[0m\n\u001b[1;32m    332\u001b[0m setup_instance \u001b[38;5;241m=\u001b[39m _WandbSetup\u001b[38;5;241m.\u001b[39m_instance\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_instance:\n\u001b[0;32m--> 334\u001b[0m     \u001b[43msetup_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m _WandbSetup\u001b[38;5;241m.\u001b[39m_instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py:272\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._teardown\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m, exit_code: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     exit_code \u001b[38;5;241m=\u001b[39m exit_code \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_setup.py:282\u001b[0m, in \u001b[0;36m_WandbSetup__WandbSetup._teardown_manager\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_manager.py:176\u001b[0m, in \u001b[0;36m_Manager._teardown\u001b[0;34m(self, exit_code)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inform_teardown(exit_code)\n\u001b[0;32m--> 176\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_notebook:\n\u001b[1;32m    178\u001b[0m         os\u001b[38;5;241m.\u001b[39m_exit(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/service/service.py:263\u001b[0m, in \u001b[0;36m_Service.join\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_proc:\n\u001b[0;32m--> 263\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_proc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:1260\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:1995\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1994\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1995\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1997\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.11/subprocess.py:1953\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1951\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1953\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mwaitpid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid, wait_flags)\n\u001b[1;32m   1954\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1955\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1956\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1957\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1958\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for drug in df.iloc[:, 8:15].columns:\n",
    "    sweep_configuration = {\n",
    "        \"name\": f\"sweep_{drug}\",\n",
    "        \"method\": \"bayes\",\n",
    "        \"metric\": {\n",
    "            \"goal\": \"maximize\",\n",
    "            \"name\": \"f1_score\",\n",
    "        },\n",
    "        \"parameters\": {\n",
    "            \"optimizer\": {\n",
    "                \"distribution\": \"categorical\",\n",
    "                \"values\": [\n",
    "                    \"adam\",\n",
    "                    \"adamw\",\n",
    "                    \"adamax\",\n",
    "                    \"sgd\",\n",
    "                ],\n",
    "            },\n",
    "            \"batch_size\": {\n",
    "                \"distribution\": \"q_uniform\",\n",
    "                \"q\": 8,\n",
    "                \"min\": 8,\n",
    "                \"max\": 256,\n",
    "            },\n",
    "            \"epoch\": {\n",
    "                \"distribution\": \"int_uniform\",\n",
    "                \"min\": 3,\n",
    "                \"max\": 100,\n",
    "            },\n",
    "            \"lr\": {\n",
    "                \"distribution\": \"uniform\",\n",
    "                \"min\": 0.00001,\n",
    "                \"max\": 0.1,\n",
    "            },\n",
    "            \"class_weighting\": {\n",
    "                \"distribution\": \"categorical\",\n",
    "                \"values\": [\n",
    "                    True,\n",
    "                    False,\n",
    "                ],\n",
    "            },\n",
    "            \"layer_1\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": 64,\n",
    "            },\n",
    "            \"activation_1\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"relu\",\n",
    "            },\n",
    "            \"input_shape_1\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": (7,),\n",
    "            },\n",
    "            \"layer_2\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": 32,\n",
    "            },\n",
    "            \"activation_2\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"relu\",\n",
    "            },\n",
    "            \"layer_3\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": 1,\n",
    "            },\n",
    "            \"activation_3\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"sigmoid\",\n",
    "            },\n",
    "            \"loss\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"binary_crossentropy\",\n",
    "            },\n",
    "            \"drug\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": drug,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Setup sweep\n",
    "    sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"XAI-group-assignment\")\n",
    "    wandb.agent(sweep_id=sweep_id, function=train_with_wandb, count=500)\n",
    "\n",
    "    # Stop sweep recording.\n",
    "    wandb.teardown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_ann_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_1,\n",
    "                activation=wandb.config.activation_1,\n",
    "                input_shape=wandb.config.input_shape_1,\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_2, activation=wandb.config.activation_2\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_3, activation=wandb.config.activation_3\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=wandb.config.loss,\n",
    "        metrics=wandb.config.metric,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize_wandb(target):\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"XAI-group-assignment\",\n",
    "        name=f\"{target}\",\n",
    "        group=\"run_epoch_25_batch_16_lr_0.001(default)\",\n",
    "        # track hyperparameters and run metadata with wandb.config\n",
    "        config={\n",
    "            \"layer_1\": 64,\n",
    "            \"activation_1\": \"relu\",\n",
    "            \"input_shape_1\": (7,),\n",
    "            \"layer_2\": 32,\n",
    "            \"activation_2\": \"relu\",\n",
    "            \"layer_3\": 1,\n",
    "            \"activation_3\": \"sigmoid\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metric\": [\"accuracy\", \"precision\", \"recall\"],\n",
    "            \"epoch\": 25,\n",
    "            \"batch_size\": 16,\n",
    "        },\n",
    "    )\n",
    "    # return wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013450-fty2d2mn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace' target=\"_blank\">Amphet</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>█▁▁▄▃▂▂▃▁▃▂▃▂▃▂▃▃▂▄▃▃▃▄▃▃</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▅▅▄▄▄▃▅▄▃▃▄▃▃▃▃▂▂▂▂▂▁▁▂</td></tr><tr><td>epoch/precision</td><td>▄▁▂▅▇▄▅▆▂▅▄▆▃▆▅▆▆▄▇▆▆▇█▆▅</td></tr><tr><td>epoch/recall</td><td>▁▇█▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇█▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.59416</td></tr><tr><td>epoch/accuracy</td><td>0.6061</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.62397</td></tr><tr><td>epoch/precision</td><td>0.08842</td></tr><tr><td>epoch/recall</td><td>0.67073</td></tr><tr><td>f1_score</td><td>0.18182</td></tr><tr><td>precision</td><td>0.1018</td></tr><tr><td>recall</td><td>0.85</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Amphet</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013450-fty2d2mn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c13e8e4795247a1afd5c7393d7b72d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112228588818754, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013502-8d7ik19v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace' target=\"_blank\">Benzo</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▄█▁▅▅▂▂▃▄▅▇▃▆▅▅▇▅▆▆▅▅▄▆▆▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▆▄▄▃▃▄▃▃▂▂▂▂▂▂▂▁▃▃▂▃▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▅▄▇▇▆▆▆▆▇█▆▇▇▆█▇▇▇▇▇▇▇▇█</td></tr><tr><td>epoch/recall</td><td>▁▃▆▇▇█▇▇▇▇▇█▇▇▇█▇█▇███▇▆▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76393</td></tr><tr><td>epoch/accuracy</td><td>0.70623</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.57874</td></tr><tr><td>epoch/precision</td><td>0.1153</td></tr><tr><td>epoch/recall</td><td>0.72368</td></tr><tr><td>f1_score</td><td>0.21239</td></tr><tr><td>precision</td><td>0.12766</td></tr><tr><td>recall</td><td>0.63158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Benzo</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013502-8d7ik19v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c80421f9f814032a3fbff00bdcfd611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112405666709593, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013513-3b2q0naq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace' target=\"_blank\">Cannabis</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▅█▇▇▇█▇▆▇▇▆▇█▇▆▇▆▇▆▆▇▆▆▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▅▄▃▃▃▃▃▂▂▃▂▂▂▃▂▂▂▂▂▁▂▂▁▁</td></tr><tr><td>epoch/precision</td><td>▁▄█▆▇▇▇▇▆▇▇▆▆█▇▆▇▆▇▆▆▇▆▆▇</td></tr><tr><td>epoch/recall</td><td>▇▅▁▃▂▃▃▄▅▆▅▄▄▇▆▆█▆▅▇▇▆█▆█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.6817</td></tr><tr><td>epoch/accuracy</td><td>0.63727</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.59136</td></tr><tr><td>epoch/precision</td><td>0.38057</td></tr><tr><td>epoch/recall</td><td>0.76216</td></tr><tr><td>f1_score</td><td>0.55556</td></tr><tr><td>precision</td><td>0.42373</td></tr><tr><td>recall</td><td>0.80645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Cannabis</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013513-3b2q0naq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662e206dbbce4aacad6492ee2713bce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112177677811511, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013526-ubweekwp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace' target=\"_blank\">Heroin</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>█▆▃▄▃▁▃▂▃▂▂▂▂▃▁▂▃▁▂▂▂▂▃▂▂</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▅▄▄▃▂▃▂▃▂▂▂▂▃▂▂▂▁▂▁▁▂</td></tr><tr><td>epoch/precision</td><td>▁█▆▇▇▇█▇█▆▇▇▇█▇▇█▆▇▇▇▇▇▇▇</td></tr><tr><td>epoch/recall</td><td>▁▄▅▅▆▇▇▇▇▇▇█▇▇██▇█▇██▇▇█▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.78249</td></tr><tr><td>epoch/accuracy</td><td>0.68302</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.49718</td></tr><tr><td>epoch/precision</td><td>0.03666</td></tr><tr><td>epoch/recall</td><td>0.78261</td></tr><tr><td>f1_score</td><td>0.12766</td></tr><tr><td>precision</td><td>0.06818</td></tr><tr><td>recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Heroin</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013526-ubweekwp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08b2cb5c2224c7aa9628f138455ec98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112446655493437, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013540-vmq1bbds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace' target=\"_blank\">Ketamine</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e50cbb40e2a4a399e957eb3befc62d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▇███████████████████████▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>▇▅▃▂▂▂▂▂▂▂▂▂█▃▃▂▃▂▂▂▂▂▁▃▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99735</td></tr><tr><td>epoch/accuracy</td><td>0.9244</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.65872</td></tr><tr><td>epoch/precision</td><td>0.00885</td></tr><tr><td>epoch/recall</td><td>0.33333</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Ketamine</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013540-vmq1bbds/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac7e543879e4a1abfecc5e77a313592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112327499965128, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013553-0sv6v044</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace' target=\"_blank\">Methadone</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa23f7cf4ff43fcbb809761cea38013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▆▅▇█▄▇▆▇█▆██▇▇▇▇█▇▇█▆▇█▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▇▄▄▄▃▃▃▄▃▄▃▃▂▃▂▃▃▃▁▂▁</td></tr><tr><td>epoch/precision</td><td>▁▃▄▅▆▅▆▅▅█▅█▆▆▆▅▆▇▇▅▇▆▇▆▆</td></tr><tr><td>epoch/recall</td><td>▆▁▄▂▂█▄▅▂▄▇▅▃▄▄▄▅▄▇▃▄▇▅▂▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57825</td></tr><tr><td>epoch/accuracy</td><td>0.6565</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.6229</td></tr><tr><td>epoch/precision</td><td>0.06767</td></tr><tr><td>epoch/recall</td><td>0.62069</td></tr><tr><td>f1_score</td><td>0.13115</td></tr><tr><td>precision</td><td>0.07143</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Methadone</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013553-0sv6v044/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c1cc711f114c14869ff676f874892f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112489822213927, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013607-hkbd95zz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace' target=\"_blank\">Semeron</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61324b3aeb954b1da0f74c27bad14a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▆█▆▅▆▁▆▄▄▂▃▄▃▂▅▅▃▃▃▃▄▄▅▄▃</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▅▆▅▅▄▇▄▄▃▃▄▃▃▃▄▂▂▃▂▂▁▂▂▁</td></tr><tr><td>epoch/precision</td><td>▄▁▆▄▇▅▁▆▆▆▆▇▅▅█▆▆▆▄▇▆██▇▇</td></tr><tr><td>epoch/recall</td><td>▂▁▄▄▅█▁▇▇██▇▇█▇▅▇█▅█▇█▇▇█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56499</td></tr><tr><td>epoch/accuracy</td><td>0.5179</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.59474</td></tr><tr><td>epoch/precision</td><td>0.00684</td></tr><tr><td>epoch/recall</td><td>0.83333</td></tr><tr><td>f1_score</td><td>0.01205</td></tr><tr><td>precision</td><td>0.0061</td></tr><tr><td>recall</td><td>0.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Semeron</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013607-hkbd95zz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': <Sequential name=sequential_14, built=True>,\n",
      " 'Benzo': <Sequential name=sequential_15, built=True>,\n",
      " 'Cannabis': <Sequential name=sequential_16, built=True>,\n",
      " 'Heroin': <Sequential name=sequential_17, built=True>,\n",
      " 'Ketamine': <Sequential name=sequential_18, built=True>,\n",
      " 'Methadone': <Sequential name=sequential_19, built=True>,\n",
      " 'Semeron': <Sequential name=sequential_20, built=True>}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.5941644562334217,\n",
      "        \"precision\": 0.10179640718562874,\n",
      "        \"recall\": 0.85,\n",
      "        \"f1_score\": 0.18181818181818182\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.7639257294429708,\n",
      "        \"precision\": 0.1276595744680851,\n",
      "        \"recall\": 0.631578947368421,\n",
      "        \"f1_score\": 0.21238938053097345\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.6816976127320955,\n",
      "        \"precision\": 0.423728813559322,\n",
      "        \"recall\": 0.8064516129032258,\n",
      "        \"f1_score\": 0.5555555555555556\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.7824933687002652,\n",
      "        \"precision\": 0.06818181818181818,\n",
      "        \"recall\": 1.0,\n",
      "        \"f1_score\": 0.1276595744680851\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9973474801061007,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.5782493368700266,\n",
      "        \"precision\": 0.07142857142857142,\n",
      "        \"recall\": 0.8,\n",
      "        \"f1_score\": 0.13114754098360656\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.5649867374005305,\n",
      "        \"precision\": 0.006097560975609756,\n",
      "        \"recall\": 0.5,\n",
      "        \"f1_score\": 0.012048192771084338\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    target_x_train, target_y_train, target_x_test, target_y_test = get_data_from_df(\n",
    "        df, target\n",
    "    )\n",
    "\n",
    "    # Calculate class weights.\n",
    "    target_class_weights = dict(\n",
    "        enumerate(\n",
    "            class_weight.compute_class_weight(\n",
    "                \"balanced\", classes=np.unique(target_y_train), y=target_y_train\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Initialize wandb\n",
    "    initialize_wandb(target)\n",
    "\n",
    "    # Create classifier.\n",
    "    target_model = create_ann_model()\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_model.fit(\n",
    "        target_x_train,\n",
    "        target_y_train,\n",
    "        epochs=wandb.config.epoch,\n",
    "        batch_size=wandb.config.batch_size,\n",
    "        class_weight=target_class_weights,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            WandbMetricsLogger(),\n",
    "        ],\n",
    "    )\n",
    "    models[target] = target_model\n",
    "\n",
    "    target_model.save(f\"./models/ann_{ target }.h5\")\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = (target_model.predict(target_x_test) >= 0.5).astype(\"int32\")\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(target_y_test, target_y_predictions)\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model_artifact = wandb.Artifact(\n",
    "        name=f\"{target}_{f1}\",\n",
    "        type=\"model\",\n",
    "        description=f\"Model trained for {target}\",\n",
    "        metadata=dict(wandb.config),\n",
    "    )\n",
    "    wandb.add_file(f\"ann_{ target }.h5\")\n",
    "    wandb.log_artifact(model_artifact)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
