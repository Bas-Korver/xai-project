{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.16.5)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.42)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.44.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (69.1.1)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 23:56:10.951919: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-31 23:56:10.975043: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>N-Score</th>\n",
       "      <th>E-Score</th>\n",
       "      <th>O-Score</th>\n",
       "      <th>A-Score</th>\n",
       "      <th>C-Score</th>\n",
       "      <th>Impulsiveness</th>\n",
       "      <th>Sensation-seeking</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Benzo</th>\n",
       "      <th>Cannabis</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Semeron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>0.40148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>-1.18084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>-0.21575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  N-Score  E-Score  O-Score  A-Score  C-Score  Impulsiveness  \\\n",
       "0    1  0.31287 -0.57545 -0.58331 -0.91699 -0.00665       -0.21712   \n",
       "1    2 -0.67825  1.93886  1.43533  0.76096 -0.14277       -0.71126   \n",
       "2    3 -0.46725  0.80523 -0.84732 -1.62090 -1.01450       -1.37983   \n",
       "3    4 -0.14882 -0.80615 -0.01928  0.59042  0.58489       -1.37983   \n",
       "4    5  0.73545 -1.63340 -0.45174 -0.30172  1.30612       -0.21712   \n",
       "\n",
       "   Sensation-seeking  Amphet  Benzo  Cannabis  Heroin  Ketamine  Methadone  \\\n",
       "0           -1.18084       0      0         0       0         0          0   \n",
       "1           -0.21575       0      0         0       0         0          0   \n",
       "2            0.40148       0      0         0       0         0          0   \n",
       "3           -1.18084       0      0         0       0         0          0   \n",
       "4           -0.21575       0      0         0       0         0          0   \n",
       "\n",
       "   Semeron  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"drug_consumption_2.txt\",\n",
    "    header=None,\n",
    "    names=[\n",
    "        \"idx\",\n",
    "        \"N-Score\",\n",
    "        \"E-Score\",\n",
    "        \"O-Score\",\n",
    "        \"A-Score\",\n",
    "        \"C-Score\",\n",
    "        \"Impulsiveness\",\n",
    "        \"Sensation-seeking\",\n",
    "        \"Amphet\",\n",
    "        \"Benzo\",\n",
    "        \"Cannabis\",\n",
    "        \"Heroin\",\n",
    "        \"Ketamine\",\n",
    "        \"Methadone\",\n",
    "        \"Semeron\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize score ranges to be [0, 1].\n",
    "for column in df.columns[1:8]:\n",
    "    column_min, column_max = df[column].min(), df[column].max()\n",
    "\n",
    "    column_normalized = (df[column] - column_min) / (column_max - column_min)\n",
    "\n",
    "    df[column] = column_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ranges:\n",
      "   idx: [1, 1888]\n",
      "   N-Score: [0.0, 1.0]\n",
      "   E-Score: [0.0, 1.0]\n",
      "   O-Score: [0.0, 1.0]\n",
      "   A-Score: [0.0, 1.0]\n",
      "   C-Score: [0.0, 1.0]\n",
      "   Impulsiveness: [0.0, 1.0]\n",
      "   Sensation-seeking: [0.0, 1.0]\n",
      "   Amphet: [0, 1]\n",
      "   Benzo: [0, 1]\n",
      "   Cannabis: [0, 1]\n",
      "   Heroin: [0, 1]\n",
      "   Ketamine: [0, 1]\n",
      "   Methadone: [0, 1]\n",
      "   Semeron: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Column ranges:\")\n",
    "for column in df.columns:\n",
    "    column_range = (df[column].min(), df[column].max())\n",
    "\n",
    "    print(f\"   { column}: [{column_range[0]}, { column_range[1] }]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      "  Amphet dataset\n",
      "     Train dataset: 0: 1426, 1: 82\n",
      "     Test dataset: 0: 357, 1: 20\n",
      "  Benzo dataset\n",
      "     Train dataset: 0: 1432, 1: 76\n",
      "     Test dataset: 0: 358, 1: 19\n",
      "  Cannabis dataset\n",
      "     Train dataset: 0: 1138, 1: 370\n",
      "     Test dataset: 0: 284, 1: 93\n",
      "  Heroin dataset\n",
      "     Train dataset: 0: 1485, 1: 23\n",
      "     Test dataset: 0: 371, 1: 6\n",
      "  Ketamine dataset\n",
      "     Train dataset: 0: 1505, 1: 3\n",
      "     Test dataset: 0: 376, 1: 1\n",
      "  Methadone dataset\n",
      "     Train dataset: 0: 1450, 1: 58\n",
      "     Test dataset: 0: 362, 1: 15\n",
      "  Semeron dataset\n",
      "     Train dataset: 0: 1502, 1: 6\n",
      "     Test dataset: 0: 375, 1: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Class counts:\")\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"  { target } dataset\\n     Train dataset: 0: { len(target_y_train[target_y_train == 0]) }, 1: { len(target_y_train[target_y_train == 1]) }\\n     Test dataset: 0: { len(target_y_test[target_y_test == 0]) }, 1: { len(target_y_test[target_y_test == 1]) }\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Benzo': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Cannabis': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Heroin': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Ketamine': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Methadone': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0),\n",
      " 'Semeron': DecisionTreeClassifier(class_weight='balanced', max_depth=15,\n",
      "                       min_samples_leaf=3, random_state=0)}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.8620689655172413,\n",
      "        \"precision\": 0.029411764705882353,\n",
      "        \"recall\": 0.05,\n",
      "        \"f1_score\": 0.037037037037037035\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.883289124668435,\n",
      "        \"precision\": 0.037037037037037035,\n",
      "        \"recall\": 0.05263157894736842,\n",
      "        \"f1_score\": 0.043478260869565216\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.6074270557029178,\n",
      "        \"precision\": 0.34104046242774566,\n",
      "        \"recall\": 0.6344086021505376,\n",
      "        \"f1_score\": 0.44360902255639095\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.9496021220159151,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9946949602122016,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.8753315649867374,\n",
      "        \"precision\": 0.05555555555555555,\n",
      "        \"recall\": 0.13333333333333333,\n",
      "        \"f1_score\": 0.0784313725490196\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.986737400530504,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    # Create classifier.\n",
    "    target_clf = DecisionTreeClassifier(\n",
    "        criterion=\"gini\",\n",
    "        max_depth=15,\n",
    "        min_samples_leaf=3,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_clf.fit(target_x_train, target_y_train)\n",
    "    models[target] = target_clf\n",
    "\n",
    "    joblib.dump(\n",
    "        target_clf, f\"./models/decision_tree_{ target.lower() }.joblib\", compress=3\n",
    "    )\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = target_clf.predict(target_x_test)\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(\n",
    "        target_y_test, target_y_predictions, zero_division=np.nan\n",
    "    )\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Benzo': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Cannabis': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Heroin': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Ketamine': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Methadone': KNeighborsClassifier(n_neighbors=3),\n",
      " 'Semeron': KNeighborsClassifier(n_neighbors=3)}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.9442970822281167,\n",
      "        \"precision\": 0.3333333333333333,\n",
      "        \"recall\": 0.05,\n",
      "        \"f1_score\": 0.08695652173913043\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.9283819628647215,\n",
      "        \"precision\": 0.1,\n",
      "        \"recall\": 0.05263157894736842,\n",
      "        \"f1_score\": 0.06896551724137931\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.7002652519893899,\n",
      "        \"precision\": 0.375,\n",
      "        \"recall\": 0.3225806451612903,\n",
      "        \"f1_score\": 0.3468208092485549\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.9840848806366048,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9973474801061007,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.9549071618037135,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.9946949602122016,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    # Create classifier.\n",
    "    target_neigh = KNeighborsClassifier(\n",
    "        n_neighbors=3,\n",
    "    )\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_neigh.fit(target_x_train, target_y_train)\n",
    "    models[target] = target_neigh\n",
    "\n",
    "    joblib.dump(target_neigh, f\"./models/knn_{ target.lower() }.joblib\", compress=3)\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = models[target].predict(target_x_test)\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(\n",
    "        target_y_test, target_y_predictions, zero_division=np.nan\n",
    "    )\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Benzo': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Cannabis': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Heroin': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Ketamine': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Methadone': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0),\n",
      " 'Semeron': RandomForestClassifier(class_weight='balanced', max_depth=25,\n",
      "                       min_samples_leaf=3, n_estimators=50, random_state=0)}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.9389920424403183,\n",
      "        \"precision\": 0.2,\n",
      "        \"recall\": 0.05,\n",
      "        \"f1_score\": 0.08\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.9257294429708223,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.726790450928382,\n",
      "        \"precision\": 0.4479166666666667,\n",
      "        \"recall\": 0.46236559139784944,\n",
      "        \"f1_score\": 0.455026455026455\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.9840848806366048,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9973474801061007,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.9575596816976127,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.9946949602122016,\n",
      "        \"precision\": NaN,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        df, train_size=0.8, shuffle=True, stratify=df[target], random_state=0\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    target_x_train, target_y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    target_x_test, target_y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    # Create classifier.\n",
    "    target_clf = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=25,\n",
    "        min_samples_leaf=3,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_clf.fit(target_x_train, target_y_train)\n",
    "    models[target] = target_clf\n",
    "\n",
    "    joblib.dump(\n",
    "        target_clf, f\"./models/random_forest_{ target.lower() }.joblib\", compress=3\n",
    "    )\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = target_clf.predict(target_x_test)\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(\n",
    "        target_y_test, target_y_predictions, zero_division=np.nan\n",
    "    )\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_df(data_frame: pd.DataFrame, target: str):\n",
    "    # Get train and test data splits, stratisfy for target.\n",
    "    target_train_df, target_test_df = train_test_split(\n",
    "        data_frame,\n",
    "        train_size=0.8,\n",
    "        shuffle=True,\n",
    "        stratify=data_frame[target],\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    # Get input and target from the data split.\n",
    "    x_train, y_train = (\n",
    "        target_train_df.iloc[:, 1:8],\n",
    "        target_train_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "    x_test, y_test = (\n",
    "        target_test_df.iloc[:, 1:8],\n",
    "        target_test_df.iloc[:, 8:15][target],\n",
    "    )\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbas_korver\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235617-4j9248zx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace' target=\"_blank\">denim-wave-171</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.008 MB uploaded\\r'), FloatProgress(value=0.5553033169378232, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-wave-171</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/4j9248zx/workspace</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235617-4j9248zx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = wandb.Artifact(\"drug_consumption\", type=\"dataset\")\n",
    "dataset.add_file(\"./drug_consumption_2.txt\")\n",
    "with wandb.init(project=\"XAI-group-assignment\", job_type=\"upload\"):\n",
    "    wandb.log_artifact(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ann_model_sweep():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_1,\n",
    "                activation=wandb.config.activation_1,\n",
    "                input_shape=wandb.config.input_shape_1,\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_2, activation=wandb.config.activation_2\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_3, activation=wandb.config.activation_3\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    match wandb.config.optimizer:\n",
    "        case \"adam\":\n",
    "            optimizer = tf.keras.optimizers.Adam\n",
    "        case \"adamw\":\n",
    "            optimizer = tf.keras.optimizers.AdamW\n",
    "        case \"adamax\":\n",
    "            optimizer = tf.keras.optimizers.Adamax\n",
    "        case \"sgd\":\n",
    "            optimizer = tf.keras.optimizers.SGD\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer(wandb.config.lr),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", \"precision\", \"recall\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb():\n",
    "    # Initialize wandb\n",
    "    with wandb.init():\n",
    "        # Load data.\n",
    "        target_x_train, target_y_train, target_x_test, target_y_test = get_data_from_df(\n",
    "            df, wandb.config.drug\n",
    "        )\n",
    "\n",
    "        # Calculate class weights.\n",
    "        if wandb.config.class_weighting:\n",
    "            target_class_weights = dict(\n",
    "                enumerate(\n",
    "                    class_weight.compute_class_weight(\n",
    "                        \"balanced\",\n",
    "                        classes=np.unique(target_y_train),\n",
    "                        y=target_y_train,\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Create classifier.\n",
    "        target_model = create_ann_model_sweep()\n",
    "\n",
    "        # Train model with data specified for target.\n",
    "        if wandb.config.class_weighting:\n",
    "            target_model.fit(\n",
    "                target_x_train,\n",
    "                target_y_train,\n",
    "                epochs=wandb.config.epoch,\n",
    "                batch_size=wandb.config.batch_size,\n",
    "                class_weight=target_class_weights,\n",
    "                callbacks=[WandbMetricsLogger(\"batch\")],\n",
    "            )\n",
    "        else:\n",
    "            target_model.fit(\n",
    "                target_x_train,\n",
    "                target_y_train,\n",
    "                epochs=wandb.config.epoch,\n",
    "                batch_size=wandb.config.batch_size,\n",
    "                callbacks=[WandbMetricsLogger(\"batch\")],\n",
    "            )\n",
    "\n",
    "        models[target] = target_model\n",
    "\n",
    "        target_model.save(f\"./models/ann_{ target }.h5\")\n",
    "\n",
    "        # Evaluate trained classifier.\n",
    "        target_y_predictions = (target_model.predict(target_x_test) >= 0.5).astype(\n",
    "            \"int32\"\n",
    "        )\n",
    "\n",
    "        # Calculate metrics.\n",
    "        accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "        precision = precision_score(target_y_test, target_y_predictions)\n",
    "        recall = recall_score(target_y_test, target_y_predictions)\n",
    "        f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": f1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        model_artifact = wandb.Artifact(\n",
    "            name=f\"{target}_{f1}\",\n",
    "            type=\"model\",\n",
    "            description=f\"Model trained for {target}\",\n",
    "            metadata=dict(wandb.config),\n",
    "        )\n",
    "        model_artifact.add_file(f\"./models/ann_{ target }.h5\")\n",
    "        wandb.log_artifact(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 9kg7b063\n",
      "Sweep URL: https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: as2ydkcv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 248\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08002929024687723\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235817-as2ydkcv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace' target=\"_blank\">classic-sweep-1</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.7232 - loss: 0.3962 - precision: 0.0753 - recall: 0.3407\n",
      "Epoch 2/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.2180 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2469 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.2161 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.2014 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9418 - loss: 0.2210 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.2269 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9416 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9506 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2177 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.2123 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.2108 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 0.2080 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2220 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2092 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.2149 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9446 - loss: 0.2094 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9505 - loss: 0.1851 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1985 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.2055 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.2136 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2017 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.2060 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/30\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.2129 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▅██▇██▇█▇██▇████████▇██▇████████████▇▇█</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▅▃▂▄▃▂▃▂▃▃▂▃▃▂▂▂▁▃▃▃▃▂▂▃▂▃▂▂▂▁▂▂▂▃▂▂▃▃▂</td></tr><tr><td>batch/precision</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁█████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▄▄▄▂▃▁▁▃▄▂▂▁▃▃▃▂▂▂▃▂▂▃▂▂▄▃▂▂▂</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>209</td></tr><tr><td>batch/loss</td><td>0.20705</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/loss</td><td>0.20705</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-1</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/as2ydkcv/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235817-as2ydkcv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kh8fw3d8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 96\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.04173528501990623\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235838-kh8fw3d8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace' target=\"_blank\">ancient-sweep-2</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.2736 - loss: 0.7149 - precision: 0.0426 - recall: 0.6581\n",
      "Epoch 2/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1855 - loss: 0.6711 - precision: 0.0537 - recall: 0.8948 \n",
      "Epoch 3/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3869 - loss: 0.6795 - precision: 0.0587 - recall: 0.6947 \n",
      "Epoch 4/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4143 - loss: 0.6633 - precision: 0.0606 - recall: 0.7326 \n",
      "Epoch 5/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 0.6774 - precision: 0.0852 - recall: 0.6441 \n",
      "Epoch 6/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9315 - loss: 0.7741 - precision: 0.0661 - recall: 0.0085         \n",
      "Epoch 7/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7010 - loss: 0.6665 - precision: 0.1197 - recall: 0.3606         \n",
      "Epoch 8/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2411 - loss: 0.6596 - precision: 0.0557 - recall: 0.8772 \n",
      "Epoch 9/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6882 - loss: 0.6553 - precision: 0.0797 - recall: 0.4834 \n",
      "Epoch 10/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5356 - loss: 0.6572 - precision: 0.0735 - recall: 0.6582 \n",
      "Epoch 11/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5763 - loss: 0.6666 - precision: 0.0876 - recall: 0.6972 \n",
      "Epoch 12/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5711 - loss: 0.7022 - precision: 0.0913 - recall: 0.6510 \n",
      "Epoch 13/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6279 - loss: 0.6734 - precision: 0.0838 - recall: 0.5784 \n",
      "Epoch 14/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6442 - loss: 0.6293 - precision: 0.0894 - recall: 0.6303 \n",
      "Epoch 15/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6351 - loss: 0.6876 - precision: 0.0940 - recall: 0.5909 \n",
      "Epoch 16/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6321 - loss: 0.7149 - precision: 0.1049 - recall: 0.5752 \n",
      "Epoch 17/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6601 - loss: 0.6356 - precision: 0.1053 - recall: 0.6678 \n",
      "Epoch 18/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7280 - loss: 0.6669 - precision: 0.0956 - recall: 0.4817 \n",
      "Epoch 19/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5842 - loss: 0.6905 - precision: 0.0940 - recall: 0.6851 \n",
      "Epoch 20/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7810 - loss: 0.6645 - precision: 0.0898 - recall: 0.3603         \n",
      "Epoch 21/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7117 - loss: 0.6623 - precision: 0.1079 - recall: 0.5661 \n",
      "Epoch 22/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6137 - loss: 0.6519 - precision: 0.0682 - recall: 0.5315         \n",
      "Epoch 23/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5755 - loss: 0.6523 - precision: 0.0801 - recall: 0.6397 \n",
      "Epoch 24/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6613 - loss: 0.6678 - precision: 0.1029 - recall: 0.5908 \n",
      "Epoch 25/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.6539 - precision: 0.1440 - recall: 0.0831         \n",
      "Epoch 26/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6448 - loss: 0.5812 - precision: 0.0809 - recall: 0.6510 \n",
      "Epoch 27/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4523 - loss: 0.7120 - precision: 0.0813 - recall: 0.7439 \n",
      "Epoch 28/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7269 - loss: 0.6717 - precision: 0.1120 - recall: 0.5130 \n",
      "Epoch 29/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6273 - loss: 0.6509 - precision: 0.0854 - recall: 0.5874 \n",
      "Epoch 30/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6536 - loss: 0.6742 - precision: 0.0990 - recall: 0.5712 \n",
      "Epoch 31/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6835 - loss: 0.6715 - precision: 0.1130 - recall: 0.5840 \n",
      "Epoch 32/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7409 - loss: 0.6470 - precision: 0.1161 - recall: 0.5624 \n",
      "Epoch 33/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6600 - loss: 0.6810 - precision: 0.0875 - recall: 0.5093 \n",
      "Epoch 34/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6942 - loss: 0.6203 - precision: 0.0956 - recall: 0.5862 \n",
      "Epoch 35/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5579 - loss: 0.6145 - precision: 0.0878 - recall: 0.8047 \n",
      "Epoch 36/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6729 - loss: 0.6647 - precision: 0.0882 - recall: 0.5368 \n",
      "Epoch 37/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6682 - loss: 0.6703 - precision: 0.1114 - recall: 0.6322 \n",
      "Epoch 38/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.6101 - precision: 0.1287 - recall: 0.5128 \n",
      "Epoch 39/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6292 - loss: 0.6272 - precision: 0.0833 - recall: 0.6606 \n",
      "Epoch 40/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6775 - loss: 0.6718 - precision: 0.0954 - recall: 0.5323 \n",
      "Epoch 41/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7874 - loss: 0.6688 - precision: 0.1248 - recall: 0.4432 \n",
      "Epoch 42/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7229 - loss: 0.6233 - precision: 0.0984 - recall: 0.5261 \n",
      "Epoch 43/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5147 - loss: 0.7023 - precision: 0.0940 - recall: 0.7515 \n",
      "Epoch 44/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8343 - loss: 0.6691 - precision: 0.1005 - recall: 0.2494         \n",
      "Epoch 45/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6606 - loss: 0.6340 - precision: 0.1025 - recall: 0.6630 \n",
      "Epoch 46/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6670 - loss: 0.6426 - precision: 0.1135 - recall: 0.6913 \n",
      "Epoch 47/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7924 - loss: 0.6525 - precision: 0.1387 - recall: 0.4924 \n",
      "Epoch 48/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7136 - loss: 0.6011 - precision: 0.0853 - recall: 0.5237 \n",
      "Epoch 49/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7091 - loss: 0.6399 - precision: 0.1155 - recall: 0.6205 \n",
      "Epoch 50/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7310 - loss: 0.6429 - precision: 0.0841 - recall: 0.4239 \n",
      "Epoch 51/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6774 - loss: 0.6448 - precision: 0.1182 - recall: 0.6737 \n",
      "Epoch 52/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.5894 - precision: 0.1493 - recall: 0.5135 \n",
      "Epoch 53/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7517 - loss: 0.6321 - precision: 0.1166 - recall: 0.5164 \n",
      "Epoch 54/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5962 - loss: 0.5880 - precision: 0.0750 - recall: 0.7204 \n",
      "Epoch 55/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 0.6333 - precision: 0.0848 - recall: 0.6593 \n",
      "Epoch 56/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.6105 - precision: 0.0850 - recall: 0.3007 \n",
      "Epoch 57/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5748 - loss: 0.6316 - precision: 0.1050 - recall: 0.7667 \n",
      "Epoch 58/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.6131 - precision: 0.0942 - recall: 0.3381         \n",
      "Epoch 59/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7205 - loss: 0.5902 - precision: 0.1150 - recall: 0.6564 \n",
      "Epoch 60/60\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.5915 - precision: 0.1295 - recall: 0.6471 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▁▃▅▆▃▄▅▄▅▄▄▄▅▄▅█▅▆▅▅▅▆▅▅▅▅▆▅▅▅▆▆▅▆▄▅▄▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▆▅▆▅▆▅▅▄▄█▅▆▅▄▅▃▄▆▄▄▇▄▆▄▆▄▃▅▂▄▃▄▆▄▁▂▄▃▂</td></tr><tr><td>batch/precision</td><td>▁▂▂▃▃▂▂▄▂▃▃▃▃▃▂▃█▃▅▃▃▃▄▄▄▄▃▃▃▄▄▄▅▄▅▂▄▄▅▅</td></tr><tr><td>batch/recall</td><td>▆█▇▅▃▇▅▅▆▆▆▆▇▅▆▅▁▆▅▆▆▄▅▅▆▆▆▄▆▆▆▅▆▆▅█▇▇▅▆</td></tr><tr><td>epoch/accuracy</td><td>▁▂▄▅▃▄▅▆▅▅▆▅▆▆▆▅█▅▆▅▅▆▆▅▆▇▅▆▅▆▆▇▆▆▆▇▅▆▆▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▆▅▆▅▆▅▅▅▃▄▄▅▄▅▄▆▄▃▃▄▄▃▄▄▄▃▄▅▅▃▃▃▃▃▄▁▃▂▁</td></tr><tr><td>epoch/precision</td><td>▁▁▂▃▂▂▂▄▃▄▃▃▄▃▃▃█▃▄▃▃▄▄▄▄▅▄▄▃▃▄▅▅▅▅▅▄▃▅▅</td></tr><tr><td>epoch/recall</td><td>██▆▅▆▇▆▅▆▆▅▆▅▅▅▅▁▆▅▆▆▅▅▇▆▄▆▅▆▄▆▅▆▅▅▄▇▅▅▆</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.687</td></tr><tr><td>batch/accuracy</td><td>0.70027</td></tr><tr><td>batch/batch_step</td><td>959</td></tr><tr><td>batch/loss</td><td>0.60555</td></tr><tr><td>batch/precision</td><td>0.11134</td></tr><tr><td>batch/recall</td><td>0.64634</td></tr><tr><td>epoch/accuracy</td><td>0.70027</td></tr><tr><td>epoch/epoch</td><td>59</td></tr><tr><td>epoch/loss</td><td>0.60555</td></tr><tr><td>epoch/precision</td><td>0.11134</td></tr><tr><td>epoch/recall</td><td>0.64634</td></tr><tr><td>f1_score</td><td>0.19178</td></tr><tr><td>precision</td><td>0.11111</td></tr><tr><td>recall</td><td>0.7</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-2</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/kh8fw3d8/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235838-kh8fw3d8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y0xljow7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 136\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 60\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.08870812353317625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamax\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235856-y0xljow7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace' target=\"_blank\">blooming-sweep-3</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.7221 - loss: 0.3901 - precision: 0.0368 - recall: 0.1995\n",
      "Epoch 2/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.2281 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.2335 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.2204 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.2007 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.2020 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9431 - loss: 0.2257 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9549 - loss: 0.1787 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9383 - loss: 0.2255 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.2002 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.2125 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9385 - loss: 0.2205 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1878 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.2133 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2083 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1940 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.2267 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9398 - loss: 0.2113 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1933 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1889 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9463 - loss: 0.1971 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1822 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1917 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9437 - loss: 0.2042 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2070 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2126 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.2106 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.2023 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1868 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1891 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1916 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9505 - loss: 0.1896 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1981 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9468 - loss: 0.1945 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.2104 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.2198 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2027 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1935 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1797 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9460 - loss: 0.2015 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9405 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1834 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9447 - loss: 0.2077 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1817 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.2021 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.1983 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9475 - loss: 0.1932 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2093 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2096 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9488 - loss: 0.1981 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9410 - loss: 0.2081 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/60\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2082 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▄▄▄▃▁▄▃▄▄▃▃▄▄▃▃▃▄▄▄▃▃▂▂▃▃▃▃▃▃▄▄▃▃▃▄▄▃▃</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▁▂▂▂▃▂▂▂▁▂▂▁▂▁▁▂▂▂▁▂▁▂▁▁▃▁▁▁▃▂▁▁▁▁▅▁▂</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>719</td></tr><tr><td>batch/loss</td><td>0.20227</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>59</td></tr><tr><td>epoch/loss</td><td>0.20227</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-3</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/y0xljow7/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235856-y0xljow7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1dbuxtcc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 58\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.04148164010801726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235912-1dbuxtcc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace' target=\"_blank\">avid-sweep-4</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8059 - loss: 0.3477 - precision: 0.0469 - recall: 0.1332\n",
      "Epoch 2/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.2161 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 3/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1963 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 4/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2246 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 5/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9524 - loss: 0.1815 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 6/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1893 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 7/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 8/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9324 - loss: 0.2593 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.2037 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 10/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9518 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 11/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9449 - loss: 0.2104 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 12/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2071 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 13/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.2065 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 14/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2076 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.2147 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 16/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9567 - loss: 0.1729 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 17/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9421 - loss: 0.2174 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 18/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1830 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.1995 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9373 - loss: 0.2255 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 22/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.2036 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9419 - loss: 0.2261 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9388 - loss: 0.2237 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9399 - loss: 0.2241 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 26/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2066 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 27/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.2296 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9402 - loss: 0.2209 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 30/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1889 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9443 - loss: 0.2044 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 32/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2134 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 33/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9436 - loss: 0.2116 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2052 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 35/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1802 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 36/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9573 - loss: 0.1653 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2194 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9461 - loss: 0.2003 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.2162 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 41/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1893 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1832 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.2116 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1852 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.2095 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9543 - loss: 0.1743 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2071 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9553 - loss: 0.1756 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.2274 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1946 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9391 - loss: 0.2196 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9469 - loss: 0.1998 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 55/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.2010 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2031 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9337 - loss: 0.2392 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 58/58\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.2137 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5d50381f3447d98da93c29e008b885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.054 MB of 0.054 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>▁▆▇▆▆▆▇▆▆▆▇▆▆▆▅▆▆▅▆▆▆▆▆▆▇▆▆▆█▆▆▆▅▆▆▆▇▆▆▆</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>█▄▄▄▄▅▃▅▄▃▂▅▄▃▅▅▄▅▄▄▄▅▅▄▁▅▃▄▁▄▄▄▆▃▄▄▂▄▄▄</td></tr><tr><td>batch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▃▁▁▂▃▂▂▂▁▂▁▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁</td></tr><tr><td>epoch/precision</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>1391</td></tr><tr><td>batch/loss</td><td>0.20112</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>57</td></tr><tr><td>epoch/loss</td><td>0.20112</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-sweep-4</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/1dbuxtcc/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235912-1dbuxtcc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lcj2vf69 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 90\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.07101435730894305\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_235937-lcj2vf69</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace' target=\"_blank\">wandering-sweep-5</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9094 - loss: 0.4067 - precision: 0.0000e+00 - recall: 0.0000e+00  \n",
      "Epoch 2/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9444 - loss: 0.2205 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 3/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9349 - loss: 0.2429 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 4/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9430 - loss: 0.2201 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 5/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9367 - loss: 0.2377 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 6/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9395 - loss: 0.2285 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 7/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.9448 - loss: 0.2131 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 8/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9375 - loss: 0.2335 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 9/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 10/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9468 - loss: 0.2063 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 11/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.9552 - loss: 0.1807 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 12/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2143 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 13/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9537 - loss: 0.1838 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 14/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2103 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 15/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.2100 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 16/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9484 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9418 - loss: 0.2145 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1913 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 19/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2121 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 20/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9428 - loss: 0.2087 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 21/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.2051 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 22/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9426 - loss: 0.2130 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 23/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.2114 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 24/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.2074 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 25/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2153 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 26/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9411 - loss: 0.2183 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 27/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.1998 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 28/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1834 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 29/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.2001 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 30/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1953 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 31/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9505 - loss: 0.1895 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 32/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.9330 - loss: 0.2308 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 33/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.2256 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 34/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.2114 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 35/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9403 - loss: 0.2193 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 36/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1810 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 37/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1982 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 38/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9436 - loss: 0.2108 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 39/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1887 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 40/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - accuracy: 0.9463 - loss: 0.2046 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 41/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1817 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 42/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9455 - loss: 0.2022 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 43/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1817 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 44/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9435 - loss: 0.2101 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 45/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9465 - loss: 0.2022 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 46/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.2038 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 47/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9433 - loss: 0.2030 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 48/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9486 - loss: 0.1968 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 49/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1848 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 50/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1782 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 51/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.2032 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 52/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1839 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 53/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9379 - loss: 0.2219 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 54/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.9479 - loss: 0.1984 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 55/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1872 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 56/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9458 - loss: 0.1997 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 57/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.9431 - loss: 0.2043 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 58/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9459 - loss: 0.1978 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 59/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9434 - loss: 0.2027 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 60/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1898 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 61/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.2112 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 62/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.2059 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 63/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9353 - loss: 0.2272 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 64/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9427 - loss: 0.2093 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 65/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 66/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step - accuracy: 0.9388 - loss: 0.2147 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 67/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.9418 - loss: 0.2138 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 68/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.9376 - loss: 0.2292 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 69/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9472 - loss: 0.1996 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 70/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.9457 - loss: 0.2054 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 71/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.2215 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 72/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9469 - loss: 0.1992 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 73/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9336 - loss: 0.2273 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 74/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9416 - loss: 0.2124 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 75/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9315 - loss: 0.2440 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 76/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9397 - loss: 0.2231 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 77/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - accuracy: 0.9430 - loss: 0.2089 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 78/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9348 - loss: 0.2307 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 79/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9431 - loss: 0.2135 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 80/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9474 - loss: 0.1959 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 81/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9503 - loss: 0.1884 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 82/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9382 - loss: 0.2257 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 83/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.9403 - loss: 0.2073 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 84/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.2246 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 85/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.2102 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 86/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.2000 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 87/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.9460 - loss: 0.1980 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 88/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9425 - loss: 0.2098 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 89/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.2053 - precision: 0.0000e+00 - recall: 0.0000e+00 \n",
      "Epoch 90/90\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9387 - loss: 0.2127 - precision: 0.0000e+00 - recall: 0.0000e+00 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0df411830f42ffa981606ae3558794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.030 MB of 0.030 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>batch/accuracy</td><td>█▆▄▆█▆▅▆▆▆▅▄▆▆▆▅▅▆▄▆▅▆▆▆▇▅▆▇▆▅▆▆▄▅▁▆▄▆▇▃</td></tr><tr><td>batch/batch_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>batch/loss</td><td>▂▄▆▃▁▄▃▂▃▂▃▅▂▂▂▄▄▃▄▂▃▂▂▂▁▄▂▁▂▄▂▃▅▄█▂▅▂▂▄</td></tr><tr><td>batch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/accuracy</td><td>▁███████████████████████████████████████</td></tr><tr><td>epoch/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▃▃▁▁▁▁▁▂▁▁▁▃▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94695</td></tr><tr><td>batch/accuracy</td><td>0.94562</td></tr><tr><td>batch/batch_step</td><td>4319</td></tr><tr><td>batch/loss</td><td>0.19672</td></tr><tr><td>batch/precision</td><td>0.0</td></tr><tr><td>batch/recall</td><td>0.0</td></tr><tr><td>epoch/accuracy</td><td>0.94562</td></tr><tr><td>epoch/epoch</td><td>89</td></tr><tr><td>epoch/loss</td><td>0.19672</td></tr><tr><td>epoch/precision</td><td>0.0</td></tr><tr><td>epoch/recall</td><td>0.0</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-sweep-5</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/lcj2vf69/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_235937-lcj2vf69/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cz3k0cko with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_1: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_2: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_3: sigmoid\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 224\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclass_weighting: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdrug: Amphet\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 72\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_shape_1: [7]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_3: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: binary_crossentropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.05899822579974695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adamw\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240401_000004-cz3k0cko</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace' target=\"_blank\">sweet-sweep-6</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/sweeps/9kg7b063</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/cz3k0cko/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/72\n"
     ]
    }
   ],
   "source": [
    "for drug in df.iloc[:, 8:15].columns:\n",
    "    sweep_configuration = {\n",
    "        \"name\": f\"sweep_{target}\",\n",
    "        \"method\": \"bayes\",\n",
    "        \"metric\": {\n",
    "            \"goal\": \"maximize\",\n",
    "            \"name\": \"f1_score\",\n",
    "        },\n",
    "        \"parameters\": {\n",
    "            \"optimizer\": {\n",
    "                \"distribution\": \"categorical\",\n",
    "                \"values\": [\n",
    "                    \"adam\",\n",
    "                    \"adamw\",\n",
    "                    \"adamax\",\n",
    "                    \"sgd\",\n",
    "                ],\n",
    "            },\n",
    "            \"batch_size\": {\n",
    "                \"distribution\": \"q_uniform\",\n",
    "                \"q\": 8,\n",
    "                \"min\": 8,\n",
    "                \"max\": 256,\n",
    "            },\n",
    "            \"epoch\": {\n",
    "                \"distribution\": \"int_uniform\",\n",
    "                \"min\": 3,\n",
    "                \"max\": 100,\n",
    "            },\n",
    "            \"lr\": {\n",
    "                \"distribution\": \"uniform\",\n",
    "                \"min\": 0.00001,\n",
    "                \"max\": 0.1,\n",
    "            },\n",
    "            \"class_weighting\": {\n",
    "                \"distribution\": \"categorical\",\n",
    "                \"values\": [\n",
    "                    True,\n",
    "                    False,\n",
    "                ],\n",
    "            },\n",
    "            \"layer_1\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": 64,\n",
    "            },\n",
    "            \"activation_1\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"relu\",\n",
    "            },\n",
    "            \"input_shape_1\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": (7,),\n",
    "            },\n",
    "            \"layer_2\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": 32,\n",
    "            },\n",
    "            \"activation_2\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"relu\",\n",
    "            },\n",
    "            \"layer_3\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": 1,\n",
    "            },\n",
    "            \"activation_3\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"sigmoid\",\n",
    "            },\n",
    "            \"loss\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": \"binary_crossentropy\",\n",
    "            },\n",
    "            \"drug\": {\n",
    "                \"distribution\": \"constant\",\n",
    "                \"value\": drug,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Setup sweep\n",
    "    sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"XAI-group-assignment\")\n",
    "    wandb.agent(sweep_id=sweep_id, function=train_with_wandb, count=100)\n",
    "\n",
    "    # Stop sweep recording.\n",
    "    wandb.teardown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_ann_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_1,\n",
    "                activation=wandb.config.activation_1,\n",
    "                input_shape=wandb.config.input_shape_1,\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_2, activation=wandb.config.activation_2\n",
    "            ),\n",
    "            tf.keras.layers.Dense(\n",
    "                wandb.config.layer_3, activation=wandb.config.activation_3\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=wandb.config.loss,\n",
    "        metrics=wandb.config.metric,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize_wandb(target):\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"XAI-group-assignment\",\n",
    "        name=f\"{target}\",\n",
    "        group=\"run_epoch_25_batch_16_lr_0.001(default)\",\n",
    "        # track hyperparameters and run metadata with wandb.config\n",
    "        config={\n",
    "            \"layer_1\": 64,\n",
    "            \"activation_1\": \"relu\",\n",
    "            \"input_shape_1\": (7,),\n",
    "            \"layer_2\": 32,\n",
    "            \"activation_2\": \"relu\",\n",
    "            \"layer_3\": 1,\n",
    "            \"activation_3\": \"sigmoid\",\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"loss\": \"binary_crossentropy\",\n",
    "            \"metric\": [\"accuracy\", \"precision\", \"recall\"],\n",
    "            \"epoch\": 25,\n",
    "            \"batch_size\": 16,\n",
    "        },\n",
    "    )\n",
    "    # return wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013450-fty2d2mn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace' target=\"_blank\">Amphet</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>█▁▁▄▃▂▂▃▁▃▂▃▂▃▂▃▃▂▄▃▃▃▄▃▃</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▅▅▄▄▄▃▅▄▃▃▄▃▃▃▃▂▂▂▂▂▁▁▂</td></tr><tr><td>epoch/precision</td><td>▄▁▂▅▇▄▅▆▂▅▄▆▃▆▅▆▆▄▇▆▆▇█▆▅</td></tr><tr><td>epoch/recall</td><td>▁▇█▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇█▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.59416</td></tr><tr><td>epoch/accuracy</td><td>0.6061</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.62397</td></tr><tr><td>epoch/precision</td><td>0.08842</td></tr><tr><td>epoch/recall</td><td>0.67073</td></tr><tr><td>f1_score</td><td>0.18182</td></tr><tr><td>precision</td><td>0.1018</td></tr><tr><td>recall</td><td>0.85</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Amphet</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/fty2d2mn/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013450-fty2d2mn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c13e8e4795247a1afd5c7393d7b72d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112228588818754, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013502-8d7ik19v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace' target=\"_blank\">Benzo</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▄█▁▅▅▂▂▃▄▅▇▃▆▅▅▇▅▆▆▅▅▄▆▆▆</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▆▄▄▃▃▄▃▃▂▂▂▂▂▂▂▁▃▃▂▃▁▁▁</td></tr><tr><td>epoch/precision</td><td>▁▅▄▇▇▆▆▆▆▇█▆▇▇▆█▇▇▇▇▇▇▇▇█</td></tr><tr><td>epoch/recall</td><td>▁▃▆▇▇█▇▇▇▇▇█▇▇▇█▇█▇███▇▆▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.76393</td></tr><tr><td>epoch/accuracy</td><td>0.70623</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.57874</td></tr><tr><td>epoch/precision</td><td>0.1153</td></tr><tr><td>epoch/recall</td><td>0.72368</td></tr><tr><td>f1_score</td><td>0.21239</td></tr><tr><td>precision</td><td>0.12766</td></tr><tr><td>recall</td><td>0.63158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Benzo</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/8d7ik19v/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013502-8d7ik19v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c80421f9f814032a3fbff00bdcfd611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112405666709593, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013513-3b2q0naq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace' target=\"_blank\">Cannabis</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▅█▇▇▇█▇▆▇▇▆▇█▇▆▇▆▇▆▆▇▆▆▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▅▄▃▃▃▃▃▂▂▃▂▂▂▃▂▂▂▂▂▁▂▂▁▁</td></tr><tr><td>epoch/precision</td><td>▁▄█▆▇▇▇▇▆▇▇▆▆█▇▆▇▆▇▆▆▇▆▆▇</td></tr><tr><td>epoch/recall</td><td>▇▅▁▃▂▃▃▄▅▆▅▄▄▇▆▆█▆▅▇▇▆█▆█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.6817</td></tr><tr><td>epoch/accuracy</td><td>0.63727</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.59136</td></tr><tr><td>epoch/precision</td><td>0.38057</td></tr><tr><td>epoch/recall</td><td>0.76216</td></tr><tr><td>f1_score</td><td>0.55556</td></tr><tr><td>precision</td><td>0.42373</td></tr><tr><td>recall</td><td>0.80645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Cannabis</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/3b2q0naq/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013513-3b2q0naq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662e206dbbce4aacad6492ee2713bce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112177677811511, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013526-ubweekwp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace' target=\"_blank\">Heroin</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>█▆▃▄▃▁▃▂▃▂▂▂▂▃▁▂▃▁▂▂▂▂▃▂▂</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▆▅▅▄▄▃▂▃▂▃▂▂▂▂▃▂▂▂▁▂▁▁▂</td></tr><tr><td>epoch/precision</td><td>▁█▆▇▇▇█▇█▆▇▇▇█▇▇█▆▇▇▇▇▇▇▇</td></tr><tr><td>epoch/recall</td><td>▁▄▅▅▆▇▇▇▇▇▇█▇▇██▇█▇██▇▇█▇</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.78249</td></tr><tr><td>epoch/accuracy</td><td>0.68302</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.49718</td></tr><tr><td>epoch/precision</td><td>0.03666</td></tr><tr><td>epoch/recall</td><td>0.78261</td></tr><tr><td>f1_score</td><td>0.12766</td></tr><tr><td>precision</td><td>0.06818</td></tr><tr><td>recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Heroin</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/ubweekwp/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013526-ubweekwp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08b2cb5c2224c7aa9628f138455ec98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112446655493437, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013540-vmq1bbds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace' target=\"_blank\">Ketamine</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e50cbb40e2a4a399e957eb3befc62d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▇███████████████████████▁</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>▇▅▃▂▂▂▂▂▂▂▂▂█▃▃▂▃▂▂▂▂▂▁▃▁</td></tr><tr><td>epoch/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>epoch/recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99735</td></tr><tr><td>epoch/accuracy</td><td>0.9244</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.65872</td></tr><tr><td>epoch/precision</td><td>0.00885</td></tr><tr><td>epoch/recall</td><td>0.33333</td></tr><tr><td>f1_score</td><td>0.0</td></tr><tr><td>precision</td><td>0.0</td></tr><tr><td>recall</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Ketamine</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/vmq1bbds/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013540-vmq1bbds/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac7e543879e4a1abfecc5e77a313592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112327499965128, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013553-0sv6v044</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace' target=\"_blank\">Methadone</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa23f7cf4ff43fcbb809761cea38013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▁▆▅▇█▄▇▆▇█▆██▇▇▇▇█▇▇█▆▇█▇</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▇▇▆▇▄▄▄▃▃▃▄▃▄▃▃▂▃▂▃▃▃▁▂▁</td></tr><tr><td>epoch/precision</td><td>▁▃▄▅▆▅▆▅▅█▅█▆▆▆▅▆▇▇▅▇▆▇▆▆</td></tr><tr><td>epoch/recall</td><td>▆▁▄▂▂█▄▅▂▄▇▅▃▄▄▄▅▄▇▃▄▇▅▂▄</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57825</td></tr><tr><td>epoch/accuracy</td><td>0.6565</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.6229</td></tr><tr><td>epoch/precision</td><td>0.06767</td></tr><tr><td>epoch/recall</td><td>0.62069</td></tr><tr><td>f1_score</td><td>0.13115</td></tr><tr><td>precision</td><td>0.07143</td></tr><tr><td>recall</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Methadone</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/0sv6v044/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013553-0sv6v044/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c1cc711f114c14869ff676f874892f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112489822213927, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/mountpoint/xai-project/wandb/run-20240331_013607-hkbd95zz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace' target=\"_blank\">Semeron</a></strong> to <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bas_korver/XAI-group-assignment' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61324b3aeb954b1da0f74c27bad14a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch/accuracy</td><td>▆█▆▅▆▁▆▄▄▂▃▄▃▂▅▅▃▃▃▃▄▄▅▄▃</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▅▆▅▅▄▇▄▄▃▃▄▃▃▃▄▂▂▃▂▂▁▂▂▁</td></tr><tr><td>epoch/precision</td><td>▄▁▆▄▇▅▁▆▆▆▆▇▅▅█▆▆▆▄▇▆██▇▇</td></tr><tr><td>epoch/recall</td><td>▂▁▄▄▅█▁▇▇██▇▇█▇▅▇█▅█▇█▇▇█</td></tr><tr><td>f1_score</td><td>▁</td></tr><tr><td>precision</td><td>▁</td></tr><tr><td>recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56499</td></tr><tr><td>epoch/accuracy</td><td>0.5179</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/loss</td><td>0.59474</td></tr><tr><td>epoch/precision</td><td>0.00684</td></tr><tr><td>epoch/recall</td><td>0.83333</td></tr><tr><td>f1_score</td><td>0.01205</td></tr><tr><td>precision</td><td>0.0061</td></tr><tr><td>recall</td><td>0.5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Semeron</strong> at: <a href='https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace' target=\"_blank\">https://wandb.ai/bas_korver/XAI-group-assignment/runs/hkbd95zz/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240331_013607-hkbd95zz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Amphet': <Sequential name=sequential_14, built=True>,\n",
      " 'Benzo': <Sequential name=sequential_15, built=True>,\n",
      " 'Cannabis': <Sequential name=sequential_16, built=True>,\n",
      " 'Heroin': <Sequential name=sequential_17, built=True>,\n",
      " 'Ketamine': <Sequential name=sequential_18, built=True>,\n",
      " 'Methadone': <Sequential name=sequential_19, built=True>,\n",
      " 'Semeron': <Sequential name=sequential_20, built=True>}\n",
      "{\n",
      "    \"Amphet\": {\n",
      "        \"accuracy\": 0.5941644562334217,\n",
      "        \"precision\": 0.10179640718562874,\n",
      "        \"recall\": 0.85,\n",
      "        \"f1_score\": 0.18181818181818182\n",
      "    },\n",
      "    \"Benzo\": {\n",
      "        \"accuracy\": 0.7639257294429708,\n",
      "        \"precision\": 0.1276595744680851,\n",
      "        \"recall\": 0.631578947368421,\n",
      "        \"f1_score\": 0.21238938053097345\n",
      "    },\n",
      "    \"Cannabis\": {\n",
      "        \"accuracy\": 0.6816976127320955,\n",
      "        \"precision\": 0.423728813559322,\n",
      "        \"recall\": 0.8064516129032258,\n",
      "        \"f1_score\": 0.5555555555555556\n",
      "    },\n",
      "    \"Heroin\": {\n",
      "        \"accuracy\": 0.7824933687002652,\n",
      "        \"precision\": 0.06818181818181818,\n",
      "        \"recall\": 1.0,\n",
      "        \"f1_score\": 0.1276595744680851\n",
      "    },\n",
      "    \"Ketamine\": {\n",
      "        \"accuracy\": 0.9973474801061007,\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1_score\": 0.0\n",
      "    },\n",
      "    \"Methadone\": {\n",
      "        \"accuracy\": 0.5782493368700266,\n",
      "        \"precision\": 0.07142857142857142,\n",
      "        \"recall\": 0.8,\n",
      "        \"f1_score\": 0.13114754098360656\n",
      "    },\n",
      "    \"Semeron\": {\n",
      "        \"accuracy\": 0.5649867374005305,\n",
      "        \"precision\": 0.006097560975609756,\n",
      "        \"recall\": 0.5,\n",
      "        \"f1_score\": 0.012048192771084338\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for target in df.iloc[:, 8:15].columns:\n",
    "    target_x_train, target_y_train, target_x_test, target_y_test = get_data_from_df(\n",
    "        df, target\n",
    "    )\n",
    "\n",
    "    # Calculate class weights.\n",
    "    target_class_weights = dict(\n",
    "        enumerate(\n",
    "            class_weight.compute_class_weight(\n",
    "                \"balanced\", classes=np.unique(target_y_train), y=target_y_train\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Initialize wandb\n",
    "    initialize_wandb(target)\n",
    "\n",
    "    # Create classifier.\n",
    "    target_model = create_ann_model()\n",
    "\n",
    "    # Train model with data specified for target.\n",
    "    target_model.fit(\n",
    "        target_x_train,\n",
    "        target_y_train,\n",
    "        epochs=wandb.config.epoch,\n",
    "        batch_size=wandb.config.batch_size,\n",
    "        class_weight=target_class_weights,\n",
    "        verbose=0,\n",
    "        callbacks=[\n",
    "            WandbMetricsLogger(),\n",
    "        ],\n",
    "    )\n",
    "    models[target] = target_model\n",
    "\n",
    "    target_model.save(f\"./models/ann_{ target }.h5\")\n",
    "\n",
    "    # Evaluate trained classifier.\n",
    "    target_y_predictions = (target_model.predict(target_x_test) >= 0.5).astype(\"int32\")\n",
    "\n",
    "    # Calculate metrics.\n",
    "    accuracy = accuracy_score(target_y_test, target_y_predictions)\n",
    "    precision = precision_score(target_y_test, target_y_predictions)\n",
    "    recall = recall_score(target_y_test, target_y_predictions)\n",
    "    f1 = f1_score(target_y_test, target_y_predictions)\n",
    "\n",
    "    metrics[target] = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model_artifact = wandb.Artifact(\n",
    "        name=f\"{target}_{f1}\",\n",
    "        type=\"model\",\n",
    "        description=f\"Model trained for {target}\",\n",
    "        metadata=dict(wandb.config),\n",
    "    )\n",
    "    wandb.add_file(f\"ann_{ target }.h5\")\n",
    "    wandb.log_artifact(model_artifact)\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "pprint.pprint(models)\n",
    "print(json.dumps(metrics, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
